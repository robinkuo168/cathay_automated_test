import os
import json
import threading
import re
import math
from typing import List, Dict, Any, Optional, Tuple
from pathlib import Path
import pandas as pd
from ibm_watsonx_ai.foundation_models import ModelInference
from ibm_watsonx_ai.metanames import GenTextParamsMetaNames as GenParams
from ibm_watsonx_ai.credentials import Credentials
from dotenv import load_dotenv
import xml.etree.ElementTree as ET
from xml.dom import minidom
import xml.sax.saxutils as saxutils
from xml.sax.saxutils import escape as saxutils_escape
from dataclasses import asdict
from .logger import get_logger
from .llm_service import LLMService
import io
import csv
from dataclasses import dataclass, field

load_dotenv()

@dataclass
class CsvInfo:
    filename: str
    variable_names: List[str] = field(default_factory=list)
    total_rows: int = 0
    raw_content: Optional[str] = None

@dataclass
class HttpRequestInfo:
    name: str
    json_body: Optional[str] = None
    source_json_filename: Optional[str] = None
    method: str = "POST"
    # æ–°å¢æ¨™è¨˜ï¼Œè¿½è¹¤æ­¤è«‹æ±‚æ˜¯å¦å·²æˆåŠŸåƒæ•¸åŒ–
    is_parameterized: bool = False

@dataclass
class ThreadGroupContext:
    name: str
    http_requests: List[HttpRequestInfo] = field(default_factory=list)
    csv_configs: List[CsvInfo] = field(default_factory=list)

@dataclass
class GenerationContext:
    test_plan_name: str
    thread_groups: List[ThreadGroupContext]
    requirements: str
    raw_processed_files: Dict

class JMXGeneratorService:
    def __init__(self, llm_service: Optional[LLMService] = None, model_name: str = "default"):
        """
        åˆå§‹åŒ– JMXGeneratorService
        :param llm_service: å¯é¸çš„ LLMService å¯¦ä¾‹ï¼Œå¦‚æœç‚º None å‰‡æœƒè‡ªå‹•å‰µå»º
        :param model_name: è¦ä½¿ç”¨çš„æ¨¡å‹åç¨±ï¼Œé è¨­ç‚º "default"
        """
        self._llm_service = llm_service
        self._model_name = model_name
        self.logger = get_logger(__name__)
        self.jmx_templates = self._load_jmx_templates()

    @property
    def llm_service(self) -> LLMService:
        if self._llm_service is None:
            self.logger.info(f"åˆå§‹åŒ– LLMService (Model: {self._model_name})")
            try:
                # å¾ main æ¨¡çµ„å°å…¥ get_llm_service å‡½æ•¸
                from main import get_llm_service
                self._llm_service = get_llm_service(self._model_name)
            except ImportError:
                self.logger.warning("ç„¡æ³•å¾ main æ¨¡çµ„å°å…¥ get_llm_serviceï¼Œä½¿ç”¨é»˜èª LLMService åˆå§‹åŒ–")
                self._llm_service = LLMService()
        return self._llm_service

    def _load_jmx_templates(self) -> Dict:
        """
        è¼‰å…¥æ‰€æœ‰å¿…è¦çš„ã€çµæ§‹æ­£ç¢ºçš„ JMX çµ„ä»¶æ¨¡æ¿ã€‚
        """
        self.logger.info("æ­£åœ¨è¼‰å…¥æ‰€æœ‰ JMX çµ„ä»¶æ¨¡æ¿...")
        templates = {
            "xml_header": """<?xml version="1.0" encoding="UTF-8"?>""",
            "test_plan_structure": """<jmeterTestPlan version="1.2" properties="5.0" jmeter="5.6.3">
      <hashTree>
        <TestPlan guiclass="TestPlanGui" testclass="TestPlan" testname="{test_name}" enabled="true">
          <stringProp name="TestPlan.comments">{comments}</stringProp>
          <boolProp name="TestPlan.functional_mode">false</boolProp>
          <boolProp name="TestPlan.tearDown_on_shutdown">{tear_down_on_shutdown}</boolProp>
          <boolProp name="TestPlan.serialize_threadgroups">false</boolProp>
          <elementProp name="TestPlan.user_defined_variables" elementType="Arguments" guiclass="ArgumentsPanel" testclass="Arguments" testname="User Defined Variables" enabled="true">
            <collectionProp name="Arguments.arguments"/>
          </elementProp>
        </TestPlan>
        <hashTree>
          {content}
        </hashTree>
      </hashTree>
    </jmeterTestPlan>""",
            "thread_group": """<ThreadGroup guiclass="ThreadGroupGui" testclass="ThreadGroup" testname="{name}" enabled="true">
            <stringProp name="ThreadGroup.on_sample_error">{on_sample_error}</stringProp>
            <elementProp name="ThreadGroup.main_controller" elementType="LoopController" guiclass="LoopControlPanel" testclass="LoopController" testname="Loop Controller" enabled="true">
              <stringProp name="LoopController.loops">{loops}</stringProp>
              <boolProp name="LoopController.continue_forever">false</boolProp>
            </elementProp>
            <stringProp name="ThreadGroup.num_threads">{num_threads}</stringProp>
            <stringProp name="ThreadGroup.ramp_time">{ramp_time}</stringProp>
            <boolProp name="ThreadGroup.scheduler">{scheduler}</boolProp>
            <stringProp name="ThreadGroup.duration">{duration}</stringProp>
            <stringProp name="ThreadGroup.delay"></stringProp>
            <boolProp name="ThreadGroup.same_user_on_next_iteration">true</boolProp>
          </ThreadGroup>
          <hashTree>
            {content}
          </hashTree>""",
            "http_request_with_body": """<HTTPSamplerProxy guiclass="HttpTestSampleGui" testclass="HTTPSamplerProxy" testname="{name}" enabled="true">
              <boolProp name="HTTPSampler.postBodyRaw">true</boolProp>
              <elementProp name="HTTPsampler.Arguments" elementType="Arguments">
                <collectionProp name="Arguments.arguments">
                  <elementProp name="" elementType="HTTPArgument">
                    <boolProp name="HTTPArgument.always_encode">false</boolProp>
                    <stringProp name="Argument.value">{body_data}</stringProp>
                    <stringProp name="Argument.metadata">=</stringProp>
                  </elementProp>
                </collectionProp>
              </elementProp>
              <stringProp name="HTTPSampler.path">{path}</stringProp>
              <stringProp name="HTTPSampler.method">{method}</stringProp>
              <boolProp name="HTTPSampler.follow_redirects">true</boolProp>
              <boolProp name="HTTPSampler.auto_redirects">false</boolProp>
              <boolProp name="HTTPSampler.use_keepalive">true</boolProp>
              <boolProp name="HTTPSampler.DO_MULTIPART_POST">false</boolProp>
              <stringProp name="HTTPSampler.concurrentPool">6</stringProp>
            </HTTPSamplerProxy>""",
            "csv_data_set_config": """<CSVDataSet guiclass="TestBeanGUI" testclass="CSVDataSet" testname="CSV Data Set Config" enabled="true">
              <stringProp name="delimiter">{delimiter}</stringProp>
              <stringProp name="fileEncoding">UTF-8</stringProp>
              <stringProp name="filename">{filename}</stringProp>
              <boolProp name="ignoreFirstLine">{ignore_first_line}</boolProp>
              <boolProp name="quotedData">{allow_quoted_data}</boolProp>
              <boolProp name="recycle">{recycle}</boolProp>
              <stringProp name="shareMode">{share_mode}</stringProp>
              <boolProp name="stopThread">{stop_thread}</boolProp>
              <stringProp name="variableNames">{variable_names}</stringProp>
            </CSVDataSet>
            <hashTree/>""",
            "http_defaults": """<ConfigTestElement guiclass="HttpDefaultsGui" testclass="ConfigTestElement" testname="HTTP Request Defaults" enabled="true">
            <elementProp name="HTTPsampler.Arguments" elementType="Arguments" guiclass="HTTPArgumentsPanel" testclass="Arguments" enabled="true">
              <collectionProp name="Arguments.arguments"/>
            </elementProp>
            <stringProp name="HTTPSampler.domain">{domain}</stringProp>
            <stringProp name="HTTPSampler.protocol">{protocol}</stringProp>
            <stringProp name="HTTPSampler.port">{port}</stringProp>
            <stringProp name="HTTPSampler.contentEncoding">{content_encoding}</stringProp>
            <stringProp name="HTTPSampler.path">{path}</stringProp>
            <stringProp name="HTTPSampler.connect_timeout">{connect_timeout}</stringProp>
            <stringProp name="HTTPSampler.response_timeout">{response_timeout}</stringProp>
          </ConfigTestElement>
          <hashTree/>""",
            "header_manager": """<HeaderManager guiclass="HeaderPanel" testclass="HeaderManager" testname="HTTP Header Manager" enabled="true">
            <collectionProp name="HeaderManager.headers">
              {headers}
            </collectionProp>
          </HeaderManager>
          <hashTree/>""",
            "header_element": """<elementProp name="" elementType="Header">
                <stringProp name="Header.name">{name}</stringProp>
                <stringProp name="Header.value">{value}</stringProp>
              </elementProp>""",
            "random_variable_config": """<RandomVariableConfig guiclass="TestBeanGUI" testclass="RandomVariableConfig" testname="{name}" enabled="true">
                <stringProp name="maximumValue">{max_value}</stringProp>
                <stringProp name="minimumValue">{min_value}</stringProp>
                <stringProp name="outputFormat">{output_format}</stringProp>
                <boolProp name="perThread">{per_thread}</boolProp>
                <stringProp name="randomSeed"></stringProp>
                <stringProp name="variableName">{variable_name}</stringProp>
            </RandomVariableConfig>
            <hashTree/>""",
            "response_assertion": """<ResponseAssertion guiclass="AssertionGui" testclass="ResponseAssertion" testname="{name}" enabled="true">
                <collectionProp name="Asserion.test_strings">
                  {patterns_to_test}
                </collectionProp>
                <stringProp name="Assertion.custom_message"></stringProp>
                <stringProp name="Assertion.test_field">Assertion.response_data</stringProp>
                <boolProp name="Assertion.assume_success">false</boolProp>
                <intProp name="Assertion.test_type">{test_type}</intProp>
            </ResponseAssertion>""",
            "assertion_pattern": """<stringProp name="{hash_code}">{pattern}</stringProp>""",
            "result_collector": """<ResultCollector guiclass="ViewResultsFullVisualizer" testclass="ResultCollector" testname="{name}" enabled="true">
                <boolProp name="ResultCollector.error_logging">false</boolProp>
                <objProp>
                  <name>saveConfig</name>
                  <value class="SampleSaveConfiguration">
                    <time>true</time>
                    <latency>true</latency>
                    <timestamp>true</timestamp>
                    <success>true</success>
                    <label>true</label>
                    <code>true</code>
                    <message>true</message>
                    <threadName>true</threadName>
                    <dataType>true</dataType>
                    <encoding>false</encoding>
                    <assertions>true</assertions>
                    <subresults>true</subresults>
                    <responseData>false</responseData>
                    <samplerData>false</samplerData>
                    <xml>false</xml>
                    <fieldNames>true</fieldNames>
                    <responseHeaders>false</responseHeaders>
                    <requestHeaders>false</requestHeaders>
                    <responseDataOnError>false</responseDataOnError>
                    <saveAssertionResultsFailureMessage>true</saveAssertionResultsFailureMessage>
                    <assertionsResultsToSave>0</assertionsResultsToSave>
                    <bytes>true</bytes>
                    <sentBytes>true</sentBytes>
                    <url>true</url>
                    <threadCounts>true</threadCounts>
                    <idleTime>true</idleTime>
                    <connectTime>true</connectTime>
                  </value>
                </objProp>
                <stringProp name="filename"></stringProp>
              </ResultCollector>
              <hashTree/>"""
        }
        self.logger.info(f"âœ… æ‰€æœ‰ {len(templates)} å€‹ JMX æ¨¡æ¿è¼‰å…¥å®Œæˆã€‚")
        return templates

    def _create_jmx_from_template(self, test_name: str, comments: str = "", content: str = "") -> str:
        """å¾æ¨¡æ¿å‰µå»ºå®Œæ•´çš„ JMX å…§å®¹"""
        return (
                self.jmx_templates["xml_header"] + "\n" +
                self.jmx_templates["test_plan_structure"].format(
                    test_name=test_name,
                    comments=comments,
                    content=content
                )
        )

    def generate_jmx_with_retry(self, requirements: str, files_data: List[Dict] = None, max_retries: int = 3) -> str:
        """
        ç”Ÿæˆ JMX æª”æ¡ˆï¼ˆæ¡ç”¨æ–°æµç¨‹ï¼‰
        """
        try:
            context = self._prepare_generation_context(requirements, files_data)
            self.logger.info(f"âœ… ç”Ÿæˆä¸Šä¸‹æ–‡æº–å‚™å®Œæˆï¼Œæ¸¬è©¦è¨ˆç•«: '{context.test_plan_name}'")
            # ã€é™¤éŒ¯å»ºè­°ã€‘å¦‚æœæ‚¨éœ€è¦æª¢æŸ¥ context å…§å®¹ï¼Œå¯ä»¥åœ¨é€™è£¡åŠ å…¥æ—¥èªŒ
            # self.logger.info(f"DEBUG CONTEXT: {context}")
        except ValueError as e:
            self.logger.error(f"âŒ è¼¸å…¥è³‡æ–™æº–å‚™å¤±æ•—: {e}")
            raise e

        validation_errors = []
        for attempt in range(max_retries):
            try:
                self.logger.info(f"ğŸš€ é–‹å§‹ç¬¬ {attempt + 1}/{max_retries} æ¬¡å…§å®¹ç”Ÿæˆå˜—è©¦...")
                prompt = self._build_content_generation_prompt(context, attempt, validation_errors)
                response = self.llm_service.generate_text(prompt=prompt)
                test_plan_data = self._parse_llm_content_response(response)
                jmx_content = self._assemble_jmx_from_structured_data(test_plan_data, context)
                is_valid, message = self.validate_xml(jmx_content)
                if not is_valid:
                    validation_errors.append(f"çµ„è£å¾Œçš„ JMX çµæ§‹ç„¡æ•ˆ: {message}")
                    self.logger.warning(f"ç¬¬ {attempt + 1} æ¬¡å˜—è©¦ - JMX çµ„è£é©—è­‰å¤±æ•—: {message}")
                    continue

                self.logger.info(f"âœ… ç¬¬ {attempt + 1} æ¬¡ç”Ÿæˆèˆ‡çµ„è£æˆåŠŸï¼")
                return jmx_content

            except (json.JSONDecodeError, ValueError) as e:
                self.logger.error(f"ç¬¬ {attempt + 1} æ¬¡å˜—è©¦ - è§£æ LLM å›æ‡‰å¤±æ•—: {e}", exc_info=True)
                validation_errors.append(f"LLM å›æ‡‰çš„ JSON æ ¼å¼éŒ¯èª¤: {str(e)}")
            except Exception as e:
                self.logger.error(f"ç¬¬ {attempt + 1} æ¬¡ç”Ÿæˆéç¨‹ä¸­ç™¼ç”Ÿç•°å¸¸: {e}", exc_info=True)
                validation_errors.append(f"åŸ·è¡Œç•°å¸¸: {str(e)}")

        self.logger.error("æ‰€æœ‰é‡è©¦å‡å‘Šå¤±æ•—ã€‚")
        raise Exception("ç„¡æ³•ç”Ÿæˆæœ‰æ•ˆçš„ JMX æª”æ¡ˆï¼Œå·²é”æœ€å¤§é‡è©¦æ¬¡æ•¸ã€‚")

    def _build_content_generation_prompt(self, context: 'GenerationContext', attempt: int,
                                         validation_errors: list[str]) -> str:
        """
        ã€â­ æœ€çµ‚ä¿®æ­£ç‰ˆã€‘å»ºç«‹ä¸€å€‹é«˜åº¦çµæ§‹åŒ–ã€åš´æ ¼ç´„æŸçš„æç¤ºè©ã€‚
        - æä¾›ç²¾ç¢ºçš„è—åœ– (Blueprint)ï¼ŒæŒ‡å° LLM é€²è¡Œå¡«ç©ºè€Œéå‰µä½œã€‚
        - æ˜ç¢ºç¦æ­¢ç¡¬å¼ç·¨ç¢¼ï¼Œå¼·åˆ¶ä½¿ç”¨ä¾†è‡ª context çš„è®Šæ•¸å’Œçµæ§‹ã€‚
        - æä¾›èˆ‡ç›®æ¨™åƒè€ƒæª”æ¡ˆå®Œå…¨ä¸€è‡´çš„ç¯„ä¾‹ï¼Œä»¥ç²å¾—æœ€ç²¾ç¢ºçš„çµæœã€‚
        """
        self.logger.info(f"=== æ­¥é©Ÿ 2 (é€šç”¨æµç¨‹): å»ºç«‹å…§å®¹ç”Ÿæˆæç¤ºè© (ç¬¬ {attempt + 1} æ¬¡å˜—è©¦) ===")

        # --- 1. å»ºç«‹ä¸€å€‹é«˜åº¦ç²¾ç¢ºçš„ JSON çµæ§‹æŒ‡å— (è—åœ–)ï¼Œèˆ‡åƒè€ƒ JMX æª”æ¡ˆå°é½Š ---
        json_structure_guide = {
            "test_plan_name": context.test_plan_name,
            "tear_down_on_shutdown": True,
            "global_user_defined_variables": [],
            "global_headers": [
                # ã€é—œéµä¿®æ­£ã€‘ä¿®æ­£ Content-Typeï¼Œä½¿å…¶èˆ‡åƒè€ƒæª”æ¡ˆå®Œå…¨ä¸€è‡´
                {"name": "Content-Type", "value": "application/json; charset=UTF-8"},
                {"name": "x-cub-it-key", "value": "zgnf1hJIZVxtIxfjLl2a0T9vl5f98o9b"}
            ],
            "http_defaults": {
                # ã€é—œéµä¿®æ­£ã€‘ç›´æ¥æä¾›æ­£ç¢ºçš„ domainï¼Œå¼•å° LLM
                "domain": "msp-gw-rest-overtest.apps.epaas.cathayuat.intra.uwccb",
                "protocol": "https",
                "path": "/rest",
                "connect_timeout": 5000,
                "response_timeout": 5000
            },
            "random_variables": [{
                "name": "TXNSEQ",
                "variable_name": "TXNSEQ",
                "output_format": "",
                "min_value": "00000000",
                "max_value": "99999999",
                "per_thread": False
            }],
            "thread_groups": []
        }

        # --- 2. ç‚ºæ¯å€‹ Thread Group å»ºç«‹ç²¾ç¢ºçš„å­çµæ§‹ ---
        for tg_context in context.thread_groups:
            tg_template = {
                "name": tg_context.name,
                "on_sample_error": "continue",
                # ã€é—œéµä¿®æ­£ã€‘ä½¿ç”¨èˆ‡åƒè€ƒæª”æ¡ˆä¸€è‡´çš„åƒæ•¸åç¨±å’Œå€¼
                "num_threads": "${__P(threadsMIU,3)}",
                "ramp_time": "${__P(rampUp,1)}",
                "loops": "${__P(loop,-1)}",
                "scheduler": True,
                "duration": "${__P(duration,5)}",
                "csv_data_configs": [],
                "http_requests": []
            }

            if tg_context.csv_configs:
                for csv in tg_context.csv_configs:
                    tg_template["csv_data_configs"].append({
                        "filename": csv.filename,
                        "variable_names": ",".join(csv.variable_names),
                        "delimiter": ",",
                        "ignore_first_line": True
                    })

            if tg_context.http_requests:
                for req in tg_context.http_requests:
                    # ã€é—œéµä¿®æ­£ã€‘æä¾›èˆ‡åƒè€ƒæª”æ¡ˆå®Œå…¨ä¸€è‡´çš„æ–·è¨€ç¯„ä¾‹
                    assertion_returncode = {
                        "name": "Response Assertion-Return code",
                        "test_field": "Assertion.response_data",
                        # 34 = Substring | Or (æª¢æŸ¥å›æ‡‰ä¸­æ˜¯å¦åŒ…å«ä»»ä¸€å­—ä¸²)
                        "test_type": 34,
                        "patterns": ["\"RETURNCODE\":\"0000\"", "\"RETURNCODE\":\"E009\""]
                    }
                    assertion_txseq = {
                        "name": "Response Assertion-TXNSEQ",
                        "test_field": "Assertion.response_data",
                        # 2 = Contains (æª¢æŸ¥å›æ‡‰ä¸­æ˜¯å¦åŒ…å«è®Šæ•¸å€¼)
                        "test_type": 2,
                        "patterns": ["${TXNSEQ}"]
                    }

                    req_template = {
                        "name": req.name,
                        "path": "/rest",
                        "method": "POST",
                        "body": json.loads(req.json_body) if req.json_body and req.json_body.strip() else {},
                        "post_processors": [],
                        "assertions": [assertion_returncode, assertion_txseq]
                    }
                    tg_template["http_requests"].append(req_template)
            json_structure_guide["thread_groups"].append(tg_template)

        context_as_json_string = json.dumps(asdict(context), indent=2, ensure_ascii=False)

        # --- 3. å»ºç«‹æœ€çµ‚çš„æç¤ºè© ---
        prompt = f"""You are a precise JMeter test script architect. Your task is to populate a given JSON structure. You MUST follow all instructions meticulously.

    === YOUR TASK ===
    Based on the "STRUCTURED DATA TO USE" and "ORIGINAL REQUIREMENTS", populate the "JSON STRUCTURE GUIDE" below. You MUST NOT invent or change values unless a field is marked as "FILL_IN_...".

    === STRUCTURED DATA TO USE (from initial analysis) ===
    {context_as_json_string}

    === ORIGINAL REQUIREMENTS ===
    {context.requirements}

    === JSON STRUCTURE GUIDE & INSTRUCTIONS (YOUR BLUEPRINT) ===
    This is your blueprint. Fill it out exactly as specified.
    - **CRITICAL**: The `body` for `http_requests` is already provided and parameterized. You MUST use it AS-IS. DO NOT modify it.
    - **CRITICAL**: For fields with `${{__P(...)}}` syntax (like `num_threads`), you MUST use the provided string verbatim.
    - **CRITICAL**: For `assertions`, use the provided examples as a template. The `test_type` MUST be an integer.
    - **FORBIDDEN**: DO NOT hardcode any values in the request `body` or `assertions` that look like test data (e.g., "164783213", "ZXZTEST-123456"). All dynamic data MUST be represented as `${{variable_name}}`.
    - If a component like `global_user_defined_variables` is not needed, you MUST use an empty list `[]`.

    ```json
    {json.dumps(json_structure_guide, indent=2, ensure_ascii=False)}
    ```

    === ğŸ”¥ FINAL, NON-NEGOTIABLE INSTRUCTIONS ğŸ”¥ ===
    Your ONLY output is a single, complete, and valid JSON object based on the guide above.
    Start with {{{{ and end with }}}}.
    DO NOT include any explanations, comments, or markdown code blocks like ```json.
    """
        if attempt > 0 and validation_errors:
            error_summary = "; ".join(list(set(validation_errors))[-3:])
            prompt += f"\n\nğŸš¨ RETRY ATTEMPT #{attempt + 1}. YOUR PREVIOUS RESPONSE FAILED. REASON: {error_summary}. YOU MUST FIX THIS AND ADHERE STRICTLY TO THE BLUEPRINT."

        return prompt

    def _parse_llm_content_response(self, response: str) -> Dict:
        """
        è§£æ LLM è¿”å›çš„ JSON å…§å®¹ï¼Œå…·å‚™è‡ªå‹•ä¿®å¾©èƒ½åŠ›ã€‚
        """
        self.logger.info("--- æ­¥é©Ÿ 3 (æ–°æµç¨‹): è§£æ LLM çš„ JSON å›æ‡‰ ---")
        match = re.search(r"```json\s*(\{.*?\})\s*```", response, re.DOTALL)
        if match:
            json_str = match.group(1)
            self.logger.info("âœ… æˆåŠŸå¾ markdown å€å¡Šä¸­æå– JSONã€‚")
        else:
            match = re.search(r'\{.*\}', response, re.DOTALL)
            if not match:
                self.logger.error(f"åœ¨ LLM å›æ‡‰ä¸­æ‰¾ä¸åˆ°ä»»ä½• JSON ç‰©ä»¶ã€‚å›æ‡‰å…§å®¹: {response[:500]}...")
                raise ValueError("åœ¨ LLM å›æ‡‰ä¸­æ‰¾ä¸åˆ°æœ‰æ•ˆçš„ JSON ç‰©ä»¶ã€‚")
            json_str = match.group(0)
            self.logger.info("å¾åŸå§‹å›æ‡‰ä¸­æå–äº† JSON å­—ä¸²ï¼Œç¾åœ¨å˜—è©¦è§£æ...")

        cleaned_json_str = json_str.strip()
        try:
            return json.loads(cleaned_json_str)
        except json.JSONDecodeError as e:
            self.logger.warning(f"æ¨™æº– JSON è§£æå¤±æ•— ({e})ï¼Œå˜—è©¦è‡ªå‹•ä¿®å¾©...")
            try:
                import ast
                return ast.literal_eval(cleaned_json_str)
            except Exception as ast_e:
                self.logger.error(f"è‡ªå‹•ä¿®å¾©å¤±æ•— ({ast_e})ï¼ŒJSON å­—ä¸²æ ¼å¼åš´é‡éŒ¯èª¤ã€‚")
                raise e from None

    def _prepare_generation_context(self, requirements: str, files_data: List[Dict]) -> GenerationContext:
        """
        ã€â­ æœ€çµ‚ä¿®æ­£ç‰ˆã€‘
        é è™•ç†å‡½æ•¸ï¼šå°‡åŸå§‹è¼¸å…¥è½‰æ›ç‚ºçµæ§‹åŒ–çš„ GenerationContextï¼Œç¢ºä¿é™„ä»¶èˆ‡åŸ·è¡Œç·’ç¾¤çµ„æ­£ç¢ºç¶å®šã€‚
        """
        self.logger.info("=== æ­¥é©Ÿ 1: é–‹å§‹æº–å‚™ç”Ÿæˆä¸Šä¸‹æ–‡ (æ¡ç”¨å¥å£¯åƒæ•¸åŒ–æµç¨‹) ===")
        processed_files = self._safe_process_files(files_data)
        req_analysis = self._analyze_requirements_dynamically(requirements)

        if not req_analysis.get('thread_groups'):
            raise ValueError("éœ€æ±‚åˆ†æå¤±æ•—ï¼šç„¡æ³•å¾éœ€æ±‚ä¸­è§£æå‡ºä»»ä½• Thread Group åç¨±ã€‚")

        thread_group_contexts = []

        # å»ºç«‹å·²ä½¿ç”¨æª”æ¡ˆçš„è¿½è¹¤å™¨ï¼Œé¿å…æª”æ¡ˆè¢«é‡è¤‡åˆ†é…
        used_json_files = set()
        used_csv_files = set()

        # æŒ‰åç¨±æ’åºä»¥ç¢ºä¿åŒ¹é…çš„ç©©å®šæ€§
        all_json_files = sorted(req_analysis['json_files'])
        all_csv_files = sorted(req_analysis['csv_files'])

        for tg_name in sorted(req_analysis['thread_groups']):
            self.logger.info(f"ğŸ”„ --- æ­£åœ¨è™•ç† Thread Group: '{tg_name}' ---")

            # 1. ç‚ºç•¶å‰ Thread Group å°‹æ‰¾æœ€åŒ¹é…çš„æª”æ¡ˆ
            # ç­–ç•¥ï¼šå„ªå…ˆå°‹æ‰¾æª”ååŒ…å« Thread Group åç¨±çš„æª”æ¡ˆï¼Œå…¶æ¬¡æŒ‰é †åºåˆ†é…æœªä½¿ç”¨çš„æª”æ¡ˆ

            json_filename = next((f for f in all_json_files if tg_name in f and f not in used_json_files), None)
            if not json_filename:
                json_filename = next((f for f in all_json_files if f not in used_json_files), None)

            csv_filename = next((f for f in all_csv_files if tg_name in f and f not in used_csv_files), None)
            if not csv_filename:
                csv_filename = next((f for f in all_csv_files if f not in used_csv_files), None)

            if json_filename: used_json_files.add(json_filename)
            if csv_filename: used_csv_files.add(csv_filename)

            http_req_name = next((r for r in req_analysis['http_requests'] if r == tg_name), tg_name)
            self.logger.info(f"ç‚º '{tg_name}' åŒ¹é…åˆ°çš„æª”æ¡ˆ -> JSON: '{json_filename}', CSV: '{csv_filename}'")

            # 2. ç²å–æª”æ¡ˆå…§å®¹
            json_info = processed_files['json_contents'].get(json_filename) if json_filename else None
            original_json_body = json_info.get('raw_content') if json_info else None
            csv_config_data = next(
                (c for c in processed_files.get('csv_configs', []) if c.get('filename') == csv_filename),
                None) if csv_filename else None

            # 3. åŸ·è¡Œåƒæ•¸åŒ–
            final_json_body, csv_info_obj, is_parameterized = original_json_body, None, False
            if original_json_body and csv_config_data:
                self.logger.info(f"âœ… ç‚º '{tg_name}' æ‰¾åˆ°åŒ¹é…çš„ JSON/CSVï¼Œé–‹å§‹åƒæ•¸åŒ–ã€‚")
                csv_info_obj = CsvInfo(
                    filename=csv_filename,
                    variable_names=csv_config_data.get('variable_names', []),
                    total_rows=csv_config_data.get('total_rows', 0),
                    raw_content=csv_config_data.get('raw_content')
                )
                final_json_body = self._parameterize_json_body(original_json_body, csv_info_obj)
                is_parameterized = True
            else:
                self.logger.warning(f"âš ï¸ ç‚º '{tg_name}' æœªèƒ½æ‰¾åˆ°å®Œæ•´çš„ JSON/CSV é…å°ï¼Œå°‡è·³éåƒæ•¸åŒ–ã€‚")

            # 4. å»ºç«‹çµæ§‹åŒ–ç‰©ä»¶
            http_req_info = HttpRequestInfo(name=http_req_name, json_body=final_json_body,
                                            source_json_filename=json_filename, is_parameterized=is_parameterized)
            tg_context = ThreadGroupContext(name=tg_name)
            tg_context.http_requests.append(http_req_info)
            if csv_info_obj:
                tg_context.csv_configs.append(csv_info_obj)
            thread_group_contexts.append(tg_context)
            self.logger.info(f"âœ… --- Thread Group '{tg_name}' è™•ç†å®Œæˆ ---")

        return GenerationContext(
            test_plan_name=req_analysis.get('test_plan_name', 'Generated Test Plan'),
            thread_groups=thread_group_contexts,
            requirements=requirements,
            raw_processed_files=processed_files
        )

    def _assess_requirements_complexity(self, requirements: str) -> int:
        """è©•ä¼°éœ€æ±‚è¤‡é›œåº¦ï¼ˆé¿å…æ–°å¢å‡½å¼ï¼Œå…§åµŒé‚è¼¯ï¼‰"""
        score = 0

        # åŸºæœ¬è¤‡é›œåº¦æŒ‡æ¨™
        if len(requirements) > 500:
            score += 2
        if requirements.count('Thread Group') > 1:
            score += 2
        if 'Header Manager' in requirements:
            score += 1
        if 'CSV Data Set' in requirements:
            score += 1
        if 'Response Assertion' in requirements:
            score += 1
        if 'POST' in requirements.upper():
            score += 1
        if '${' in requirements:  # åŒ…å«è®Šæ•¸
            score += 2

        return min(score, 10)

    def _count_jmx_components(self, jmx_content: str) -> int:
        """è¨ˆç®— JMX å…§å®¹ä¸­çš„çµ„ä»¶æ•¸é‡"""
        import re

        # å®šç¾©ä¸»è¦çµ„ä»¶çš„æ¨¡å¼
        component_patterns = [
            r'<TestPlan\s+',  # TestPlan
            r'<HeaderManager\s+',  # Header Manager
            r'<ThreadGroup\s+',  # Thread Group
            r'<HTTPSamplerProxy\s+',  # HTTP Request
            r'<CSVDataSet\s+',  # CSV Data Set Config
            r'<ResponseAssertion\s+',  # Response Assertion
            r'<ResultCollector\s+.*testclass="ResultCollector"',  # View Results Tree
        ]

        total_count = 0
        for pattern in component_patterns:
            matches = re.findall(pattern, jmx_content, re.IGNORECASE)
            total_count += len(matches)

        return total_count

    def _safe_process_files(self, files_data: List[Dict] = None) -> Dict:
        """å®‰å…¨åœ°è™•ç†æª”æ¡ˆè³‡æ–™"""
        try:
            if not files_data:
                self.logger.warning("æ²’æœ‰å‚³å…¥ä»»ä½•æª”æ¡ˆè³‡æ–™")
                return {"csv_configs": [], "json_contents": {}}

            self.logger.info(f"é–‹å§‹è™•ç† {len(files_data)} å€‹æª”æ¡ˆ")

            # å¾ _process_csv_files ç²å–çš„æ˜¯å­—å…¸ï¼Œkey æ˜¯æª”å
            csv_configs_dict = self._process_csv_files(files_data)
            json_contents = self._process_json_files(files_data)

            self.logger.info(f"JSON è™•ç†çµæœ: {list(json_contents.keys())}")

            # å°‡ CSV configs å­—å…¸è½‰æ›ç‚ºåˆ—è¡¨æ ¼å¼ï¼Œä¸¦ç¢ºä¿åŒ…å« raw_content
            csv_configs_list = []
            for filename, config in csv_configs_dict.items():
                if config and 'error' not in config:
                    # ç¢ºä¿æˆ‘å€‘å¾ _safe_process_single_csv è¿”å›çš„æ‰€æœ‰é‡è¦è³‡è¨Šéƒ½è¢«åŒ…å«
                    csv_configs_list.append({
                        'filename': filename,
                        'variable_names': config.get('headers', []),
                        'total_rows': config.get('total_rows', 0),
                        'filepath': config.get('filepath', filename),
                        'raw_content': config.get('raw_content', '')  # ç¢ºä¿ raw_content è¢«å‚³é
                    })
                    self.logger.info(
                        f"ç‚ºåˆ—è¡¨æ·»åŠ  CSV è¨­å®š: '{filename}', è®Šæ•¸: {config.get('headers', [])}, raw_content é•·åº¦: {len(config.get('raw_content', ''))}")
                else:
                    self.logger.warning(f"è·³éæœ‰å•é¡Œçš„ CSV è¨­å®š: {filename}")

            result = {"csv_configs": csv_configs_list, "json_contents": json_contents}
            self.logger.info(f"æª”æ¡ˆè™•ç†å®Œæˆ - CSV: {len(csv_configs_list)}, JSON: {len(json_contents)}")
            return result

        except Exception as e:
            self.logger.error(f"æª”æ¡ˆè™•ç†å¤±æ•—: {e}", exc_info=True)
            return {"csv_configs": [], "json_contents": {}}

    def _analyze_requirements_dynamically(self, requirements: str) -> Dict:
        """
        ã€â­ æœ€çµ‚ä¿®æ­£ç‰ˆ v2ã€‘å‹•æ…‹åˆ†æéœ€æ±‚ï¼Œæå–é—œéµè³‡è¨Šã€‚
        - æ”¾å¯¬äº† Test Plan åç¨±çš„æå–è¦å‰‡ã€‚
        """
        analysis = {
            'test_plan_name': '',
            'thread_groups': [],
            'http_requests': [],
            'json_files': [],
            'csv_files': []
        }

        # â­ã€é—œéµä¿®æ­£ã€‘ä½¿ç”¨æ›´å¯¬é¬†ã€æ›´ç©©å¥çš„æ­£å‰‡è¡¨é”å¼ä¾†æå– Test Plan åç¨±ã€‚
        # é€™å¯ä»¥åŒ¹é… "åœ¨ã€æ¸¬è©¦è¨ˆç•«ã€ä¸­ï¼Œåç¨±..." ç­‰æ›´å¤šæ¨£çš„å¥å¼ã€‚
        match = re.search(r'æ¸¬è©¦è¨ˆç•«.*?åç¨±.*?[ã€ã€Œ]([^ã€ã€]+)[ã€ã€]', requirements)
        if match:
            analysis['test_plan_name'] = match.group(1).strip()
        else:
            # å¦‚æœæ‰¾ä¸åˆ°ï¼Œå¯ä»¥è¨­ç½®ä¸€å€‹é è¨­å€¼æˆ–è¨˜éŒ„è­¦å‘Š
            self.logger.warning("åœ¨éœ€æ±‚æ–‡ä»¶ä¸­æœªèƒ½æå–åˆ° 'æ¸¬è©¦è¨ˆç•«åç¨±'ï¼Œå°‡ä½¿ç”¨é è¨­å€¼ã€‚")
            analysis['test_plan_name'] = 'Generated Test Plan'

        # æå–æ‰€æœ‰ç¬¦åˆç‰¹å®šæ¨¡å¼çš„åç¨±
        potential_names = re.findall(r'\b[A-Z]{2,}[-C][-A-Z0-9]+\b', requirements)

        # åˆ†é¡ Thread Group å’Œ HTTP Request
        tg_lines = [line for line in requirements.split('\n') if 'thread group' in line.lower() or 'åŸ·è¡Œç·’ç¾¤çµ„' in line]
        for line in tg_lines:
            names_in_line = re.findall(r'\b[A-Z]{2,}[-C][-A-Z0-9]+\b', line)
            analysis['thread_groups'].extend(names_in_line)

        http_lines = [line for line in requirements.split('\n') if
                      'http request' in line.lower() or 'http è«‹æ±‚' in line]
        for line in http_lines:
            names_in_line = re.findall(r'\b[A-Z]{2,}[-C][-A-Z0-9]+\b', line)
            analysis['http_requests'].extend(names_in_line)

        # å¦‚æœæŒ‰è¡Œåˆ†é¡å¤±æ•—ï¼Œå‰‡å°‡æ‰€æœ‰æ‰¾åˆ°çš„åç¨±éƒ½è¦–ç‚ºå…©è€…
        if not analysis['thread_groups']: analysis['thread_groups'] = potential_names
        if not analysis['http_requests']: analysis['http_requests'] = potential_names

        # æå–é™„ä»¶æª”å
        analysis['json_files'] = re.findall(r'([A-Z0-9_-]+\.json)', requirements, re.IGNORECASE)
        analysis['csv_files'] = re.findall(r'([A-Z0-9_-]+\.csv)', requirements, re.IGNORECASE)

        # æ¸…ç†å’Œå»é‡
        for key in analysis:
            if isinstance(analysis[key], list):
                analysis[key] = sorted(list(set(analysis[key])))

        self.logger.info(f"éœ€æ±‚åˆ†æçµæœ (v2): {analysis}")
        return analysis

    def _build_prompt(self, context: GenerationContext, attempt: int = 0, validation_errors: List[str] = None) -> str:
        """ å»ºç«‹æç¤ºè© """
        self.logger.info("=== æ­¥é©Ÿ 2: å»ºç«‹æç¤ºè© ===")

        base_prompt = f"""You are an expert JMeter test script generator...
        === Original Requirements ===
        {context.requirements}
        """

        base_prompt += "\n=== Structured Test Plan Information ===\n"
        base_prompt += f"Test Plan Name: {context.test_plan_name}\n"

        for tg_context in context.thread_groups:
            # âœ… è®Šæ›´ 1: ä½¿ç”¨æ›´å¼·çƒˆã€æ›´æ˜é¡¯çš„åˆ†éš”ç¬¦ï¼Œç‚ºæ¯å€‹ Thread Group å»ºç«‹ç¨ç«‹çš„æŒ‡ä»¤ä¸Šä¸‹æ–‡ã€Œç‰†ã€ã€‚
            base_prompt += f"\n\n==================================================\n"
            base_prompt += f"=== INSTRUCTIONS FOR THREAD GROUP: '{tg_context.name}' ===\n"
            base_prompt += f"==================================================\n"

            if tg_context.http_requests:
                for http_req in tg_context.http_requests:
                    base_prompt += f"\n  - HTTP Request Name: {http_req.name}\n"
                    if http_req.json_body:
                        escaped_json = http_req.json_body.replace('&', '&amp;').replace('<', '&lt;').replace('>',
                                                                                                             '&gt;').replace(
                            '"', '&quot;')
                        base_prompt += f"    Source JSON: {http_req.source_json_filename}\n"
                        base_prompt += f"""    ğŸ¯ CRITICAL: Use the following full JSON content for the body:
        ```json
        {http_req.json_body}
        ```
        And format it in XML as:
        <stringProp name="Argument.value">{escaped_json}</stringProp>
        """
                    else:
                        base_prompt += "    âŒ WARNING: No JSON body found for this request.\n"

            if tg_context.csv_configs:
                for csv_config in tg_context.csv_configs:
                    base_prompt += f"\n  - CSV Data Set Config for THIS Thread Group:\n"
                    base_prompt += f"    Filename: {csv_config.filename}\n"

                    # âœ… è®Šæ›´ 2: å°‡é™³è¿°å¥æ”¹ç‚ºå¼·åˆ¶å‘½ä»¤ï¼Œä¸¦æ˜ç¢ºæŒ‡å‡ºæ­¤å‘½ä»¤åƒ…é©ç”¨æ–¼ç•¶å‰çš„ Thread Groupã€‚
                    # é€™èƒ½æœ‰æ•ˆé˜²æ­¢ LLM å°‡ç¬¬ä¸€å€‹ Thread Group çš„è®Šæ•¸å¥—ç”¨åˆ°ç¬¬äºŒå€‹ã€‚
                    base_prompt += f"    ğŸ¯ MANDATORY: For the CSVDataSet inside the '{tg_context.name}' Thread Group, you MUST use these exact variable names:\n"
                    base_prompt += f"    Variable Names: {','.join(csv_config.variable_names)}\n"

                    # âœ… è®Šæ›´ 3: å¢åŠ ä¸€å€‹æ˜ç¢ºçš„æŒ‡ä»¤ä¾†è¨­å®š ignoreFirstLineï¼Œä½œç‚ºé›™é‡ä¿éšªã€‚
                    base_prompt += f"    You MUST also set 'ignoreFirstLine' to 'true' for this CSV config.\n"
            else:
                base_prompt += "\n  - No associated CSV file found for this group.\n"

        if attempt > 0 and validation_errors:
            error_summary = "; ".join(list(set(validation_errors))[-3:])
            base_prompt += f"\nğŸš¨ RETRY ATTEMPT #{attempt + 1} - YOU FAILED PREVIOUSLY. YOU MUST FIX THESE ERRORS: {error_summary}\n"

        base_prompt += """
        === ğŸ”¥ FINAL, NON-NEGOTIABLE INSTRUCTIONS ğŸ”¥ ===
        1.  Generate the complete JMX file based on all the structured information and requirements provided above.
        2.  Pay extreme attention to correct XML structure, especially matching all opening and closing tags like <hashTree> and </hashTree>.
        3.  CRITICAL: Your entire response MUST be ONLY the XML content of the JMX file.
            - Start directly with `<?xml version="1.0" encoding="UTF-8"?>`.
            - End directly with `</jmeterTestPlan>`.
            - DO NOT include any explanations, comments, or markdown code blocks like ```xml.
        """

        self.logger.info(f"æç¤ºè©å»ºç«‹å®Œæˆï¼Œç¸½é•·åº¦: {len(base_prompt)}")
        return base_prompt

    def _validate_jmx_content_requirements(self, jmx_content: str, context: 'GenerationContext') -> Tuple[bool, str]:
        """
        é©—è­‰ JMX å…§å®¹æ˜¯å¦ç¬¦åˆéœ€æ±‚
        """
        errors = []

        try:
            # 1. æª¢æŸ¥ Body Data æ ¼å¼ (é€™éƒ¨åˆ†é‚è¼¯ä¸è®Š)
            if 'HTTPsampler.BodyData' in jmx_content and 'elementType="ElementProp"' in jmx_content:
                errors.append("ç™¼ç¾éŒ¯èª¤çš„ Body Data æ ¼å¼ï¼ˆHTTPsampler.BodyDataï¼‰ï¼Œæ‡‰ä½¿ç”¨ Arguments çµæ§‹")

            # 2. æª¢æŸ¥ HTTP Request Body Data å…§å®¹å®Œæ•´æ€§
            correct_body_pattern = r'<stringProp name="Argument\.value">(.*?)</stringProp>'
            body_matches = re.findall(correct_body_pattern, jmx_content, re.DOTALL)

            # æª¢æŸ¥æ˜¯å¦æœ‰ POST è«‹æ±‚ï¼Œä½†å®Œå…¨æ²’æœ‰ Body
            # æˆ‘å€‘å¯ä»¥å¾ context å¾—çŸ¥é æœŸæœ‰å¤šå°‘å€‹ HTTP Request
            expected_http_requests = sum(len(tg.http_requests) for tg in context.thread_groups)

            if expected_http_requests > 0 and not body_matches:
                # åƒ…ç•¶ JMX ä¸­ç¢ºå¯¦å­˜åœ¨ POST æ–¹æ³•çš„ Sampler æ™‚æ‰å ±éŒ¯
                if '<stringProp name="HTTPSampler.method">POST</stringProp>' in jmx_content:
                    errors.append("POST è«‹æ±‚ç¼ºå°‘ Body Data å…§å®¹")
            else:
                for i, body_content in enumerate(body_matches, 1):
                    clean_body = body_content.strip()
                    if not clean_body or clean_body.lower() == 'none':
                        errors.append(f"HTTP Request #{i} Body Data ç‚ºç©ºæˆ–ç‚º 'None'")
                    elif len(clean_body) < 10:
                        errors.append(f"HTTP Request #{i} Body Data å…§å®¹éçŸ­ï¼Œå¯èƒ½ä¸å®Œæ•´")

            # 3. ä½¿ç”¨ context é©—è­‰çµ„ä»¶æ˜¯å¦å­˜åœ¨
            # æª¢æŸ¥ Thread Group
            if context.thread_groups and '<ThreadGroup' not in jmx_content:
                errors.append("éœ€æ±‚ä¸­æåˆ° Thread Group ä½† JMX ä¸­æ‰¾ä¸åˆ°")

            # æª¢æŸ¥ HTTP Request
            if expected_http_requests > 0 and '<HTTPSamplerProxy' not in jmx_content:
                errors.append("éœ€æ±‚ä¸­æåˆ° HTTP Request ä½† JMX ä¸­æ‰¾ä¸åˆ°")

            # æª¢æŸ¥ CSV
            expected_csv_configs = sum(len(tg.csv_configs) for tg in context.thread_groups)
            if expected_csv_configs > 0 and '<CSVDataSet' not in jmx_content:
                errors.append("æœ‰æä¾› CSV æª”æ¡ˆä½† JMX ä¸­æ‰¾ä¸åˆ° CSV Data Set Config")

            # 4. æª¢æŸ¥ hashTree æ¨™ç±¤æ˜¯å¦åŒ¹é… (é€™éƒ¨åˆ†é‚è¼¯ä¸è®Š)
            open_hashtree = jmx_content.count('<hashTree>')
            close_hashtree = jmx_content.count('</hashTree>')
            if open_hashtree != close_hashtree:
                errors.append(f"hashTree æ¨™ç±¤ä¸åŒ¹é… (é–‹å§‹: {open_hashtree}, çµæŸ: {close_hashtree})")

        except Exception as e:
            # æ•ç²é©—è­‰éç¨‹ä¸­çš„ä»»ä½•å…¶ä»–ç¨‹å¼ç¢¼éŒ¯èª¤
            self.logger.error(f"å…§å®¹é©—è­‰å‡½æ•¸å…§éƒ¨ç™¼ç”ŸéŒ¯èª¤: {e}", exc_info=True)
            errors.append(f"é©—è­‰éç¨‹ç™¼ç”Ÿå…§éƒ¨éŒ¯èª¤: {str(e)}")

        if errors:
            return False, "; ".join(errors)
        else:
            return True, "å…§å®¹é©—è­‰é€šé"

    def _format_csv_info_safe(self, csv_configs: Dict) -> str:
        """é€šç”¨æ ¼å¼åŒ– CSV è³‡è¨Š"""
        if not csv_configs:
            return "ç„¡å¯ç”¨çš„ CSV æª”æ¡ˆ\n"

        formatted_info = ""
        for filename, config in csv_configs.items():
            if 'error' in config:
                formatted_info += f"æª”æ¡ˆ: {filename} (éŒ¯èª¤: {config['error']})\n"
                continue

            formatted_info += f"æª”æ¡ˆåç¨±: {filename}\n"
            formatted_info += f"è®Šæ•¸åç¨±: {','.join(config.get('headers', []))}\n"
            formatted_info += f"ç¸½è¡Œæ•¸: {config.get('total_rows', 0)}\n"

            # é¡¯ç¤ºæ¨£æœ¬è³‡æ–™
            sample_data = config.get('sample_data', [])
            if sample_data:
                formatted_info += "æ¨£æœ¬è³‡æ–™:\n"
                for i, row in enumerate(sample_data[:3], 1):
                    formatted_info += f"  ç¬¬{i}è¡Œ: {dict(zip(config.get('headers', []), row))}\n"

            formatted_info += "---\n"

        return formatted_info

    def _extract_and_clean_jmx(self, response: str, context: GenerationContext) -> str:
        """
        æå–ã€æ¸…ç†ä¸¦æ™ºèƒ½ä¿®æ­£ JMX å…§å®¹ - é‡æ§‹å¾Œä½¿ç”¨ GenerationContextã€‚
        """
        self.logger.info("=== æ­¥é©Ÿ 4: æå–ã€æ¸…ç†èˆ‡ä¿®æ­£ JMX ===")
        jmx_content = self._extract_jmx_from_response(response)
        cleaned_content = self._clean_xml_declarations(jmx_content)
        fixed_content = self._fix_testplan_structure(cleaned_content)
        body_fixed_content = self._fix_body_data_format(fixed_content)

        # ã€æ ¸å¿ƒä¿®æ”¹ã€‘æ™ºèƒ½ä¿®æ­£ CSV è¨­å®šç¾åœ¨å‚³å…¥ context
        csv_fixed_content = self._intelligently_fix_csv_settings(body_fixed_content, context)

        final_content = self._fix_basic_xml_issues(csv_fixed_content)
        return final_content

    def _intelligently_fix_csv_settings(self, jmx_content: str, context: GenerationContext) -> str:
        """
        æ™ºèƒ½æ ¡é©—ä¸¦ä¿®æ­£ JMX ä¸­çš„ CSV Data Set Config è¨­å®šã€‚
        ç¾åœ¨æœƒå¼·åˆ¶å°‡æ‰€æœ‰è¢«ç”¨æ–¼åƒæ•¸åŒ–çš„ CSV çš„ ignoreFirstLine è¨­ç‚º trueã€‚
        """
        try:
            self.logger.info("====== é–‹å§‹æ™ºèƒ½ä¿®æ­£ CSV è¨­å®š ======")

            # æ‰¾å‡ºæ‰€æœ‰åœ¨ context ä¸­è¢«ç”¨æ–¼åƒæ•¸åŒ–çš„ CSV æª”æ¡ˆåç¨±
            parameterized_csv_files = set()
            for tg in context.thread_groups:
                for req in tg.http_requests:
                    if req.is_parameterized:
                        for csv_conf in tg.csv_configs:
                            parameterized_csv_files.add(csv_conf.filename)

            if not parameterized_csv_files:
                self.logger.info("ä¸Šä¸‹æ–‡ä¸­ç„¡åƒæ•¸åŒ–çš„ CSV è³‡è¨Šï¼Œè·³éä¿®æ­£ã€‚")
                return jmx_content

            self.logger.info(f"éœ€è¦å¼·åˆ¶ä¿®æ­£ ignoreFirstLine=true çš„ CSV æª”æ¡ˆ: {parameterized_csv_files}")

            csv_dataset_pattern = re.compile(r'(<CSVDataSet.*?>.*?</CSVDataSet>)', re.DOTALL)
            modified_content = jmx_content

            # ä½¿ç”¨ re.sub çš„ callback å‡½å¼ä¾†é€²è¡Œæ›¿æ›ï¼Œæ›´å®‰å…¨
            def replace_callback(match):
                csv_block = match.group(1)
                filename_match = re.search(r'<stringProp name="filename">(.*?)</stringProp>', csv_block)

                if filename_match:
                    csv_filename = filename_match.group(1)
                    # å¦‚æœé€™å€‹ CSV æª”æ¡ˆåœ¨æˆ‘å€‘çš„å¾…ä¿®æ­£åˆ—è¡¨ä¸­
                    if csv_filename in parameterized_csv_files:
                        # æª¢æŸ¥ä¸¦å¼·åˆ¶ä¿®æ­£ ignoreFirstLine
                        if '<boolProp name="ignoreFirstLine">false</boolProp>' in csv_block:
                            self.logger.warning(f"åµæ¸¬åˆ°é‚è¼¯çŸ›ç›¾ï¼å¼·åˆ¶ä¿®æ­£ '{csv_filename}' çš„ ignoreFirstLine ç‚º trueã€‚")
                            return csv_block.replace(
                                '<boolProp name="ignoreFirstLine">false</boolProp>',
                                '<boolProp name="ignoreFirstLine">true</boolProp>'
                            )
                # å¦‚æœä¸éœ€ä¿®æ”¹ï¼Œè¿”å›åŸå§‹å€å¡Š
                return csv_block

            modified_content = csv_dataset_pattern.sub(replace_callback, jmx_content)

            self.logger.info("====== æ™ºèƒ½ä¿®æ­£ CSV è¨­å®šçµæŸ ======")
            return modified_content

        except Exception as e:
            self.logger.error(f"æ™ºèƒ½ä¿®æ­£ CSV è¨­å®šæ™‚ç™¼ç”Ÿåš´é‡éŒ¯èª¤: {e}", exc_info=True)
            return jmx_content

    def _fix_testplan_structure(self, content: str) -> str:
        """ä¿®å¾© TestPlan çµæ§‹ä¸­çš„å¸¸è¦‹å•é¡Œ"""
        try:
            # ä¿®å¾© TestPlan.user_define_classpath çš„ elementType
            pattern = r'<elementProp name="TestPlan\.user_define_classpath" elementType="collectionProp">'
            replacement = '<elementProp name="TestPlan.user_define_classpath" elementType="Arguments" guiclass="ArgumentsPanel" testclass="Arguments" enabled="true">'
            content = re.sub(pattern, replacement, content)

            # ä¿®å¾©å°æ‡‰çš„ collectionProp çµæ§‹
            pattern = r'<collectionProp name="TestPlan\.user_define_classpath"/>'
            replacement = '<collectionProp name="Arguments.arguments"/>'
            content = re.sub(pattern, replacement, content)

            self.logger.info("TestPlan çµæ§‹ä¿®å¾©å®Œæˆ")
            return content

        except Exception as e:
            self.logger.error(f"ä¿®å¾© TestPlan çµæ§‹å¤±æ•—: {e}")
            return content

    def _fix_body_data_format(self, content: str) -> str:
        """ä¿®æ­£ HTTP Request Body Data æ ¼å¼"""
        try:
            import re

            # æŸ¥æ‰¾éŒ¯èª¤çš„ Body Data æ ¼å¼
            wrong_pattern = r'<elementProp name="HTTPsampler\.BodyData" elementType="ElementProp">(.*?)</elementProp>'
            matches = re.findall(wrong_pattern, content, re.DOTALL)

            if not matches:
                self.logger.info("æœªç™¼ç¾éœ€è¦ä¿®æ­£çš„ Body Data æ ¼å¼")
                return content

            self.logger.info(f"ç™¼ç¾ {len(matches)} å€‹éœ€è¦ä¿®æ­£çš„ Body Data æ ¼å¼")

            # é€å€‹ä¿®æ­£æ¯å€‹éŒ¯èª¤æ ¼å¼
            fixed_content = content
            for i, match_content in enumerate(matches):
                # æå– Body Data çš„å€¼
                value_pattern = r'<stringProp name="ElementProp\.value">(.*?)</stringProp>'
                value_matches = re.findall(value_pattern, match_content, re.DOTALL)

                if value_matches:
                    body_value = value_matches[0]

                    # æ§‹å»ºæ­£ç¢ºçš„æ ¼å¼
                    correct_format = f"""<boolProp name="HTTPSampler.postBodyRaw">true</boolProp>
      <elementProp name="HTTPsampler.Arguments" elementType="Arguments">
        <collectionProp name="Arguments.arguments">
          <elementProp name="" elementType="HTTPArgument">
            <boolProp name="HTTPArgument.always_encode">false</boolProp>
            <stringProp name="Argument.value">{body_value}</stringProp>
            <stringProp name="Argument.metadata">=</stringProp>
          </elementProp>
        </collectionProp>
      </elementProp>"""

                    # æ›¿æ›éŒ¯èª¤æ ¼å¼
                    wrong_full_pattern = r'<elementProp name="HTTPsampler\.BodyData" elementType="ElementProp">.*?</elementProp>'
                    fixed_content = re.sub(wrong_full_pattern, correct_format, fixed_content, count=1, flags=re.DOTALL)

                    self.logger.info(f"å·²ä¿®æ­£ç¬¬ {i + 1} å€‹ Body Data æ ¼å¼")

            return fixed_content

        except Exception as e:
            self.logger.error(f"ä¿®æ­£ Body Data æ ¼å¼å¤±æ•—: {e}")
            return content

    def _process_csv_files(self, files_data: List[Dict]) -> Dict[str, Dict]:
        """
        è™•ç†æ‰€æœ‰ä¸Šå‚³çš„ CSV æª”æ¡ˆã€‚
        æ­¤å‡½æ•¸è¿­ä»£æ‰€æœ‰å‚³å…¥çš„æª”æ¡ˆè³‡æ–™ï¼Œç¯©é¸å‡º CSV æª”æ¡ˆï¼Œ
        ä¸¦å‘¼å« _safe_process_single_csv é€²è¡Œå–®ä¸€æª”æ¡ˆçš„è§£æã€‚
        Args:
            files_data: ä¸€å€‹æª”æ¡ˆå­—å…¸çš„åˆ—è¡¨ï¼Œæ¯å€‹å­—å…¸ä»£è¡¨ä¸€å€‹ä¸Šå‚³çš„æª”æ¡ˆã€‚

        Returns:
            ä¸€å€‹å­—å…¸ï¼Œå…¶ä¸­ï¼š
            - Key æ˜¯ CSV æª”æ¡ˆçš„åç¨± (e.g., "MOCK-B-CHECKIDC001.csv")ã€‚
            - Value æ˜¯ _safe_process_single_csv è¿”å›çš„è©³ç´°è³‡è¨Šå­—å…¸ã€‚
        """
        csv_configs = {}
        if not files_data:
            self.logger.warning("æ²’æœ‰å‚³å…¥ä»»ä½•æª”æ¡ˆè³‡æ–™ï¼Œç„¡æ³•è™•ç† CSV æª”æ¡ˆã€‚")
            return csv_configs

        self.logger.info(f"é–‹å§‹è™•ç† {len(files_data)} å€‹æª”æ¡ˆä¸­çš„ CSV æª”æ¡ˆ...")
        for file_info in files_data:
            try:
                # å…¼å®¹ä¸åŒå‰ç«¯å‚³å…¥çš„æª”å key
                filename = file_info.get('filename', file_info.get('name', ''))
                if not filename or not filename.lower().endswith('.csv'):
                    continue

                self.logger.info(f"ç™¼ç¾ CSV æª”æ¡ˆ: '{filename}'ï¼Œé€²è¡Œè§£æ...")
                config = self._safe_process_single_csv(file_info)
                if config:
                    # ä½¿ç”¨æª”åä½œç‚º keyï¼Œæ–¹ä¾¿å¾ŒçºŒå¿«é€ŸæŸ¥æ‰¾
                    csv_configs[filename] = config
                else:
                    self.logger.warning(f"æª”æ¡ˆ '{filename}' è§£æå¤±æ•—æˆ–ç‚ºç©ºï¼Œå·²è·³éã€‚")

            except Exception as e:
                # æ•ç²è¿´åœˆä¸­çš„æ„å¤–éŒ¯èª¤ï¼Œç¢ºä¿ä¸€å€‹æª”æ¡ˆçš„å¤±æ•—ä¸æœƒå½±éŸ¿å…¶ä»–æª”æ¡ˆ
                filename_for_log = file_info.get('filename', 'æœªçŸ¥æª”æ¡ˆ')
                self.logger.error(f"è™•ç†æª”æ¡ˆ '{filename_for_log}' æ™‚ç™¼ç”Ÿæœªé æœŸéŒ¯èª¤: {e}", exc_info=True)

        self.logger.info(f"CSV æª”æ¡ˆè™•ç†å®Œæˆï¼Œå…±æˆåŠŸè§£æ {len(csv_configs)} å€‹æª”æ¡ˆã€‚")
        return csv_configs

    def _safe_process_single_csv(self, file_info: Dict) -> Optional[Dict]:
        """
        å®‰å…¨ä¸”å¥å£¯åœ°è™•ç†å–®ä¸€ CSV æª”æ¡ˆçš„å…§å®¹ã€‚

        æ­¤å‡½æ•¸ä½¿ç”¨æ¨™æº–çš„ `io` å’Œ `csv` æ¨¡çµ„ï¼Œå°‡æª”æ¡ˆå…§å®¹å­—ä¸²è½‰æ›ç‚º
        çµæ§‹åŒ–çš„è³‡è¨Šï¼ŒåŒ…æ‹¬æ¨™é ­ã€è³‡æ–™è¡Œæ•¸å’ŒåŸå§‹å…§å®¹ã€‚

        Args:
            file_info: ä»£è¡¨å–®ä¸€æª”æ¡ˆçš„å­—å…¸ã€‚

        Returns:
            ä¸€å€‹åŒ…å« CSV è©³ç´°è³‡è¨Šçš„å­—å…¸ï¼Œå¦‚æœè™•ç†å¤±æ•—å‰‡è¿”å› Noneã€‚
            æˆåŠŸæ™‚è¿”å›çš„å­—å…¸çµæ§‹ï¼š
            {
                'headers': List[str],      # æ¸…ç†éçš„æ¨™é ­åˆ—è¡¨
                'sample_data': List[List[str]], # æœ€å¤š 5 è¡Œçš„æ¨£æœ¬è³‡æ–™
                'total_rows': int,         # è³‡æ–™è¡Œçš„ç¸½æ•¸ (ä¸å«æ¨™é ­)
                'filepath': str,           # æª”æ¡ˆè·¯å¾‘/åç¨±
                'raw_content': str         # æœªç¶“ä¿®æ”¹çš„åŸå§‹æª”æ¡ˆå…§å®¹å­—ä¸²
            }
        """
        filename = file_info.get('filename', file_info.get('name', 'unknown.csv'))

        try:
            # å¾å¤šå€‹å¯èƒ½çš„ key ä¸­ç²å–æª”æ¡ˆå…§å®¹å­—ä¸²
            content_str = ''
            if 'content' in file_info and isinstance(file_info['content'], str):
                content_str = file_info['content']
            elif 'data' in file_info and isinstance(file_info['data'], str):
                content_str = file_info['data']

            if not content_str or not content_str.strip():
                self.logger.warning(f"CSV æª”æ¡ˆ '{filename}' å…§å®¹ç‚ºç©ºã€‚")
                return None

            # ä½¿ç”¨ io.StringIO å°‡å­—ä¸²å…§å®¹æ¨¡æ“¬æˆä¸€å€‹æª”æ¡ˆï¼Œä»¥ä¾¿ csv æ¨¡çµ„å¯ä»¥è®€å–
            file_stream = io.StringIO(content_str)

            # ä½¿ç”¨ csv.reader é€²è¡Œè§£æï¼Œé€™æ˜¯è™•ç† CSV çš„æ¨™æº–åšæ³•
            csv_reader = csv.reader(file_stream)

            # è®€å–ç¬¬ä¸€è¡Œä½œç‚ºæ¨™é ­
            try:
                headers = next(csv_reader)
                # æ¸…ç†æ¨™é ­ï¼Œå»é™¤å‰å¾Œç©ºæ ¼å’Œç©ºå­—ä¸²
                cleaned_headers = [h.strip() for h in headers if h and h.strip()]
            except StopIteration:
                # æª”æ¡ˆç‚ºç©ºï¼Œæ²’æœ‰ä»»ä½•è¡Œ
                self.logger.warning(f"CSV æª”æ¡ˆ '{filename}' ç‚ºç©ºï¼Œç„¡æ³•è®€å–æ¨™é ­ã€‚")
                return {
                    'headers': [], 'sample_data': [], 'total_rows': 0,
                    'filepath': filename, 'raw_content': content_str
                }

            # è®€å–å‰©é¤˜çš„æ‰€æœ‰è³‡æ–™è¡Œ
            data_rows = list(csv_reader)
            total_data_rows = len(data_rows)

            # æå–æœ€å¤š 5 è¡Œä½œç‚ºæ¨£æœ¬è³‡æ–™
            sample_data = data_rows[:5]

            self.logger.info(
                f"âœ… CSV è§£ææˆåŠŸ: '{filename}' -> æ¨™é ­: {cleaned_headers}, è³‡æ–™è¡Œæ•¸: {total_data_rows}"
            )

            return {
                'headers': cleaned_headers,
                'sample_data': sample_data,
                'total_rows': total_data_rows,
                'filepath': filename,
                'raw_content': content_str  # åŒ…å«åŸå§‹å…§å®¹ï¼Œç”¨æ–¼å¾ŒçºŒé‚è¼¯åˆ¤æ–·
            }

        except csv.Error as e:
            self.logger.error(f"è§£æ CSV æª”æ¡ˆ '{filename}' æ™‚ç™¼ç”Ÿæ ¼å¼éŒ¯èª¤: {e}")
            return None
        except Exception as e:
            self.logger.error(f"è™•ç†å–®ä¸€ CSV æª”æ¡ˆ '{filename}' æ™‚ç™¼ç”Ÿæœªé æœŸéŒ¯èª¤: {e}", exc_info=True)
            return None

    def _clean_csv_header(self, header: str) -> str:
        """æ¸…ç† CSV æ¨™é ­"""
        if not header or str(header).lower() in ['nan', 'null', 'none', '']:
            return ''
        return str(header).strip().strip('"').strip("'")

    def _clean_csv_value(self, value: str) -> str:
        """æ¸…ç† CSV å€¼"""
        if not value or str(value).lower() in ['nan', 'null', 'none', '']:
            return ''

        try:
            float_val = float(value)
            if math.isnan(float_val) or math.isinf(float_val):
                return ''
        except (ValueError, TypeError):
            pass

        return str(value).strip().strip('"').strip("'")

    def _process_json_files(self, files_data: List[Dict]) -> Dict:
        """è™•ç† JSON æª”æ¡ˆ"""
        json_contents = {}

        if not files_data:
            return json_contents

        for file_info in files_data:
            try:
                filename = file_info.get('filename', file_info.get('name', ''))
                if not filename or not filename.lower().endswith('.json'):
                    continue

                content = self._safe_process_single_json(file_info)
                if content:
                    json_contents[filename] = content

            except Exception as e:
                self.logger.error(f"è™•ç† JSON æª”æ¡ˆ {filename} å¤±æ•—: {e}")
                json_contents[filename] = {'error': str(e), 'raw_content': '', 'variables': []}

        return json_contents

    def _safe_process_single_json(self, file_info: Dict) -> Optional[Dict]:
        """å®‰å…¨åœ°è™•ç†å–®ä¸€ JSON æª”æ¡ˆ - å¢å¼·ç‰ˆ"""
        try:
            self.logger.info(f"è™•ç† JSON æª”æ¡ˆ: {file_info.get('filename', file_info.get('name', 'æœªçŸ¥'))}")
            self.logger.info(f"æª”æ¡ˆè³‡è¨Šéµå€¼: {list(file_info.keys())}")

            content = ''

            # ğŸ¯ å¤šé‡ç­–ç•¥ç²å–å…§å®¹
            strategies = [
                ('content', lambda x: x.get('content')),
                ('data', lambda x: self._extract_data_content(x.get('data'))),
                ('body', lambda x: x.get('body')),
                ('text', lambda x: x.get('text')),
                ('raw_content', lambda x: x.get('raw_content')),
            ]

            for strategy_name, extractor in strategies:
                try:
                    extracted = extractor(file_info)
                    if extracted:
                        content = str(extracted) if not isinstance(extracted, str) else extracted
                        self.logger.info(f"âœ… ä½¿ç”¨ç­–ç•¥ '{strategy_name}' æˆåŠŸç²å–å…§å®¹ï¼Œé•·åº¦: {len(content)}")
                        break
                except Exception as e:
                    self.logger.warning(f"ç­–ç•¥ '{strategy_name}' å¤±æ•—: {e}")

            if not content:
                self.logger.error(f"æ‰€æœ‰å…§å®¹æå–ç­–ç•¥éƒ½å¤±æ•—ï¼Œæª”æ¡ˆè³‡è¨Š: {file_info}")
                return None

            # ğŸ¯ ç¢ºä¿æ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼
            self.logger.info(f"åŸå§‹å…§å®¹å‰100å­—ç¬¦: {content[:100]}")

            # å˜—è©¦è§£æ JSON
            parsed_json = None
            try:
                parsed_json = json.loads(content)
                self.logger.info(f"âœ… JSON è§£ææˆåŠŸ")
            except json.JSONDecodeError as e:
                self.logger.warning(f"JSON è§£æå¤±æ•—ï¼Œä¿ç•™åŸå§‹å…§å®¹: {e}")
                # å¦‚æœä¸æ˜¯æœ‰æ•ˆJSONï¼Œä»ç„¶ä¿ç•™åŸå§‹å…§å®¹

            # æ¸…ç†å’Œæå–è®Šæ•¸
            cleaned_json = self._clean_json_values(parsed_json) if parsed_json else None
            variables = self._extract_json_variables(cleaned_json) if cleaned_json else []

            result = {
                'raw_content': content,
                'parsed': cleaned_json,
                'variables': variables
            }

            self.logger.info(f"JSON è™•ç†æˆåŠŸï¼raw_content é•·åº¦: {len(content)}, è®Šæ•¸æ•¸é‡: {len(variables)}")
            return result

        except Exception as e:
            self.logger.error(f"è™•ç† JSON æª”æ¡ˆå¤±æ•—: {e}", exc_info=True)
            return None

    def _extract_data_content(self, data):
        """å¾dataå­—æ®µæå–å…§å®¹"""
        if not data:
            return None

        if isinstance(data, dict):
            return json.dumps(data, ensure_ascii=False, indent=2)
        elif isinstance(data, str):
            return data
        else:
            return str(data)

    def _clean_json_values(self, obj):
        """æ¸…ç† JSON ç‰©ä»¶ä¸­çš„å•é¡Œå€¼"""
        if isinstance(obj, dict):
            return {key: self._clean_json_values(value) for key, value in obj.items()}
        elif isinstance(obj, list):
            return [self._clean_json_values(item) for item in obj]
        elif isinstance(obj, float):
            if math.isnan(obj) or math.isinf(obj):
                return None
            return obj
        else:
            return obj

    def _extract_json_variables(self, json_obj) -> List[str]:
        """å¾ JSON ä¸­æå–è®Šæ•¸åç¨±"""
        if json_obj is None:
            return []

        variables = []

        def extract_vars(obj):
            try:
                if isinstance(obj, dict):
                    for key, value in obj.items():
                        if isinstance(value, str) and value.startswith('${') and value.endswith('}'):
                            var_name = value[2:-1]
                            if var_name and var_name not in variables:
                                variables.append(var_name)
                        elif isinstance(value, (dict, list)):
                            extract_vars(value)
                elif isinstance(obj, list):
                    for item in obj:
                        extract_vars(item)
            except Exception as e:
                self.logger.warning(f"æå–è®Šæ•¸æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

        extract_vars(json_obj)
        return variables

    def validate_xml(self, xml_content: str) -> Tuple[bool, str]:
        """
        é©—è­‰æœ€çµ‚ç”Ÿæˆçš„ JMX å­—ä¸²æ˜¯å¦ç‚ºæœ‰æ•ˆçš„ XMLã€‚
        """
        try:
            if not xml_content or not xml_content.strip():
                return False, "XML content is empty or whitespace."

            content = xml_content.strip()
            if not content.startswith('<?xml'):
                return False, "Validation failed: Missing XML declaration '<?xml ...?>'."
            if not content.endswith('</jmeterTestPlan>'):
                return False, "Validation failed: Content does not end with '</jmeterTestPlan>'."

            open_tags = content.count('<hashTree>')
            close_tags = content.count('</hashTree>')
            if open_tags != close_tags:
                return False, f"Validation failed: Mismatched <hashTree> tags (open: {open_tags}, close: {close_tags})."

            ET.fromstring(content)
            self.logger.info("âœ… XML çµæ§‹é©—è­‰é€šéã€‚")
            return True, "XML validation successful."

        except ET.ParseError as e:
            error_line = str(e).split(',')[1].strip() if ',' in str(e) else str(e)
            self.logger.error(f"XML é©—è­‰å¤±æ•—: èªæ³•è§£æéŒ¯èª¤ -> {error_line}", exc_info=True)
            return False, f"XML ParseError: The generated XML is not well-formed. Details: {error_line}"
        except Exception as e:
            self.logger.error(f"XML é©—è­‰éç¨‹ä¸­ç™¼ç”Ÿæœªé æœŸçš„éŒ¯èª¤: {e}", exc_info=True)
            return False, f"An unexpected error occurred during XML validation: {str(e)}"

    def _parameterize_json_body(self, json_body: str, csv_info: CsvInfo) -> str:
        """
        å®‰å…¨åœ°å°‡ JSON Body åƒæ•¸åŒ–ã€‚
        1. å„ªå…ˆç­–ç•¥ï¼šå¦‚æœ JSON çš„ key èˆ‡ CSV çš„è®Šæ•¸ååŒ¹é…ï¼Œç›´æ¥æ›¿æ›ã€‚
        2. å‚™ç”¨ç­–ç•¥ï¼šå¦‚æœ key ä¸åŒ¹é…ï¼Œå‰‡å˜—è©¦åŒ¹é… value (èˆŠæœ‰é‚è¼¯)ï¼Œä»¥è™•ç†ç‰¹æ®Šæƒ…æ³ã€‚
        """
        self.logger.info(f"ğŸš€ é–‹å§‹ä½¿ç”¨ã€æ™ºæ…§å‹é›™é‡ç­–ç•¥ã€‘åƒæ•¸åŒ– JSONï¼Œä¾†æº CSV: '{csv_info.filename}'")

        if not json_body or not csv_info.raw_content or not csv_info.variable_names:
            self.logger.warning("JSON Body æˆ– CSV å…§å®¹/è®Šæ•¸ç‚ºç©ºï¼Œè·³éåƒæ•¸åŒ–ã€‚")
            return json_body or ""

        try:
            # æ­¥é©Ÿ 1: è§£æ JSON å­—ä¸²ç‚º Python ç‰©ä»¶
            data_obj = json.loads(json_body)

            # æ­¥é©Ÿ 2: æº–å‚™å…©ç¨®æ›¿æ›ç­–ç•¥æ‰€éœ€çš„è³‡æ–™
            # ç­–ç•¥ä¸€ï¼šå»ºç«‹ä¸€å€‹é«˜æ•ˆçš„ CSV è®Šæ•¸åé›†åˆ (ç”¨æ–¼éµåŒ¹é…)
            variable_set = set(csv_info.variable_names)

            # ç­–ç•¥äºŒï¼šå¾ CSV è®€å–ç¬¬ä¸€è¡Œè³‡æ–™ï¼Œå»ºç«‹ "å€¼ -> ${è®Šæ•¸}" çš„å°æ‡‰å­—å…¸ (ç”¨æ–¼å€¼åŒ¹é…)
            file_stream = io.StringIO(csv_info.raw_content)
            csv_reader = csv.reader(file_stream)
            next(csv_reader, None)  # è·³éæ¨™é ­
            first_data_row = next(csv_reader, None)

            value_to_placeholder_map = {}
            if first_data_row:
                value_to_placeholder_map = {
                    value.strip(): f"${{{variable}}}"
                    for variable, value in zip(csv_info.variable_names, first_data_row)
                    if value and value.strip()
                }
                self.logger.info(f"å»ºç«‹çš„ã€Œå€¼ã€æ›¿æ›å°æ‡‰è¡¨: {value_to_placeholder_map}")
            else:
                self.logger.warning(f"CSV '{csv_info.filename}' ä¸­æ²’æœ‰è³‡æ–™è¡Œï¼Œç„¡æ³•ä½¿ç”¨ã€Œå€¼åŒ¹é…ã€ç­–ç•¥ã€‚")

            # ä½¿ç”¨ä¸€å€‹ list ä¾†è¿½è¹¤è¢«æ›¿æ›çš„éµå’ŒåŸå› 
            replacements_made = []

            # æ­¥é©Ÿ 3: å®šç¾©ä¸€å€‹éè¿´å‡½å¼ä¾†èµ°è¨ªä¸¦åŸ·è¡Œé›™é‡æ›¿æ›ç­–ç•¥
            def recursive_replace(obj):
                if isinstance(obj, dict):
                    # ä½¿ç”¨ list(obj.keys()) ä¾†é¿å…åœ¨è¿­ä»£æœŸé–“ä¿®æ”¹å­—å…¸çš„å•é¡Œ
                    for key in list(obj.keys()):
                        value = obj[key]

                        # --- ç­–ç•¥ä¸€ï¼šå„ªå…ˆé€²è¡Œã€Œéµã€åŒ¹é… ---
                        if key in variable_set:
                            placeholder = f"${{{key}}}"
                            if obj[key] != placeholder:
                                obj[key] = placeholder
                                replacements_made.append(f"'{key}' (éµåŒ¹é…)")
                            # éµåŒ¹é…æˆåŠŸå¾Œï¼Œè·³éå°è©²éµå€¼çš„å¾ŒçºŒè™•ç†
                            continue

                        # --- ç­–ç•¥äºŒï¼šå¦‚æœéµä¸åŒ¹é…ï¼Œå‰‡å˜—è©¦ã€Œå€¼ã€åŒ¹é… ---
                        str_value = str(value)
                        if str_value in value_to_placeholder_map:
                            placeholder = value_to_placeholder_map[str_value]
                            if obj[key] != placeholder:
                                obj[key] = placeholder
                                replacements_made.append(f"'{key}' (å€¼åŒ¹é…)")
                            # å€¼åŒ¹é…æˆåŠŸå¾Œï¼Œä¹Ÿè·³ééè¿´
                            continue

                        # --- å¦‚æœéƒ½æ²’æœ‰åŒ¹é…ï¼Œå‰‡éè¿´æ·±å…¥ ---
                        if isinstance(value, (dict, list)):
                            recursive_replace(value)

                elif isinstance(obj, list):
                    for item in obj:
                        recursive_replace(item)

            # åŸ·è¡Œéè¿´æ›¿æ›
            recursive_replace(data_obj)

            if replacements_made:
                # ä½¿ç”¨ set å»é™¤é‡è¤‡é …ï¼Œç„¶å¾Œå†è½‰å› list
                unique_replacements = sorted(list(set(replacements_made)))
                self.logger.info(f"âœ… JSON Body åƒæ•¸åŒ–æˆåŠŸï¼å·²æ›¿æ›çš„æ¬„ä½: {unique_replacements}")
            else:
                self.logger.warning(
                    "JSON Body å…§å®¹æœªç™¼ç”Ÿè®ŠåŒ–ã€‚è«‹æª¢æŸ¥ JSON çš„éµåæˆ–å€¼æ˜¯å¦èƒ½å°æ‡‰åˆ° CSV çš„è®Šæ•¸ã€‚")

            # æ­¥é©Ÿ 4: å°‡ä¿®æ”¹å¾Œçš„ Python ç‰©ä»¶åºåˆ—åŒ–å›æ ¼å¼åŒ–çš„ JSON å­—ä¸²
            parameterized_body = json.dumps(data_obj, indent=4, ensure_ascii=False)
            self.logger.debug(f"åƒæ•¸åŒ–å¾Œçš„ Body: \n{parameterized_body}")
            return parameterized_body

        except json.JSONDecodeError:
            self.logger.error(f"JSON è§£æå¤±æ•—ï¼è«‹æª¢æŸ¥ JSON æª”æ¡ˆæ ¼å¼ã€‚Body: \n{json_body[:500]}...")
            return json_body
        except Exception as e:
            self.logger.error(f"åƒæ•¸åŒ–éç¨‹ä¸­ç™¼ç”Ÿæœªé æœŸçš„éŒ¯èª¤: {e}", exc_info=True)
            return json_body

    def _assemble_jmx_from_structured_data(self, test_plan_data: Dict, context: 'GenerationContext') -> str:
        """
        ã€â­ æœ€çµ‚ä¿®æ­£ç‰ˆã€‘JMX çµ„è£å™¨ï¼šå¾çµæ§‹åŒ–è³‡æ–™çµ„è£ JMX æª”æ¡ˆã€‚
        - å¼·åˆ¶è¦†å¯«é—œéµåƒæ•¸ (timeout, perThread, ignoreFirstLine, CSV path, same_user_on_next_iteration) ä»¥ç¢ºä¿æ­£ç¢ºæ€§ã€‚
        - ä¿®æ­£äº†å…ƒä»¶æŸ¥æ‰¾é‚è¼¯ï¼Œç¢ºä¿èƒ½æ­£ç¢ºè™•ç†å¤šå€‹ Thread Groupï¼Œé¿å…ç”Ÿæˆé‡è¤‡å…ƒä»¶ã€‚
        """
        self.logger.info("=== æ­¥é©Ÿ 4 (é€šç”¨æµç¨‹): é–‹å§‹å¾çµæ§‹åŒ–è³‡æ–™çµ„è£ JMX (æ¡ç”¨åš´æ ¼æ§åˆ¶æ¨¡å¼) ===")
        test_plan_components = []

        # --- 1. çµ„è£å…¨åŸŸå…ƒä»¶ ---

        # çµ„è£ Header Manager
        global_headers_data = test_plan_data.get("global_headers", [])
        if global_headers_data:
            headers_xml_parts = [
                self.jmx_templates["header_element"].format(
                    name=saxutils_escape(h.get("name", "")),
                    value=saxutils_escape(h.get("value", ""))
                ) for h in global_headers_data if h and h.get("name")
            ]
            if headers_xml_parts:
                test_plan_components.append(
                    self.jmx_templates["header_manager"].format(headers="\n              ".join(headers_xml_parts))
                )
                self.logger.info(f"  -> âœ… å·²çµ„è£ {len(headers_xml_parts)} å€‹å…¨åŸŸ HTTP æ¨™é ­ã€‚")

        # çµ„è£ HTTP Defaults
        http_defaults_data = test_plan_data.get("http_defaults", {})
        if http_defaults_data and http_defaults_data.get("domain"):
            # ã€é—œéµä¿®æ­£ã€‘å¼·åˆ¶ä½¿ç”¨æ­£ç¢ºçš„ timeout èªæ³•ï¼Œç¢ºä¿ç”Ÿæˆ ${__P(...)}
            connect_timeout_str = f"${{__P(connTimeOut,{http_defaults_data.get('connect_timeout', 5000)})}}"
            response_timeout_str = f"${{__P(respTimeOut,{http_defaults_data.get('response_timeout', 5000)})}}"

            http_defaults_xml = self.jmx_templates["http_defaults"].format(
                domain=http_defaults_data.get("domain", ""),
                protocol=http_defaults_data.get("protocol", "https"),
                port=http_defaults_data.get("port", ""),
                content_encoding="UTF-8",
                path=http_defaults_data.get("path", ""),
                connect_timeout=connect_timeout_str,
                response_timeout=response_timeout_str
            )
            test_plan_components.append(http_defaults_xml)
            self.logger.info(f"  -> âœ… å·²çµ„è£ HTTP Defaultsï¼Œç›®æ¨™ç‚º: {http_defaults_data.get('domain')}")

        # çµ„è£ Random Variables
        random_variables_data = test_plan_data.get("random_variables", [])
        if random_variables_data:
            for rv_data in random_variables_data:
                if rv_data and rv_data.get("variable_name"):
                    rv_xml = self.jmx_templates["random_variable_config"].format(
                        name=saxutils_escape(rv_data.get("name", "Random Variable")),
                        variable_name=saxutils_escape(rv_data.get("variable_name", "")),
                        output_format=rv_data.get("output_format", ""),
                        min_value=rv_data.get("min_value", "1"),
                        max_value=rv_data.get("max_value", "99999999"),
                        # ã€é—œéµä¿®æ­£ã€‘å¼·åˆ¶è¦†å¯« per_thread ç‚º 'false'ï¼Œä»¥ç¬¦åˆåƒè€ƒæª”æ¡ˆçš„å…¨åŸŸå”¯ä¸€é‚è¼¯
                        per_thread="false"
                    )
                    test_plan_components.append(rv_xml)
                    self.logger.info(f"  -> âœ… å·²çµ„è£éš¨æ©Ÿè®Šæ•¸: '{rv_data.get('name')}' (å¼·åˆ¶ perThread=false)")

        # --- 2. è¿­ä»£çµ„è£åŸ·è¡Œç·’ç¾¤çµ„ (ä¿®æ­£äº†çµæ§‹æ€§å•é¡Œ) ---
        all_llm_tgs = {tg.get("name"): tg for tg in test_plan_data.get("thread_groups", []) if tg.get("name")}

        for tg_context in context.thread_groups:
            tg_name = tg_context.name
            self.logger.info(f"ğŸ”„ æ­£åœ¨çµ„è£ Thread Group: '{tg_name}'")

            tg_data_from_llm = all_llm_tgs.get(tg_name, {})
            if not tg_data_from_llm:
                self.logger.warning(f"åœ¨ LLM å›æ‡‰ä¸­æ‰¾ä¸åˆ°åç‚º '{tg_name}' çš„ Thread Group è³‡æ–™ï¼Œå°‡ä½¿ç”¨é è¨­å€¼ã€‚")

            thread_group_children = []

            # çµ„è£ CSV Data Set Config
            if tg_context.csv_configs:
                for csv_info in tg_context.csv_configs:
                    # ã€é—œéµä¿®æ­£ã€‘å¼·åˆ¶è¦†å¯«é—œéµ CSV åƒæ•¸ï¼Œä¸å†ä¿¡ä»» LLM
                    csv_xml = self.jmx_templates["csv_data_set_config"].format(
                        filename=f"..\\TestData\\{csv_info.filename}",
                        variable_names=",".join(csv_info.variable_names),
                        delimiter=",",
                        ignore_first_line="true",  # å¼·åˆ¶ç‚º true
                        allow_quoted_data="false", recycle="true", stop_thread="false", share_mode="shareMode.all"
                    )
                    thread_group_children.append(csv_xml)
                    self.logger.info(
                        f"  -> âœ… å·²ç‚º '{tg_name}' çµ„è£ CSV: {csv_info.filename} (å¼·åˆ¶è¨­å®šè·¯å¾‘å’Œ ignoreFirstLine)")

            # çµ„è£ HTTP Requests åŠå…¶å­å…ƒä»¶
            if tg_context.http_requests:
                all_llm_reqs = {req.get("name"): req for req in tg_data_from_llm.get("http_requests", []) if
                                req.get("name")}
                for http_req_info in tg_context.http_requests:
                    req_name = http_req_info.name
                    req_data_from_llm = all_llm_reqs.get(req_name, {})
                    if not req_data_from_llm:
                        self.logger.warning(f"åœ¨ Thread Group '{tg_name}' ä¸­æ‰¾ä¸åˆ°è«‹æ±‚ '{req_name}' çš„è³‡æ–™ï¼Œå°‡è·³éã€‚")
                        continue

                    sampler_children = []
                    # çµ„è£ Assertions
                    assertions_xml = self._assemble_assertions(req_data_from_llm.get("assertions", []))
                    if assertions_xml:
                        sampler_children.append(assertions_xml)
                        self.logger.info(f"    -> âœ… å·²ç‚º '{req_name}' çµ„è£ Response Assertionsã€‚")

                    # çµ„è£ HTTP Request XML æœ¬èº«
                    body_content = http_req_info.json_body or "{}"
                    escaped_body = saxutils_escape(body_content)
                    http_request_xml = self.jmx_templates["http_request_with_body"].format(
                        name=saxutils_escape(req_name),
                        path=saxutils_escape(req_data_from_llm.get("path", "/rest")),
                        method=req_data_from_llm.get("method", "POST"),
                        body_data=escaped_body
                    )
                    self.logger.info(f"  -> âœ… å·²çµ„è£ HTTP Request: '{req_name}'")

                    # çµ„åˆ Sampler å’Œå…¶æ‰€æœ‰å­å…ƒä»¶
                    if sampler_children:
                        sampler_children_xml = "\n              ".join(sampler_children)
                        full_sampler_xml = f"{http_request_xml}\n            <hashTree>\n              {sampler_children_xml}\n            </hashTree>"
                        thread_group_children.append(full_sampler_xml)
                    else:
                        thread_group_children.append(f"{http_request_xml}\n            <hashTree/>")

            # çµ„è£ Thread Group æœ¬èº«
            # ã€é—œéµä¿®æ­£ã€‘å¼·åˆ¶è¦†å¯« same_user_on_next_iteration ç‚º falseï¼Œèˆ‡åƒè€ƒæª”æ¡ˆä¸€è‡´
            modified_tg_template = self.jmx_templates["thread_group"].replace(
                '<boolProp name="ThreadGroup.same_user_on_next_iteration">true</boolProp>',
                '<boolProp name="ThreadGroup.same_user_on_next_iteration">false</boolProp>'
            )

            tg_content_xml = "\n            ".join(thread_group_children)
            thread_group_xml = modified_tg_template.format(
                name=saxutils_escape(tg_name),
                on_sample_error=tg_data_from_llm.get("on_sample_error", "continue"),
                loops=tg_data_from_llm.get("loops", "${__P(loop,-1)}"),
                num_threads=tg_data_from_llm.get("num_threads", "${__P(threads,3)}"),
                ramp_time=tg_data_from_llm.get("ramp_time", "${__P(rampUp,1)}"),
                scheduler=str(tg_data_from_llm.get("scheduler", "true")).lower(),
                duration=tg_data_from_llm.get("duration", "${__P(duration,10)}"),
                content=tg_content_xml
            )
            test_plan_components.append(thread_group_xml)

        # --- 3. çµ„è£å…¨åŸŸ Listeners (é è¨­åŠ å…¥ View Results Tree) ---
        test_plan_components.append(
            self.jmx_templates["result_collector"].format(name="View Results Tree")
        )
        self.logger.info("  -> âœ… å·²é è¨­åŠ å…¥ 'View Results Tree' Listenerã€‚")

        # --- 4. çµ„è£æœ€çµ‚çš„ Test Plan ---
        final_content_xml = "\n          ".join(test_plan_components)
        final_jmx = self.jmx_templates["test_plan_structure"].format(
            test_name=saxutils_escape(context.test_plan_name),
            comments="Generated by a universal JMXGeneratorService.",
            tear_down_on_shutdown=str(test_plan_data.get("tear_down_on_shutdown", "true")).lower(),
            content=final_content_xml
        )

        self.logger.info("âœ… JMX é€šç”¨çµ„è£å®Œæˆï¼")
        return self.jmx_templates["xml_header"] + "\n" + final_jmx

    def _assemble_assertions(self, assertions_data: List[Dict]) -> str:
        """
        æ ¹æ“šçµæ§‹åŒ–è³‡æ–™çµ„è£ä¸€æˆ–å¤šå€‹ Response Assertion çš„ XML å­—ä¸²ã€‚
        """
        if not assertions_data:
            return ""

        all_assertions_xml_parts = []
        for assertion_details in assertions_data:
            if not assertion_details or not assertion_details.get("name"):
                continue

            patterns_list = assertion_details.get("patterns", [])
            if not patterns_list:
                continue

            patterns_to_test_xml_parts = [
                self.jmx_templates["assertion_pattern"].format(
                    hash_code=str(hash(p)),
                    pattern=saxutils_escape(p)
                ) for p in patterns_list if p
            ]

            if not patterns_to_test_xml_parts:
                continue

            full_assertion_xml = self.jmx_templates["response_assertion"].format(
                name=saxutils_escape(assertion_details.get("name", "Response Assertion")),
                patterns_to_test="\n                  ".join(patterns_to_test_xml_parts),
                test_field=assertion_details.get("test_field", "Assertion.response_data"),
                test_type=assertion_details.get("test_type", 2)
            )
            all_assertions_xml_parts.append(f"{full_assertion_xml}\n              <hashTree/>")

        return "\n              ".join(all_assertions_xml_parts)

    def _find_http_request_info_in_context(self, context: GenerationContext, name: str) -> Optional[HttpRequestInfo]:
        """æ ¹æ“šè«‹æ±‚åç¨±å¾ GenerationContext ä¸­å®‰å…¨åœ°æŸ¥æ‰¾ HttpRequestInfoã€‚"""
        for tg_context in context.thread_groups:
            for req_info in tg_context.http_requests:
                if req_info.name == name:
                    return req_info
        return None

    def _find_req_data_by_name(self, test_plan_data: Dict, name: str) -> Dict:
        """è¼”åŠ©å‡½å¼ï¼šæ ¹æ“šåç¨±å¾ LLM çš„è¼¸å‡ºä¸­æŸ¥æ‰¾å°æ‡‰çš„è«‹æ±‚è³‡æ–™ã€‚"""
        for tg in test_plan_data.get("thread_groups", []):
            if tg.get("http_request", {}).get("name") == name:
                return tg["http_request"]
        self.logger.warning(f"åœ¨ LLM è¼¸å‡ºä¸­æœªæ‰¾åˆ°åç‚º '{name}' çš„è«‹æ±‚è³‡æ–™ï¼Œå°‡è¿”å›ç©ºå­—å…¸ã€‚")
        return {}