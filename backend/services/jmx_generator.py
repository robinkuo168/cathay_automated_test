import os
import json
import threading
import re
import math
from typing import List, Dict, Any, Optional, Tuple
from pathlib import Path
import pandas as pd
from ibm_watsonx_ai.foundation_models import ModelInference
from ibm_watsonx_ai.metanames import GenTextParamsMetaNames as GenParams
from ibm_watsonx_ai.credentials import Credentials
from dotenv import load_dotenv
import xml.etree.ElementTree as ET
from .logger import get_logger
from .llm_service import LLMService
import io
import csv
from dataclasses import dataclass, field

load_dotenv()

@dataclass
class CsvInfo:
    filename: str
    variable_names: List[str] = field(default_factory=list)
    total_rows: int = 0
    raw_content: Optional[str] = None

@dataclass
class HttpRequestInfo:
    name: str
    json_body: Optional[str] = None
    source_json_filename: Optional[str] = None
    method: str = "POST"
    # æ–°å¢æ¨™è¨˜ï¼Œè¿½è¹¤æ­¤è«‹æ±‚æ˜¯å¦å·²æˆåŠŸåƒæ•¸åŒ–
    is_parameterized: bool = False

@dataclass
class ThreadGroupContext:
    name: str
    http_requests: List[HttpRequestInfo] = field(default_factory=list)
    csv_configs: List[CsvInfo] = field(default_factory=list)

@dataclass
class GenerationContext:
    test_plan_name: str
    thread_groups: List[ThreadGroupContext]
    requirements: str
    raw_processed_files: Dict

class JMXGeneratorService:
    def __init__(self, llm_service: Optional[LLMService] = None, model_name: str = "default"):
        """
        åˆå§‹åŒ– JMXGeneratorService
        :param llm_service: å¯é¸çš„ LLMService å¯¦ä¾‹ï¼Œå¦‚æœç‚º None å‰‡æœƒè‡ªå‹•å‰µå»º
        :param model_name: è¦ä½¿ç”¨çš„æ¨¡å‹åç¨±ï¼Œé è¨­ç‚º "default"
        """
        self._llm_service = llm_service
        self._model_name = model_name
        self.logger = get_logger(__name__)
        self.jmx_templates = self._load_jmx_templates()
        
    @property
    def llm_service(self) -> LLMService:
        if self._llm_service is None:
            self.logger.info(f"åˆå§‹åŒ– LLMService (Model: {self._model_name})")
            try:
                # å¾ main æ¨¡çµ„å°å…¥ get_llm_service å‡½æ•¸
                from main import get_llm_service
                self._llm_service = get_llm_service(self._model_name)
            except ImportError:
                self.logger.warning("ç„¡æ³•å¾ main æ¨¡çµ„å°å…¥ get_llm_serviceï¼Œä½¿ç”¨é»˜èª LLMService åˆå§‹åŒ–")
                self._llm_service = LLMService()
        return self._llm_service

    def _load_jmx_templates(self) -> Dict:
        """è¼‰å…¥ JMX æ¨¡æ¿ - ä¿®æ­£ HTTP Request æ ¼å¼"""
        return {
            "xml_header": '<?xml version="1.0" encoding="UTF-8"?>',
            # ... å…¶ä»–æ¨¡æ¿ ...

            "http_request_with_body": """<HTTPSamplerProxy guiclass="HttpTestSampleGui" testclass="HTTPSamplerProxy" testname="{name}" enabled="true">
      <boolProp name="HTTPSampler.postBodyRaw">true</boolProp>
      <elementProp name="HTTPsampler.Arguments" elementType="Arguments">
        <collectionProp name="Arguments.arguments">
          <elementProp name="" elementType="HTTPArgument">
            <boolProp name="HTTPArgument.always_encode">false</boolProp>
            <stringProp name="Argument.value">{body_data}</stringProp>
            <stringProp name="Argument.metadata">=</stringProp>
          </elementProp>
        </collectionProp>
      </elementProp>
      <stringProp name="HTTPSampler.protocol">{protocol}</stringProp>
      <stringProp name="HTTPSampler.domain">{domain}</stringProp>
      <stringProp name="HTTPSampler.port">{port}</stringProp>
      <stringProp name="HTTPSampler.path">{path}</stringProp>
      <stringProp name="HTTPSampler.method">{method}</stringProp>
      <boolProp name="HTTPSampler.follow_redirects">true</boolProp>
      <boolProp name="HTTPSampler.auto_redirects">false</boolProp>
      <boolProp name="HTTPSampler.use_keepalive">true</boolProp>
      <boolProp name="HTTPSampler.save_response_data">false</boolProp>
      <stringProp name="HTTPSampler.contentEncoding">UTF-8</stringProp>
    </HTTPSamplerProxy>
    <hashTree/>"""
        }

    def _create_jmx_from_template(self, test_name: str, comments: str = "", content: str = "") -> str:
        """å¾æ¨¡æ¿å‰µå»ºå®Œæ•´çš„ JMX å…§å®¹"""
        return (
            self.jmx_templates["xml_header"] + "\n" +
            self.jmx_templates["test_plan_structure"].format(
                test_name=test_name,
                comments=comments,
                content=content
                )
            )

    def generate_jmx_with_retry(self, requirements: str, files_data: List[Dict] = None, max_retries: int = 3) -> str:
        """
        ç”Ÿæˆ JMX æª”æ¡ˆï¼ˆå¸¶é‡è©¦æ©Ÿåˆ¶ï¼‰
        """
        try:
            context = self._prepare_generation_context(requirements, files_data)
            self.logger.info(f"âœ… ç”Ÿæˆä¸Šä¸‹æ–‡æº–å‚™å®Œæˆï¼Œæ¸¬è©¦è¨ˆç•«: '{context.test_plan_name}'")
        except ValueError as e:
            self.logger.error(f"âŒ è¼¸å…¥è³‡æ–™æº–å‚™å¤±æ•—ï¼Œç„¡æ³•ç¹¼çºŒç”Ÿæˆ: {e}")
            return self._get_fallback_jmx(requirements, self._safe_process_files(files_data))

        validation_errors = []
        for attempt in range(max_retries):
            try:
                self.logger.info(f"ğŸš€ é–‹å§‹ç¬¬ {attempt + 1}/{max_retries} æ¬¡ç”Ÿæˆå˜—è©¦...")
                prompt = self._build_prompt(context, attempt, validation_errors)
                response = self.llm_service.generate_text(prompt=prompt)
                jmx_content = self._extract_and_clean_jmx(response, context)

                is_valid, message = self.validate_xml(jmx_content)
                if not is_valid:
                    validation_errors.append(f"XMLæ ¼å¼éŒ¯èª¤: {message}")
                    self.logger.warning(f"ç¬¬ {attempt + 1} æ¬¡å˜—è©¦ - XML é©—è­‰å¤±æ•—: {message}")
                    continue

                content_valid, content_message = self._validate_jmx_content_requirements(jmx_content, context)
                if not content_valid:
                    validation_errors.append(f"å…§å®¹ä¸ç¬¦éœ€æ±‚: {content_message}")
                    self.logger.warning(f"ç¬¬ {attempt + 1} æ¬¡å˜—è©¦ - å…§å®¹é©—è­‰å¤±æ•—: {content_message}")
                    continue

                self.logger.info(f"âœ… ç¬¬ {attempt + 1} æ¬¡ç”ŸæˆæˆåŠŸï¼")
                return jmx_content

            except Exception as e:
                self.logger.error(f"ç¬¬ {attempt + 1} æ¬¡ç”Ÿæˆéç¨‹ä¸­ç™¼ç”Ÿç•°å¸¸: {e}", exc_info=True)
                validation_errors.append(f"åŸ·è¡Œç•°å¸¸: {str(e)}")

        self.logger.error("æ‰€æœ‰é‡è©¦å‡å‘Šå¤±æ•—ã€‚")
        raise Exception("ç„¡æ³•ç”Ÿæˆæœ‰æ•ˆçš„ JMX æª”æ¡ˆï¼Œå·²é”æœ€å¤§é‡è©¦æ¬¡æ•¸ã€‚")

    def _prepare_generation_context(self, requirements: str, files_data: List[Dict]) -> GenerationContext:
        """
        ã€é‡æ§‹ç‰ˆã€‘
        é è™•ç†å‡½æ•¸ï¼šå°‡åŸå§‹è¼¸å…¥è½‰æ›ç‚ºçµæ§‹åŒ–çš„ GenerationContextã€‚
        æ­¤ç‰ˆæœ¬å°‡ JSON åƒæ•¸åŒ–ä½œç‚ºæ ¸å¿ƒå‰ç½®è™•ç†æ­¥é©Ÿã€‚
        """
        self.logger.info("=== æ­¥é©Ÿ 1: é–‹å§‹æº–å‚™ç”Ÿæˆä¸Šä¸‹æ–‡ (æ¡ç”¨å¥å£¯åƒæ•¸åŒ–æµç¨‹) ===")
        processed_files = self._safe_process_files(files_data)
        req_analysis = self._analyze_requirements_dynamically(requirements)

        if not req_analysis.get('thread_groups'):
            raise ValueError("éœ€æ±‚åˆ†æå¤±æ•—ï¼šç„¡æ³•å¾éœ€æ±‚ä¸­è§£æå‡ºä»»ä½• Thread Group åç¨±ã€‚")

        thread_group_contexts = []

        # å¾éœ€æ±‚åˆ†æä¸­ç²å–æ‰€æœ‰é æœŸçš„ HTTP Request åç¨±
        all_http_requests_from_analysis = req_analysis.get('http_requests', [])

        # ä¸»è¿´åœˆï¼šç‚ºæ¯ä¸€å€‹ Thread Group å»ºç«‹ä¸Šä¸‹æ–‡
        for tg_name in req_analysis['thread_groups']:
            self.logger.info(f"ğŸ”„ --- æ­£åœ¨è™•ç† Thread Group: '{tg_name}' ---")

            # 1. ç¢ºå®šç›¸é—œæª”æ¡ˆåç¨±
            # å‡è¨­ HTTP Request åç¨±èˆ‡ Thread Group åç¨±ä¸€è‡´
            http_req_name = next((r for r in all_http_requests_from_analysis if r == tg_name), tg_name)
            json_filename = f"{http_req_name}.json"
            csv_filename = f"{tg_name}.csv"

            # 2. ç²å–åŸå§‹æª”æ¡ˆå…§å®¹
            json_info = processed_files['json_contents'].get(json_filename)
            original_json_body = json_info.get('raw_content') if json_info else None

            # ä½¿ç”¨æ›´å®‰å…¨çš„æ–¹å¼å°‹æ‰¾ CSV è¨­å®š
            csv_config_data = next(
                (c for c in processed_files.get('csv_configs', []) if c.get('filename') == csv_filename), None)

            # 3. ã€æ ¸å¿ƒé‚è¼¯ã€‘åŸ·è¡Œåƒæ•¸åŒ–ä¸¦æº–å‚™æœ€çµ‚è³‡æ–™
            final_json_body = original_json_body
            csv_info_obj = None
            is_parameterized = False

            if original_json_body and csv_config_data:
                self.logger.info(f"ç‚º '{tg_name}' æ‰¾åˆ°åŒ¹é…çš„ JSON ('{json_filename}') å’Œ CSV ('{csv_filename}')ã€‚")

                # å»ºç«‹ CsvInfo ç‰©ä»¶ä»¥å‚³éçµ¦åƒæ•¸åŒ–å‡½å¼
                csv_info_obj = CsvInfo(
                    filename=csv_filename,
                    variable_names=csv_config_data.get('variable_names', []),
                    total_rows=csv_config_data.get('total_rows', 0),
                    raw_content=csv_config_data.get('raw_content')
                )

                # ğŸš€ å‘¼å«æˆ‘å€‘æ–°çš„ã€å¥å£¯çš„åƒæ•¸åŒ–å‡½å¼
                final_json_body = self._parameterize_json_body(original_json_body, csv_info_obj)
                is_parameterized = True  # æ¨™è¨˜å·²åŸ·è¡Œåƒæ•¸åŒ–æµç¨‹

            else:
                self.logger.warning(f"âš ï¸  ç‚º '{tg_name}' æœªèƒ½æ‰¾åˆ°å®Œæ•´çš„ JSON/CSV é…å°ï¼Œå°‡è·³éåƒæ•¸åŒ–ã€‚")
                if not original_json_body:
                    self.logger.warning(f"   - ç¼ºå°‘ JSON æª”æ¡ˆ: '{json_filename}'")
                if not csv_config_data:
                    self.logger.warning(f"   - ç¼ºå°‘ CSV æª”æ¡ˆ: '{csv_filename}'")

            # 4. å»ºç«‹çµæ§‹åŒ–ç‰©ä»¶
            # ä½¿ç”¨ã€æœ€çµ‚ã€‘çš„ JSON body (å¯èƒ½æ˜¯åŸå§‹çš„ï¼Œä¹Ÿå¯èƒ½æ˜¯åƒæ•¸åŒ–å¾Œçš„)
            http_req_info = HttpRequestInfo(
                name=http_req_name,
                json_body=final_json_body,
                source_json_filename=json_filename if json_info else None,
                is_parameterized=is_parameterized
            )

            tg_context = ThreadGroupContext(name=tg_name)
            tg_context.http_requests.append(http_req_info)

            # åªæœ‰æˆåŠŸå»ºç«‹ CsvInfo ç‰©ä»¶æ™‚æ‰å°‡å…¶åŠ å…¥
            if csv_info_obj:
                tg_context.csv_configs.append(csv_info_obj)

            thread_group_contexts.append(tg_context)
            self.logger.info(f"âœ… --- Thread Group '{tg_name}' è™•ç†å®Œæˆ ---")

        # 5. è¿”å›æœ€çµ‚çš„ã€å®Œæ•´çš„ä¸Šä¸‹æ–‡ç‰©ä»¶
        return GenerationContext(
            test_plan_name=req_analysis.get('test_plan_name', 'Generated Test Plan'),
            thread_groups=thread_group_contexts,
            requirements=requirements,
            raw_processed_files=processed_files
        )

    def _assess_requirements_complexity(self, requirements: str) -> int:
        """è©•ä¼°éœ€æ±‚è¤‡é›œåº¦ï¼ˆé¿å…æ–°å¢å‡½å¼ï¼Œå…§åµŒé‚è¼¯ï¼‰"""
        score = 0

        # åŸºæœ¬è¤‡é›œåº¦æŒ‡æ¨™
        if len(requirements) > 500:
            score += 2
        if requirements.count('Thread Group') > 1:
            score += 2
        if 'Header Manager' in requirements:
            score += 1
        if 'CSV Data Set' in requirements:
            score += 1
        if 'Response Assertion' in requirements:
            score += 1
        if 'POST' in requirements.upper():
            score += 1
        if '${' in requirements:  # åŒ…å«è®Šæ•¸
            score += 2

        return min(score, 10)

    def _count_jmx_components(self, jmx_content: str) -> int:
        """è¨ˆç®— JMX å…§å®¹ä¸­çš„çµ„ä»¶æ•¸é‡"""
        import re

        # å®šç¾©ä¸»è¦çµ„ä»¶çš„æ¨¡å¼
        component_patterns = [
            r'<TestPlan\s+',  # TestPlan
            r'<HeaderManager\s+',  # Header Manager
            r'<ThreadGroup\s+',  # Thread Group
            r'<HTTPSamplerProxy\s+',  # HTTP Request
            r'<CSVDataSet\s+',  # CSV Data Set Config
            r'<ResponseAssertion\s+',  # Response Assertion
            r'<ResultCollector\s+.*testclass="ResultCollector"',  # View Results Tree
        ]

        total_count = 0
        for pattern in component_patterns:
            matches = re.findall(pattern, jmx_content, re.IGNORECASE)
            total_count += len(matches)

        return total_count

    def _safe_process_files(self, files_data: List[Dict] = None) -> Dict:
        """å®‰å…¨åœ°è™•ç†æª”æ¡ˆè³‡æ–™"""
        try:
            if not files_data:
                self.logger.warning("æ²’æœ‰å‚³å…¥ä»»ä½•æª”æ¡ˆè³‡æ–™")
                return {"csv_configs": [], "json_contents": {}}

            self.logger.info(f"é–‹å§‹è™•ç† {len(files_data)} å€‹æª”æ¡ˆ")

            # å¾ _process_csv_files ç²å–çš„æ˜¯å­—å…¸ï¼Œkey æ˜¯æª”å
            csv_configs_dict = self._process_csv_files(files_data)
            json_contents = self._process_json_files(files_data)

            self.logger.info(f"JSON è™•ç†çµæœ: {list(json_contents.keys())}")

            # å°‡ CSV configs å­—å…¸è½‰æ›ç‚ºåˆ—è¡¨æ ¼å¼ï¼Œä¸¦ç¢ºä¿åŒ…å« raw_content
            csv_configs_list = []
            for filename, config in csv_configs_dict.items():
                if config and 'error' not in config:
                    # ç¢ºä¿æˆ‘å€‘å¾ _safe_process_single_csv è¿”å›çš„æ‰€æœ‰é‡è¦è³‡è¨Šéƒ½è¢«åŒ…å«
                    csv_configs_list.append({
                        'filename': filename,
                        'variable_names': config.get('headers', []),
                        'total_rows': config.get('total_rows', 0),
                        'filepath': config.get('filepath', filename),
                        'raw_content': config.get('raw_content', '')  # ç¢ºä¿ raw_content è¢«å‚³é
                    })
                    self.logger.info(
                        f"ç‚ºåˆ—è¡¨æ·»åŠ  CSV è¨­å®š: '{filename}', è®Šæ•¸: {config.get('headers', [])}, raw_content é•·åº¦: {len(config.get('raw_content', ''))}")
                else:
                    self.logger.warning(f"è·³éæœ‰å•é¡Œçš„ CSV è¨­å®š: {filename}")

            result = {"csv_configs": csv_configs_list, "json_contents": json_contents}
            self.logger.info(f"æª”æ¡ˆè™•ç†å®Œæˆ - CSV: {len(csv_configs_list)}, JSON: {len(json_contents)}")
            return result

        except Exception as e:
            self.logger.error(f"æª”æ¡ˆè™•ç†å¤±æ•—: {e}", exc_info=True)
            return {"csv_configs": [], "json_contents": {}}

    def _analyze_requirements_dynamically(self, requirements: str) -> Dict:
        """å‹•æ…‹åˆ†æéœ€æ±‚ï¼Œæå–é—œéµè³‡è¨Šï¼ˆé€šç”¨ç‰ˆæœ¬ï¼‰"""
        import re

        analysis = {
            'test_plan_name': '',
            'thread_groups': [],
            'http_requests': [],
            'csv_configs': [],
            'response_assertions': [],
            'view_results_trees': [],
            'expected_components': 0
        }

        try:
            # 1. æå–æ¸¬è©¦è¨ˆç•«åç¨±ï¼ˆå¤šç¨®æ ¼å¼æ”¯æ´ï¼‰
            testplan_patterns = [
                r'æ¸¬è©¦è¨ˆç•«[^ï¼Œ,\n]*åç¨±[æ¬„ä½]*[å¡«å…¥ç‚º]*[ã€ã€Œ]([^ã€ã€]+)[ã€ã€]',
                r'åç¨±[æ¬„ä½]*å¡«å…¥[ã€ã€Œ]([^ã€ã€]+)[ã€ã€]',
                r"Test Plan.*name.*[ã€ã€Œ]([^ã€ã€]+)[ã€ã€]",
                r"testname.*[ã€ã€Œ]([^ã€ã€]+)[ã€ã€]"
            ]

            for pattern in testplan_patterns:
                match = re.search(pattern, requirements, re.IGNORECASE)
                if match:
                    analysis['test_plan_name'] = match.group(1).strip()
                    break

            # 2. æå– Thread Group åç¨±ï¼ˆé€šç”¨æ¨¡å¼ï¼‰
            tg_patterns = [
                # ä¸­æ–‡æ¨¡å¼
                r'thread group[^ï¼Œ,\n]*åç¨±[ç‚ºåˆ†åˆ¥ç‚º]*[ã€ã€Œ]*([A-Z0-9_-]+)[ã€ã€]*',
                r'åŸ·è¡Œç·’ç¾¤çµ„[^ï¼Œ,\n]*åç¨±[ç‚ºåˆ†åˆ¥ç‚º]*[ã€ã€Œ]*([A-Z0-9_-]+)[ã€ã€]*',
                r'å¢åŠ .*thread group.*åç¨±ç‚º\s*[ã€ã€Œ]*([A-Z0-9_-]+)[ã€ã€]*',
                # è™•ç† "åç¨±åˆ†åˆ¥ç‚º A åŠ B" çš„æ ¼å¼
                r'åç¨±åˆ†åˆ¥ç‚º\s*([A-Z0-9_-]+)\s*åŠ\s*([A-Z0-9_-]+)',
                r'åç¨±åˆ†åˆ¥ç‚º\s*([A-Z0-9_-]+)[ã€ï¼Œ]\s*([A-Z0-9_-]+)',
                # è‹±æ–‡æ¨¡å¼
                r'Thread Group.*name[s]*[:\s]*[ã€ã€Œ]*([A-Z0-9_-]+)[ã€ã€]*',
            ]

            for pattern in tg_patterns:
                matches = re.findall(pattern, requirements, re.IGNORECASE)
                for match in matches:
                    if isinstance(match, tuple):
                        # è™•ç†å¤šçµ„åŒ¹é…ï¼ˆå¦‚ "A åŠ B"ï¼‰
                        for item in match:
                            if item.strip():
                                analysis['thread_groups'].append(item.strip())
                    else:
                        if match.strip():
                            analysis['thread_groups'].append(match.strip())

            # 3. æå– HTTP Request åç¨±ï¼ˆé€šç”¨æ¨¡å¼ï¼‰
            http_patterns = [
                # ä¸­æ–‡æ¨¡å¼
                r'http request[^ï¼Œ,\n]*åç¨±[ç‚ºåˆ†åˆ¥ç‚º]*\s*[ã€ã€Œ]*([A-Z0-9_-]+)[ã€ã€]*',
                r'HTTPè«‹æ±‚[^ï¼Œ,\n]*åç¨±[ç‚ºåˆ†åˆ¥ç‚º]*\s*[ã€ã€Œ]*([A-Z0-9_-]+)[ã€ã€]*',
                r'å¢åŠ .*http request.*åç¨±ç‚º\s*[ã€ã€Œ]*([A-Z0-9_-]+)[ã€ã€]*',
                r'åº•ä¸‹å¢åŠ \s*http request[^ï¼Œ,\n]*åç¨±ç‚º\s*([A-Z0-9_-]+)',
                # è‹±æ–‡æ¨¡å¼
                r'HTTP Request.*name[s]*[:\s]*[ã€ã€Œ]*([A-Z0-9_-]+)[ã€ã€]*',
                r'HTTP Sampler.*name[s]*[:\s]*[ã€ã€Œ]*([A-Z0-9_-]+)[ã€ã€]*',
            ]

            for pattern in http_patterns:
                matches = re.findall(pattern, requirements, re.IGNORECASE)
                for match in matches:
                    if isinstance(match, tuple):
                        for item in match:
                            if item.strip():
                                analysis['http_requests'].append(item.strip())
                    else:
                        if match.strip():
                            analysis['http_requests'].append(match.strip())

            # 4. æ™ºèƒ½æ¨æ–·ï¼šå¦‚æœ HTTP Request å’Œ Thread Group åœ¨åŒä¸€æ®µè½ï¼Œå¯èƒ½åŒå
            if len(analysis['http_requests']) < len(analysis['thread_groups']):
                lines = requirements.split('\n')
                for i, line in enumerate(lines):
                    for tg_name in analysis['thread_groups']:
                        # æª¢æŸ¥æ˜¯å¦åœ¨ç›¸é„°è¡Œä¸­æåˆ°ç›¸åŒåç¨±çš„ http request
                        context_lines = lines[max(0, i - 2):min(len(lines), i + 3)]
                        context = ' '.join(context_lines)
                        if (tg_name in line and 'thread group' in line.lower() and
                                'http request' in context.lower()):
                            if tg_name not in analysis['http_requests']:
                                analysis['http_requests'].append(tg_name)

            # 5. æå– CSV é…ç½®è³‡è¨Šï¼ˆé€šç”¨æ¨¡å¼ï¼‰
            csv_patterns = [
                r'CSV.*è³‡æ–™.*è¨­å®š',
                r'CSV.*Data.*Set.*Config',
                r'([A-Z0-9_-]+\.csv)',
                r'æª”å.*å¡«å…¥.*[ã€ã€Œ]*([^ã€ã€\s]+\.csv)[ã€ã€]*',
                r'é™„ä»¶.*[ã€ã€Œ]*([^ã€ã€\s]+\.csv)[ã€ã€]*',
            ]

            for pattern in csv_patterns:
                matches = re.findall(pattern, requirements, re.IGNORECASE)
                for match in matches:
                    if match.strip().endswith('.csv'):
                        analysis['csv_configs'].append(match.strip())

            # 6. æå– Response Assertion è³‡è¨Š
            assertion_patterns = [
                r'Response Assertion.*[ã€ã€Œ]*([^ã€ã€\n]+)[ã€ã€]*',
                r'å›æ‡‰.*æ–·è¨€.*[ã€ã€Œ]*([^ã€ã€\n]+)[ã€ã€]*',
                r'é©—è­‰.*å›[è¦†æ‡‰].*[ã€ã€Œ]*([^ã€ã€\n]+)[ã€ã€]*',
            ]

            for pattern in assertion_patterns:
                matches = re.findall(pattern, requirements, re.IGNORECASE)
                analysis['response_assertions'].extend([m.strip() for m in matches if m.strip()])

            # 7. æå– View Results Tree è³‡è¨Š
            view_patterns = [
                r'View Results Tree.*[ã€ã€Œ]*([^ã€ã€\n]+)[ã€ã€]*',
                r'æª¢è¦–.*çµæœ.*æ¨¹ç‹€.*[ã€ã€Œ]*([^ã€ã€\n]+)[ã€ã€]*',
                r'çµæœ.*æª¢è¦–.*[ã€ã€Œ]*([^ã€ã€\n]+)[ã€ã€]*',
            ]

            for pattern in view_patterns:
                matches = re.findall(pattern, requirements, re.IGNORECASE)
                analysis['view_results_trees'].extend([m.strip() for m in matches if m.strip()])

        except Exception as e:
            self.logger.warning(f"éœ€æ±‚åˆ†ææ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
            # ç™¼ç”ŸéŒ¯èª¤æ™‚å˜—è©¦å‚™ç”¨è§£æ
            return self._fallback_parse_requirements(requirements)

        # æ¸…ç†å’Œå»é‡
        analysis['thread_groups'] = list(set([x for x in analysis['thread_groups'] if x]))
        analysis['http_requests'] = list(set([x for x in analysis['http_requests'] if x]))
        analysis['csv_configs'] = list(set([x for x in analysis['csv_configs'] if x]))
        analysis['response_assertions'] = list(set([x for x in analysis['response_assertions'] if x]))
        analysis['view_results_trees'] = list(set([x for x in analysis['view_results_trees'] if x]))

        # è¨ˆç®—é æœŸçµ„ä»¶æ•¸é‡
        analysis['expected_components'] = (
                len(analysis['thread_groups']) +
                len(analysis['http_requests']) +
                len(analysis['csv_configs']) +
                len(analysis['response_assertions']) +
                len(analysis['view_results_trees'])
        )

        return analysis

    def _debug_requirement_analysis(self, requirements: str) -> Dict:
        """èª¿è©¦éœ€æ±‚åˆ†æçµæœ"""
        self.logger.info("=== é–‹å§‹éœ€æ±‚åˆ†æèª¿è©¦ ===")

        analysis = self._analyze_requirements_dynamically(requirements)

        # è¨˜éŒ„åˆ†æçµæœ
        self.logger.info(f"æ¸¬è©¦è¨ˆç•«åç¨±: '{analysis['test_plan_name']}'")
        self.logger.info(f"Thread Groups ({len(analysis['thread_groups'])}): {analysis['thread_groups']}")
        self.logger.info(f"HTTP Requests ({len(analysis['http_requests'])}): {analysis['http_requests']}")
        self.logger.info(f"CSV é…ç½® ({len(analysis['csv_configs'])}): {analysis['csv_configs']}")
        self.logger.info(
            f"Response Assertions ({len(analysis['response_assertions'])}): {analysis['response_assertions']}")
        self.logger.info(
            f"View Results Trees ({len(analysis['view_results_trees'])}): {analysis['view_results_trees']}")
        self.logger.info(f"é æœŸçµ„ä»¶ç¸½æ•¸: {analysis['expected_components']}")

        # æª¢æŸ¥é—œéµå­—å‡ºç¾æƒ…æ³
        self.logger.info("=== é—œéµå­—æª¢æŸ¥ ===")
        keywords = ['thread group', 'http request', 'csv', 'assertion', 'view results']
        for keyword in keywords:
            count = requirements.lower().count(keyword.lower())
            self.logger.info(f"'{keyword}' å‡ºç¾æ¬¡æ•¸: {count}")

        self.logger.info("=== éœ€æ±‚åˆ†æèª¿è©¦å®Œæˆ ===")
        return analysis

    def _fallback_parse_requirements(self, requirements: str) -> Dict:
        """å‚™ç”¨éœ€æ±‚è§£æé‚è¼¯ï¼ˆç•¶æ­£å‰‡è¡¨é”å¼å¤±æ•—æ™‚ä½¿ç”¨ï¼‰"""
        self.logger.warning("ä½¿ç”¨å‚™ç”¨éœ€æ±‚è§£æé‚è¼¯")

        analysis = {
            'test_plan_name': '',
            'thread_groups': [],
            'http_requests': [],
            'csv_configs': [],
            'response_assertions': [],
            'view_results_trees': [],
            'expected_components': 0
        }

        lines = requirements.split('\n')
        req_text = requirements.lower()

        # ç°¡å–®çš„é—œéµå­—åŒ¹é…
        for line in lines:
            line_lower = line.lower()
            line_clean = line.strip()

            # æŸ¥æ‰¾å¯èƒ½çš„çµ„ä»¶åç¨±ï¼ˆé€šå¸¸æ˜¯å¤§å¯«å­—æ¯+æ•¸å­—+é€£å­—ç¬¦çš„æ ¼å¼ï¼‰
            import re
            component_names = re.findall(r'\b[A-Z]{2,}[-_][A-Z0-9-_]+\b', line)

            for name in component_names:
                # æ ¹æ“šä¸Šä¸‹æ–‡åˆ¤æ–·æ˜¯ä»€éº¼é¡å‹çš„çµ„ä»¶
                if 'thread group' in line_lower and name not in analysis['thread_groups']:
                    analysis['thread_groups'].append(name)
                elif 'http request' in line_lower and name not in analysis['http_requests']:
                    analysis['http_requests'].append(name)

            # æŸ¥æ‰¾ CSV æª”æ¡ˆ
            csv_files = re.findall(r'\b[A-Z0-9-_]+\.csv\b', line)
            analysis['csv_configs'].extend(csv_files)

            # æŸ¥æ‰¾æ¸¬è©¦è¨ˆç•«åç¨±
            if 'æ¸¬è©¦è¨ˆç•«' in line and 'åç¨±' in line:
                # ç°¡å–®æå–å¼•è™Ÿå…§çš„å…§å®¹
                name_match = re.search(r'[ã€ã€Œ]([^ã€ã€]+)[ã€ã€]', line)
                if name_match:
                    analysis['test_plan_name'] = name_match.group(1)

        # æ¸…ç†å»é‡
        for key in ['thread_groups', 'http_requests', 'csv_configs']:
            analysis[key] = list(set([x for x in analysis[key] if x]))

        analysis['expected_components'] = len(analysis['thread_groups']) + len(analysis['http_requests'])

        self.logger.info(f"å‚™ç”¨è§£æçµæœ: {analysis}")
        return analysis

    def _build_prompt(self, context: GenerationContext, attempt: int = 0, validation_errors: List[str] = None) -> str:
        """ å»ºç«‹æç¤ºè© """
        self.logger.info("=== æ­¥é©Ÿ 2: å»ºç«‹æç¤ºè© ===")

        base_prompt = f"""You are an expert JMeter test script generator...
        === Original Requirements ===
        {context.requirements}
        """

        base_prompt += "\n=== Structured Test Plan Information ===\n"
        base_prompt += f"Test Plan Name: {context.test_plan_name}\n"

        for tg_context in context.thread_groups:
            # âœ… è®Šæ›´ 1: ä½¿ç”¨æ›´å¼·çƒˆã€æ›´æ˜é¡¯çš„åˆ†éš”ç¬¦ï¼Œç‚ºæ¯å€‹ Thread Group å»ºç«‹ç¨ç«‹çš„æŒ‡ä»¤ä¸Šä¸‹æ–‡ã€Œç‰†ã€ã€‚
            base_prompt += f"\n\n==================================================\n"
            base_prompt += f"=== INSTRUCTIONS FOR THREAD GROUP: '{tg_context.name}' ===\n"
            base_prompt += f"==================================================\n"

            if tg_context.http_requests:
                for http_req in tg_context.http_requests:
                    base_prompt += f"\n  - HTTP Request Name: {http_req.name}\n"
                    if http_req.json_body:
                        escaped_json = http_req.json_body.replace('&', '&amp;').replace('<', '&lt;').replace('>',
                                                                                                             '&gt;').replace(
                            '"', '&quot;')
                        base_prompt += f"    Source JSON: {http_req.source_json_filename}\n"
                        base_prompt += f"""    ğŸ¯ CRITICAL: Use the following full JSON content for the body:
        ```json
        {http_req.json_body}
        ```
        And format it in XML as:
        <stringProp name="Argument.value">{escaped_json}</stringProp>
        """
                    else:
                        base_prompt += "    âŒ WARNING: No JSON body found for this request.\n"

            if tg_context.csv_configs:
                for csv_config in tg_context.csv_configs:
                    base_prompt += f"\n  - CSV Data Set Config for THIS Thread Group:\n"
                    base_prompt += f"    Filename: {csv_config.filename}\n"

                    # âœ… è®Šæ›´ 2: å°‡é™³è¿°å¥æ”¹ç‚ºå¼·åˆ¶å‘½ä»¤ï¼Œä¸¦æ˜ç¢ºæŒ‡å‡ºæ­¤å‘½ä»¤åƒ…é©ç”¨æ–¼ç•¶å‰çš„ Thread Groupã€‚
                    # é€™èƒ½æœ‰æ•ˆé˜²æ­¢ LLM å°‡ç¬¬ä¸€å€‹ Thread Group çš„è®Šæ•¸å¥—ç”¨åˆ°ç¬¬äºŒå€‹ã€‚
                    base_prompt += f"    ğŸ¯ MANDATORY: For the CSVDataSet inside the '{tg_context.name}' Thread Group, you MUST use these exact variable names:\n"
                    base_prompt += f"    Variable Names: {','.join(csv_config.variable_names)}\n"

                    # âœ… è®Šæ›´ 3: å¢åŠ ä¸€å€‹æ˜ç¢ºçš„æŒ‡ä»¤ä¾†è¨­å®š ignoreFirstLineï¼Œä½œç‚ºé›™é‡ä¿éšªã€‚
                    base_prompt += f"    You MUST also set 'ignoreFirstLine' to 'true' for this CSV config.\n"
            else:
                base_prompt += "\n  - No associated CSV file found for this group.\n"

        if attempt > 0 and validation_errors:
            error_summary = "; ".join(list(set(validation_errors))[-3:])
            base_prompt += f"\nğŸš¨ RETRY ATTEMPT #{attempt + 1} - YOU FAILED PREVIOUSLY. YOU MUST FIX THESE ERRORS: {error_summary}\n"

        base_prompt += """
        === ğŸ”¥ FINAL, NON-NEGOTIABLE INSTRUCTIONS ğŸ”¥ ===
        1.  Generate the complete JMX file based on all the structured information and requirements provided above.
        2.  Pay extreme attention to correct XML structure, especially matching all opening and closing tags like <hashTree> and </hashTree>.
        3.  CRITICAL: Your entire response MUST be ONLY the XML content of the JMX file.
            - Start directly with `<?xml version="1.0" encoding="UTF-8"?>`.
            - End directly with `</jmeterTestPlan>`.
            - DO NOT include any explanations, comments, apologies, or markdown code blocks like ```xml.
        """

        self.logger.info(f"æç¤ºè©å»ºç«‹å®Œæˆï¼Œç¸½é•·åº¦: {len(base_prompt)}")
        return base_prompt

    def _validate_jmx_content_requirements(self, jmx_content: str, context: 'GenerationContext') -> Tuple[bool, str]:
        """
        é©—è­‰ JMX å…§å®¹æ˜¯å¦ç¬¦åˆéœ€æ±‚
        """
        errors = []

        try:
            # 1. æª¢æŸ¥ Body Data æ ¼å¼ (é€™éƒ¨åˆ†é‚è¼¯ä¸è®Š)
            if 'HTTPsampler.BodyData' in jmx_content and 'elementType="ElementProp"' in jmx_content:
                errors.append("ç™¼ç¾éŒ¯èª¤çš„ Body Data æ ¼å¼ï¼ˆHTTPsampler.BodyDataï¼‰ï¼Œæ‡‰ä½¿ç”¨ Arguments çµæ§‹")

            # 2. æª¢æŸ¥ HTTP Request Body Data å…§å®¹å®Œæ•´æ€§
            correct_body_pattern = r'<stringProp name="Argument\.value">(.*?)</stringProp>'
            body_matches = re.findall(correct_body_pattern, jmx_content, re.DOTALL)

            # æª¢æŸ¥æ˜¯å¦æœ‰ POST è«‹æ±‚ï¼Œä½†å®Œå…¨æ²’æœ‰ Body
            # æˆ‘å€‘å¯ä»¥å¾ context å¾—çŸ¥é æœŸæœ‰å¤šå°‘å€‹ HTTP Request
            expected_http_requests = sum(len(tg.http_requests) for tg in context.thread_groups)

            if expected_http_requests > 0 and not body_matches:
                # åƒ…ç•¶ JMX ä¸­ç¢ºå¯¦å­˜åœ¨ POST æ–¹æ³•çš„ Sampler æ™‚æ‰å ±éŒ¯
                if '<stringProp name="HTTPSampler.method">POST</stringProp>' in jmx_content:
                    errors.append("POST è«‹æ±‚ç¼ºå°‘ Body Data å…§å®¹")
            else:
                for i, body_content in enumerate(body_matches, 1):
                    clean_body = body_content.strip()
                    if not clean_body or clean_body.lower() == 'none':
                        errors.append(f"HTTP Request #{i} Body Data ç‚ºç©ºæˆ–ç‚º 'None'")
                    elif len(clean_body) < 10:
                        errors.append(f"HTTP Request #{i} Body Data å…§å®¹éçŸ­ï¼Œå¯èƒ½ä¸å®Œæ•´")

            # 3. ä½¿ç”¨ context é©—è­‰çµ„ä»¶æ˜¯å¦å­˜åœ¨
            # æª¢æŸ¥ Thread Group
            if context.thread_groups and '<ThreadGroup' not in jmx_content:
                errors.append("éœ€æ±‚ä¸­æåˆ° Thread Group ä½† JMX ä¸­æ‰¾ä¸åˆ°")

            # æª¢æŸ¥ HTTP Request
            if expected_http_requests > 0 and '<HTTPSamplerProxy' not in jmx_content:
                errors.append("éœ€æ±‚ä¸­æåˆ° HTTP Request ä½† JMX ä¸­æ‰¾ä¸åˆ°")

            # æª¢æŸ¥ CSV
            expected_csv_configs = sum(len(tg.csv_configs) for tg in context.thread_groups)
            if expected_csv_configs > 0 and '<CSVDataSet' not in jmx_content:
                errors.append("æœ‰æä¾› CSV æª”æ¡ˆä½† JMX ä¸­æ‰¾ä¸åˆ° CSV Data Set Config")

            # 4. æª¢æŸ¥ hashTree æ¨™ç±¤æ˜¯å¦åŒ¹é… (é€™éƒ¨åˆ†é‚è¼¯ä¸è®Š)
            open_hashtree = jmx_content.count('<hashTree>')
            close_hashtree = jmx_content.count('</hashTree>')
            if open_hashtree != close_hashtree:
                errors.append(f"hashTree æ¨™ç±¤ä¸åŒ¹é… (é–‹å§‹: {open_hashtree}, çµæŸ: {close_hashtree})")

        except Exception as e:
            # æ•ç²é©—è­‰éç¨‹ä¸­çš„ä»»ä½•å…¶ä»–ç¨‹å¼ç¢¼éŒ¯èª¤
            self.logger.error(f"å…§å®¹é©—è­‰å‡½æ•¸å…§éƒ¨ç™¼ç”ŸéŒ¯èª¤: {e}", exc_info=True)
            errors.append(f"é©—è­‰éç¨‹ç™¼ç”Ÿå…§éƒ¨éŒ¯èª¤: {str(e)}")

        if errors:
            return False, "; ".join(errors)
        else:
            return True, "å…§å®¹é©—è­‰é€šé"

    def _format_csv_info_safe(self, csv_configs: Dict) -> str:
        """é€šç”¨æ ¼å¼åŒ– CSV è³‡è¨Š"""
        if not csv_configs:
            return "ç„¡å¯ç”¨çš„ CSV æª”æ¡ˆ\n"

        formatted_info = ""
        for filename, config in csv_configs.items():
            if 'error' in config:
                formatted_info += f"æª”æ¡ˆ: {filename} (éŒ¯èª¤: {config['error']})\n"
                continue

            formatted_info += f"æª”æ¡ˆåç¨±: {filename}\n"
            formatted_info += f"è®Šæ•¸åç¨±: {','.join(config.get('headers', []))}\n"
            formatted_info += f"ç¸½è¡Œæ•¸: {config.get('total_rows', 0)}\n"

            # é¡¯ç¤ºæ¨£æœ¬è³‡æ–™
            sample_data = config.get('sample_data', [])
            if sample_data:
                formatted_info += "æ¨£æœ¬è³‡æ–™:\n"
                for i, row in enumerate(sample_data[:3], 1):
                    formatted_info += f"  ç¬¬{i}è¡Œ: {dict(zip(config.get('headers', []), row))}\n"

            formatted_info += "---\n"

        return formatted_info

    def _extract_and_clean_jmx(self, response: str, context: GenerationContext) -> str:
        """
        æå–ã€æ¸…ç†ä¸¦æ™ºèƒ½ä¿®æ­£ JMX å…§å®¹ - é‡æ§‹å¾Œä½¿ç”¨ GenerationContextã€‚
        """
        self.logger.info("=== æ­¥é©Ÿ 4: æå–ã€æ¸…ç†èˆ‡ä¿®æ­£ JMX ===")
        jmx_content = self._extract_jmx_from_response(response)
        cleaned_content = self._clean_xml_declarations(jmx_content)
        fixed_content = self._fix_testplan_structure(cleaned_content)
        body_fixed_content = self._fix_body_data_format(fixed_content)

        # ã€æ ¸å¿ƒä¿®æ”¹ã€‘æ™ºèƒ½ä¿®æ­£ CSV è¨­å®šç¾åœ¨å‚³å…¥ context
        csv_fixed_content = self._intelligently_fix_csv_settings(body_fixed_content, context)

        final_content = self._fix_basic_xml_issues(csv_fixed_content)
        return final_content

    def _intelligently_fix_csv_settings(self, jmx_content: str, context: GenerationContext) -> str:
        """
        æ™ºèƒ½æ ¡é©—ä¸¦ä¿®æ­£ JMX ä¸­çš„ CSV Data Set Config è¨­å®šã€‚
        ç¾åœ¨æœƒå¼·åˆ¶å°‡æ‰€æœ‰è¢«ç”¨æ–¼åƒæ•¸åŒ–çš„ CSV çš„ ignoreFirstLine è¨­ç‚º trueã€‚
        """
        try:
            self.logger.info("====== é–‹å§‹æ™ºèƒ½ä¿®æ­£ CSV è¨­å®š ======")

            # æ‰¾å‡ºæ‰€æœ‰åœ¨ context ä¸­è¢«ç”¨æ–¼åƒæ•¸åŒ–çš„ CSV æª”æ¡ˆåç¨±
            parameterized_csv_files = set()
            for tg in context.thread_groups:
                for req in tg.http_requests:
                    if req.is_parameterized:
                        for csv_conf in tg.csv_configs:
                            parameterized_csv_files.add(csv_conf.filename)

            if not parameterized_csv_files:
                self.logger.info("ä¸Šä¸‹æ–‡ä¸­ç„¡åƒæ•¸åŒ–çš„ CSV è³‡è¨Šï¼Œè·³éä¿®æ­£ã€‚")
                return jmx_content

            self.logger.info(f"éœ€è¦å¼·åˆ¶ä¿®æ­£ ignoreFirstLine=true çš„ CSV æª”æ¡ˆ: {parameterized_csv_files}")

            csv_dataset_pattern = re.compile(r'(<CSVDataSet.*?>.*?</CSVDataSet>)', re.DOTALL)
            modified_content = jmx_content

            # ä½¿ç”¨ re.sub çš„ callback å‡½å¼ä¾†é€²è¡Œæ›¿æ›ï¼Œæ›´å®‰å…¨
            def replace_callback(match):
                csv_block = match.group(1)
                filename_match = re.search(r'<stringProp name="filename">(.*?)</stringProp>', csv_block)

                if filename_match:
                    csv_filename = filename_match.group(1)
                    # å¦‚æœé€™å€‹ CSV æª”æ¡ˆåœ¨æˆ‘å€‘çš„å¾…ä¿®æ­£åˆ—è¡¨ä¸­
                    if csv_filename in parameterized_csv_files:
                        # æª¢æŸ¥ä¸¦å¼·åˆ¶ä¿®æ­£ ignoreFirstLine
                        if '<boolProp name="ignoreFirstLine">false</boolProp>' in csv_block:
                            self.logger.warning(f"åµæ¸¬åˆ°é‚è¼¯çŸ›ç›¾ï¼å¼·åˆ¶ä¿®æ­£ '{csv_filename}' çš„ ignoreFirstLine ç‚º trueã€‚")
                            return csv_block.replace(
                                '<boolProp name="ignoreFirstLine">false</boolProp>',
                                '<boolProp name="ignoreFirstLine">true</boolProp>'
                            )
                # å¦‚æœä¸éœ€ä¿®æ”¹ï¼Œè¿”å›åŸå§‹å€å¡Š
                return csv_block

            modified_content = csv_dataset_pattern.sub(replace_callback, jmx_content)

            self.logger.info("====== æ™ºèƒ½ä¿®æ­£ CSV è¨­å®šçµæŸ ======")
            return modified_content

        except Exception as e:
            self.logger.error(f"æ™ºèƒ½ä¿®æ­£ CSV è¨­å®šæ™‚ç™¼ç”Ÿåš´é‡éŒ¯èª¤: {e}", exc_info=True)
            return jmx_content

    def _fix_testplan_structure(self, content: str) -> str:
        """ä¿®å¾© TestPlan çµæ§‹ä¸­çš„å¸¸è¦‹å•é¡Œ"""
        try:
            # ä¿®å¾© TestPlan.user_define_classpath çš„ elementType
            pattern = r'<elementProp name="TestPlan\.user_define_classpath" elementType="collectionProp">'
            replacement = '<elementProp name="TestPlan.user_define_classpath" elementType="Arguments" guiclass="ArgumentsPanel" testclass="Arguments" enabled="true">'
            content = re.sub(pattern, replacement, content)

            # ä¿®å¾©å°æ‡‰çš„ collectionProp çµæ§‹
            pattern = r'<collectionProp name="TestPlan\.user_define_classpath"/>'
            replacement = '<collectionProp name="Arguments.arguments"/>'
            content = re.sub(pattern, replacement, content)

            self.logger.info("TestPlan çµæ§‹ä¿®å¾©å®Œæˆ")
            return content

        except Exception as e:
            self.logger.error(f"ä¿®å¾© TestPlan çµæ§‹å¤±æ•—: {e}")
            return content

    def _fix_body_data_format(self, content: str) -> str:
        """ä¿®æ­£ HTTP Request Body Data æ ¼å¼"""
        try:
            import re

            # æŸ¥æ‰¾éŒ¯èª¤çš„ Body Data æ ¼å¼
            wrong_pattern = r'<elementProp name="HTTPsampler\.BodyData" elementType="ElementProp">(.*?)</elementProp>'
            matches = re.findall(wrong_pattern, content, re.DOTALL)

            if not matches:
                self.logger.info("æœªç™¼ç¾éœ€è¦ä¿®æ­£çš„ Body Data æ ¼å¼")
                return content

            self.logger.info(f"ç™¼ç¾ {len(matches)} å€‹éœ€è¦ä¿®æ­£çš„ Body Data æ ¼å¼")

            # é€å€‹ä¿®æ­£æ¯å€‹éŒ¯èª¤æ ¼å¼
            fixed_content = content
            for i, match_content in enumerate(matches):
                # æå– Body Data çš„å€¼
                value_pattern = r'<stringProp name="ElementProp\.value">(.*?)</stringProp>'
                value_matches = re.findall(value_pattern, match_content, re.DOTALL)

                if value_matches:
                    body_value = value_matches[0]

                    # æ§‹å»ºæ­£ç¢ºçš„æ ¼å¼
                    correct_format = f"""<boolProp name="HTTPSampler.postBodyRaw">true</boolProp>
      <elementProp name="HTTPsampler.Arguments" elementType="Arguments">
        <collectionProp name="Arguments.arguments">
          <elementProp name="" elementType="HTTPArgument">
            <boolProp name="HTTPArgument.always_encode">false</boolProp>
            <stringProp name="Argument.value">{body_value}</stringProp>
            <stringProp name="Argument.metadata">=</stringProp>
          </elementProp>
        </collectionProp>
      </elementProp>"""

                    # æ›¿æ›éŒ¯èª¤æ ¼å¼
                    wrong_full_pattern = r'<elementProp name="HTTPsampler\.BodyData" elementType="ElementProp">.*?</elementProp>'
                    fixed_content = re.sub(wrong_full_pattern, correct_format, fixed_content, count=1, flags=re.DOTALL)

                    self.logger.info(f"å·²ä¿®æ­£ç¬¬ {i + 1} å€‹ Body Data æ ¼å¼")

            return fixed_content

        except Exception as e:
            self.logger.error(f"ä¿®æ­£ Body Data æ ¼å¼å¤±æ•—: {e}")
            return content

    def _clean_xml_declarations(self, content: str) -> str:
        """çµ±ä¸€çš„ XML è²æ˜æ¸…ç†æ–¹æ³•"""
        if not content or not isinstance(content, str):
            return content

        try:
            # æ–¹æ³•1: ä½¿ç”¨æ­£å‰‡è¡¨é”å¼ç§»é™¤æ‰€æœ‰ XML è²æ˜ï¼Œç„¶å¾Œæ·»åŠ å–®ä¸€è²æ˜
            cleaned = re.sub(r'<\?xml[^>]*\?>\s*', '', content)
            result = '<?xml version="1.0" encoding="UTF-8"?>\n' + cleaned.lstrip()

            # é©—è­‰çµæœ
            xml_count = result.count('<?xml')
            if xml_count == 1:
                self.logger.info("XML è²æ˜æ¸…ç†æˆåŠŸ (æ­£å‰‡è¡¨é”å¼æ–¹æ³•)")
                return result
            else:
                self.logger.warning(f"æ­£å‰‡è¡¨é”å¼æ–¹æ³•å¤±æ•—ï¼ŒXML è²æ˜æ•¸é‡: {xml_count}ï¼Œå˜—è©¦è¡Œåˆ†å‰²æ–¹æ³•")

        except Exception as e:
            self.logger.warning(f"æ­£å‰‡è¡¨é”å¼æ¸…ç†å¤±æ•—: {e}ï¼Œå˜—è©¦è¡Œåˆ†å‰²æ–¹æ³•")

        try:
            # æ–¹æ³•2: ä½¿ç”¨è¡Œåˆ†å‰²æ–¹æ³• (åŸ _force_single_xml_declaration çš„é‚è¼¯)
            lines = content.split('\n')
            content_lines = [line for line in lines if not line.strip().startswith('<?xml')]
            result = '<?xml version="1.0" encoding="UTF-8"?>\n' + '\n'.join(content_lines)

            # å†æ¬¡é©—è­‰
            xml_count = result.count('<?xml')
            if xml_count == 1:
                self.logger.info("XML è²æ˜æ¸…ç†æˆåŠŸ (è¡Œåˆ†å‰²æ–¹æ³•)")
                return result
            else:
                self.logger.error(f"è¡Œåˆ†å‰²æ–¹æ³•ä¹Ÿå¤±æ•—ï¼ŒXML è²æ˜æ•¸é‡: {xml_count}")

        except Exception as e:
            self.logger.error(f"è¡Œåˆ†å‰²æ¸…ç†ä¹Ÿå¤±æ•—: {e}")

        # æœ€å¾Œçš„å‚™ç”¨æ–¹æ³•ï¼šå¼·åˆ¶æ›¿æ›
        try:
            # æ‰¾åˆ°ç¬¬ä¸€å€‹é XML è²æ˜çš„å…§å®¹
            content_start = 0
            for i, char in enumerate(content):
                if content[i:i + 5] == '<?xml':
                    # æ‰¾åˆ° XML è²æ˜çš„çµæŸ
                    end_pos = content.find('?>', i)
                    if end_pos != -1:
                        content_start = end_pos + 2
                        # è·³éç©ºç™½å­—ç¬¦
                        while content_start < len(content) and content[content_start].isspace():
                            content_start += 1
                    break
                elif not char.isspace():
                    break

            clean_content = content[content_start:] if content_start > 0 else content
            result = '<?xml version="1.0" encoding="UTF-8"?>\n' + clean_content

            self.logger.info("XML è²æ˜æ¸…ç†æˆåŠŸ (å‚™ç”¨æ–¹æ³•)")
            return result

        except Exception as e:
            self.logger.error(f"æ‰€æœ‰ XML æ¸…ç†æ–¹æ³•éƒ½å¤±æ•—: {e}")
            return content

    def _fix_basic_xml_issues(self, content: str) -> str:
        """ä¿®å¾©åŸºæœ¬çš„ XML å•é¡Œï¼ˆä¸ç ´å£çµæ§‹ï¼‰"""
        try:
            # åªä¿®å¾©æ˜é¡¯çš„å•é¡Œï¼Œä¸é€²è¡Œç ´å£æ€§çš„è½‰ç¾©
            fixed = content

            # ä¿®å¾©æœªé–‰åˆçš„è‡ªé–‰åˆæ¨™ç±¤ï¼ˆåªé‡å°ç‰¹å®šæ¨™ç±¤ï¼‰
            self_closing_tags = ['collectionProp', 'stringProp', 'boolProp', 'intProp']
            for tag in self_closing_tags:
                # ä¿®å¾©æœªé–‰åˆçš„ç©ºæ¨™ç±¤
                pattern = f'<{tag}([^>]*?)(?<!/)>\\s*</{tag}>'
                replacement = f'<{tag}\\1/>'
                fixed = re.sub(pattern, replacement, fixed)

            return fixed

        except Exception as e:
            self.logger.error(f"ä¿®å¾©åŸºæœ¬ XML å•é¡Œå¤±æ•—: {e}")
            return content

    def _validate_jmx_content(self, content: str) -> bool:
        """é©—è­‰ JMX å…§å®¹"""
        if not content or not content.strip():
            return False

        try:
            # æª¢æŸ¥åŸºæœ¬çµæ§‹
            if not content.strip().startswith('<?xml'):
                return False

            if '</jmeterTestPlan>' not in content:
                return False

            # æª¢æŸ¥ XML è²æ˜æ•¸é‡
            if content.count('<?xml') != 1:
                return False

            # å˜—è©¦è§£æ XML
            root = ET.fromstring(content)

            # æª¢æŸ¥æ ¹å…ƒç´ 
            if root.tag != 'jmeterTestPlan':
                return False

            # æª¢æŸ¥æ˜¯å¦æœ‰ TestPlan
            if root.find('.//TestPlan') is None:
                return False

            self.logger.info("JMX å…§å®¹é©—è­‰é€šé")
            return True

        except ET.ParseError as e:
            self.logger.error(f"XML è§£æå¤±æ•—: {e}")
            return False
        except Exception as e:
            self.logger.error(f"JMX é©—è­‰å¤±æ•—: {e}")
            return False

    def _get_fallback_jmx(self, requirements: str, processed_files: Dict = None) -> str:
        """ç²å–æ™ºèƒ½å‚™ç”¨ JMX æ¨¡æ¿"""

        # å¾éœ€æ±‚æå–åŸºæœ¬è³‡è¨Š
        test_name = self._extract_test_name_from_requirements(requirements)

        # æª¢æŸ¥æ˜¯å¦éœ€è¦å¤šå€‹ Thread Group
        thread_group_count = max(1, requirements.lower().count('thread group'))

        # æ§‹å»ºå…§å®¹
        content_parts = []

        # æ·»åŠ  Header Managerï¼ˆå¦‚æœéœ€æ±‚ä¸­æåˆ°ï¼‰
        if 'header manager' in requirements.lower() or 'content-type' in requirements.lower() or 'application/json' in requirements.lower():
            header_manager = """<HeaderManager guiclass="HeaderPanel" testclass="HeaderManager" testname="HTTP Header Manager" enabled="true">
            <collectionProp name="HeaderManager.headers">
              <elementProp name="" elementType="Header">
                <stringProp name="Header.name">Content-Type</stringProp>
                <stringProp name="Header.value">application/json</stringProp>
              </elementProp>
            </collectionProp>
          </HeaderManager>
          <hashTree/>"""
            content_parts.append(header_manager)

        # æ·»åŠ  Thread Groups
        for i in range(thread_group_count):
            thread_group_content = []

            # æ·»åŠ  CSV Data Set Configï¼ˆå¦‚æœæœ‰ CSV æª”æ¡ˆï¼‰
            if processed_files and processed_files.get("csv_configs"):
                csv_configs = processed_files["csv_configs"]
                if i < len(csv_configs):
                    csv_config = csv_configs[i]
                    filename = csv_config.get('filename', f'data{i + 1}.csv')
                    variable_names = csv_config.get('variable_names', [])

                    csv_element = f"""<CSVDataSet guiclass="testBeanGUI" testclass="CSVDataSet" testname="CSV Data Set Config" enabled="true">
              <stringProp name="delimiter">,</stringProp>
              <stringProp name="fileEncoding">UTF-8</stringProp>
              <stringProp name="filename">{filename}</stringProp>
              <boolProp name="ignoreFirstLine">false</boolProp>
              <boolProp name="quotedData">false</boolProp>
              <boolProp name="recycle">true</boolProp>
              <stringProp name="shareMode">shareMode.all</stringProp>
              <boolProp name="stopThread">false</boolProp>
              <stringProp name="variableNames">{','.join(variable_names)}</stringProp>
            </CSVDataSet>
            <hashTree/>"""
                    thread_group_content.append(csv_element)

            # æ§‹å»º HTTP Request çš„ Body Data
            json_body = ""
            if processed_files and processed_files.get("json_contents"):
                json_files = list(processed_files["json_contents"].items())
                if i < len(json_files):
                    filename, content = json_files[i]
                    json_body = content.get('raw_content', '') if content else ''

            # å¦‚æœæ²’æœ‰ JSON å…§å®¹ï¼Œä½¿ç”¨åŸºæœ¬çµæ§‹
            if not json_body:
                json_body = '''{
      "message": "test request",
      "data": {
        "param1": "${param1}",
        "param2": "${param2}"
      }
    }'''

            # XML è½‰ç¾©è™•ç†
            escaped_json = json_body.replace('&', '&amp;').replace('<', '&lt;').replace('>', '&gt;').replace('"',
                                                                                                             '&quot;')

            # æ§‹å»º HTTP Requestï¼ˆä½¿ç”¨æ­£ç¢ºçš„ Arguments æ ¼å¼ï¼‰
            http_request = f"""<HTTPSamplerProxy guiclass="HttpTestSampleGui" testclass="HTTPSamplerProxy" testname="HTTP Request {i + 1}" enabled="true">
            <boolProp name="HTTPSampler.postBodyRaw">true</boolProp>
            <elementProp name="HTTPsampler.Arguments" elementType="Arguments">
              <collectionProp name="Arguments.arguments">
                <elementProp name="" elementType="HTTPArgument">
                  <boolProp name="HTTPArgument.always_encode">false</boolProp>
                  <stringProp name="Argument.value">{escaped_json}</stringProp>
                  <stringProp name="Argument.metadata">=</stringProp>
                </elementProp>
              </collectionProp>
            </elementProp>
            <stringProp name="HTTPSampler.domain">api.example.com</stringProp>
            <stringProp name="HTTPSampler.port"></stringProp>
            <stringProp name="HTTPSampler.protocol">https</stringProp>
            <stringProp name="HTTPSampler.contentEncoding">UTF-8</stringProp>
            <stringProp name="HTTPSampler.path">/api/test</stringProp>
            <stringProp name="HTTPSampler.method">{"POST" if json_body else "GET"}</stringProp>
            <boolProp name="HTTPSampler.follow_redirects">true</boolProp>
            <boolProp name="HTTPSampler.auto_redirects">false</boolProp>
            <boolProp name="HTTPSampler.use_keepalive">true</boolProp>
            <boolProp name="HTTPSampler.save_response_data">false</boolProp>
          </HTTPSamplerProxy>
          <hashTree/>"""
            thread_group_content.append(http_request)

            # æ·»åŠ  Response Assertionï¼ˆå¦‚æœéœ€æ±‚ä¸­æåˆ°ï¼‰
            if 'response assertion' in requirements.lower() or 'assertion' in requirements.lower():
                response_assertion = """<ResponseAssertion guiclass="AssertionGui" testclass="ResponseAssertion" testname="Response Assertion" enabled="true">
              <collectionProp name="Asserion.test_strings">
                <stringProp name="49586">200</stringProp>
              </collectionProp>
              <stringProp name="Assertion.custom_message"></stringProp>
              <stringProp name="Assertion.test_field">Assertion.response_code</stringProp>
              <boolProp name="Assertion.assume_success">false</boolProp>
              <intProp name="Assertion.test_type">2</intProp>
            </ResponseAssertion>
            <hashTree/>"""
                thread_group_content.append(response_assertion)

            # æ§‹å»ºå®Œæ•´çš„ Thread Group
            thread_group = self.jmx_templates["thread_group"].format(
                name=f"Thread Group {i + 1}",
                loops="${__P(loop,1)}",
                threads="${__P(threads,1)}",
                ramp_time="${__P(rampUp,1)}",
                scheduler="false",
                duration="",
                delay="",
                extra_content='\n        '.join(thread_group_content)
            )
            content_parts.append(thread_group)

        # æ·»åŠ  View Results Treeï¼ˆå¦‚æœéœ€æ±‚ä¸­æåˆ°ï¼‰
        if 'view results tree' in requirements.lower() or 'results tree' in requirements.lower():
            listener = """<ResultCollector guiclass="ViewResultsFullVisualizer" testclass="ResultCollector" testname="View Results Tree" enabled="true">
            <boolProp name="ResultCollector.error_logging">false</boolProp>
            <objProp>
              <name>saveConfig</name>
              <value class="SampleSaveConfiguration">
                <time>true</time>
                <latency>true</latency>
                <timestamp>true</timestamp>
                <success>true</success>
                <label>true</label>
                <code>true</code>
                <message>true</message>
                <threadName>true</threadName>
                <dataType>true</dataType>
                <encoding>false</encoding>
                <assertions>true</assertions>
                <subresults>true</subresults>
                <responseData>false</responseData>
                <samplerData>false</samplerData>
                <xml>false</xml>
                <fieldNames>true</fieldNames>
                <responseHeaders>false</responseHeaders>
                <requestHeaders>false</requestHeaders>
                <responseDataOnError>false</responseDataOnError>
                <saveAssertionResultsFailureMessage>true</saveAssertionResultsFailureMessage>
                <assertionsResultsToSave>0</assertionsResultsToSave>
                <bytes>true</bytes>
                <sentBytes>true</sentBytes>
                <url>true</url>
                <threadCounts>true</threadCounts>
                <idleTime>true</idleTime>
                <connectTime>true</connectTime>
              </value>
            </objProp>
            <stringProp name="filename"></stringProp>
          </ResultCollector>
          <hashTree/>"""
            content_parts.append(listener)

        return self._create_jmx_from_template(
            test_name=test_name,
            comments=f"æ™ºèƒ½å‚™ç”¨æ¸¬è©¦è¨ˆåŠƒ - åŸºæ–¼éœ€æ±‚è‡ªå‹•ç”Ÿæˆ",
            content='\n      '.join(content_parts)
        )

    def _extract_test_name_from_requirements(self, requirements: str) -> str:
        """å¾éœ€æ±‚ä¸­æå–æ¸¬è©¦åç¨±"""
        if len(requirements) > 10:
            words = requirements.split()[:3]
            return " ".join(words) + " Test"
        return "Generated Test Plan"

    def _extract_jmx_from_response(self, response: str) -> str:
        """å¾æ¨¡å‹éŸ¿æ‡‰ä¸­æå– JMX å…§å®¹"""
        if not response or not response.strip():
            raise ValueError("æ¨¡å‹éŸ¿æ‡‰ç‚ºç©º")

        try:
            # æ¸…ç†éŸ¿æ‡‰å…§å®¹
            cleaned_response = response.strip()

            # è™•ç†è½‰ç¾©çš„ XML å…§å®¹
            unescaped = cleaned_response.replace('&lt;', '<').replace('&gt;', '>').replace('&quot;', '"')

            # å˜—è©¦æå– XML å…§å®¹çš„æ¨¡å¼
            patterns = [
                r'<\?xml.*?</jmeterTestPlan>',
                r'<jmeterTestPlan.*?</jmeterTestPlan>',
                r'```xml\s*(.*?)\s*```',
                r'```\s*(.*?)\s*```'
            ]

            for pattern in patterns:
                matches = re.findall(pattern, unescaped, re.DOTALL | re.IGNORECASE)
                if matches:
                    content = matches[0].strip()

                    # ç¢ºä¿å…§å®¹ä»¥ <?xml é–‹é ­
                    if not content.startswith('<?xml') and '<jmeterTestPlan' in content:
                        content = '<?xml version="1.0" encoding="UTF-8"?>\n' + content

                    # åŸºæœ¬é©—è­‰
                    if self._basic_xml_check(content):
                        return content

            raise ValueError("ç„¡æ³•å¾éŸ¿æ‡‰ä¸­æå–æœ‰æ•ˆçš„ JMX å…§å®¹")

        except Exception as e:
            self.logger.error(f"æå– JMX å…§å®¹å¤±æ•—: {e}")
            raise

    def _basic_xml_check(self, content: str) -> bool:
        """åŸºæœ¬çš„ XML æª¢æŸ¥"""
        try:
            return (content.strip().startswith('<?xml') or content.strip().startswith('<jmeterTestPlan')) and \
                '</jmeterTestPlan>' in content and \
                len(content) > 100
        except:
            return False

    def _process_csv_files(self, files_data: List[Dict]) -> Dict[str, Dict]:
        """
        è™•ç†æ‰€æœ‰ä¸Šå‚³çš„ CSV æª”æ¡ˆã€‚
        æ­¤å‡½æ•¸è¿­ä»£æ‰€æœ‰å‚³å…¥çš„æª”æ¡ˆè³‡æ–™ï¼Œç¯©é¸å‡º CSV æª”æ¡ˆï¼Œ
        ä¸¦å‘¼å« _safe_process_single_csv é€²è¡Œå–®ä¸€æª”æ¡ˆçš„è§£æã€‚
        Args:
            files_data: ä¸€å€‹æª”æ¡ˆå­—å…¸çš„åˆ—è¡¨ï¼Œæ¯å€‹å­—å…¸ä»£è¡¨ä¸€å€‹ä¸Šå‚³çš„æª”æ¡ˆã€‚

        Returns:
            ä¸€å€‹å­—å…¸ï¼Œå…¶ä¸­ï¼š
            - Key æ˜¯ CSV æª”æ¡ˆçš„åç¨± (e.g., "MOCK-B-CHECKIDC001.csv")ã€‚
            - Value æ˜¯ _safe_process_single_csv è¿”å›çš„è©³ç´°è³‡è¨Šå­—å…¸ã€‚
        """
        csv_configs = {}
        if not files_data:
            self.logger.warning("æ²’æœ‰å‚³å…¥ä»»ä½•æª”æ¡ˆè³‡æ–™ï¼Œç„¡æ³•è™•ç† CSV æª”æ¡ˆã€‚")
            return csv_configs

        self.logger.info(f"é–‹å§‹è™•ç† {len(files_data)} å€‹æª”æ¡ˆä¸­çš„ CSV æª”æ¡ˆ...")
        for file_info in files_data:
            try:
                # å…¼å®¹ä¸åŒå‰ç«¯å‚³å…¥çš„æª”å key
                filename = file_info.get('filename', file_info.get('name', ''))
                if not filename or not filename.lower().endswith('.csv'):
                    continue

                self.logger.info(f"ç™¼ç¾ CSV æª”æ¡ˆ: '{filename}'ï¼Œé€²è¡Œè§£æ...")
                config = self._safe_process_single_csv(file_info)
                if config:
                    # ä½¿ç”¨æª”åä½œç‚º keyï¼Œæ–¹ä¾¿å¾ŒçºŒå¿«é€ŸæŸ¥æ‰¾
                    csv_configs[filename] = config
                else:
                    self.logger.warning(f"æª”æ¡ˆ '{filename}' è§£æå¤±æ•—æˆ–ç‚ºç©ºï¼Œå·²è·³éã€‚")

            except Exception as e:
                # æ•ç²è¿´åœˆä¸­çš„æ„å¤–éŒ¯èª¤ï¼Œç¢ºä¿ä¸€å€‹æª”æ¡ˆçš„å¤±æ•—ä¸æœƒå½±éŸ¿å…¶ä»–æª”æ¡ˆ
                filename_for_log = file_info.get('filename', 'æœªçŸ¥æª”æ¡ˆ')
                self.logger.error(f"è™•ç†æª”æ¡ˆ '{filename_for_log}' æ™‚ç™¼ç”Ÿæœªé æœŸéŒ¯èª¤: {e}", exc_info=True)

        self.logger.info(f"CSV æª”æ¡ˆè™•ç†å®Œæˆï¼Œå…±æˆåŠŸè§£æ {len(csv_configs)} å€‹æª”æ¡ˆã€‚")
        return csv_configs

    def _safe_process_single_csv(self, file_info: Dict) -> Optional[Dict]:
        """
        å®‰å…¨ä¸”å¥å£¯åœ°è™•ç†å–®ä¸€ CSV æª”æ¡ˆçš„å…§å®¹ã€‚

        æ­¤å‡½æ•¸ä½¿ç”¨æ¨™æº–çš„ `io` å’Œ `csv` æ¨¡çµ„ï¼Œå°‡æª”æ¡ˆå…§å®¹å­—ä¸²è½‰æ›ç‚º
        çµæ§‹åŒ–çš„è³‡è¨Šï¼ŒåŒ…æ‹¬æ¨™é ­ã€è³‡æ–™è¡Œæ•¸å’ŒåŸå§‹å…§å®¹ã€‚

        Args:
            file_info: ä»£è¡¨å–®ä¸€æª”æ¡ˆçš„å­—å…¸ã€‚

        Returns:
            ä¸€å€‹åŒ…å« CSV è©³ç´°è³‡è¨Šçš„å­—å…¸ï¼Œå¦‚æœè™•ç†å¤±æ•—å‰‡è¿”å› Noneã€‚
            æˆåŠŸæ™‚è¿”å›çš„å­—å…¸çµæ§‹ï¼š
            {
                'headers': List[str],      # æ¸…ç†éçš„æ¨™é ­åˆ—è¡¨
                'sample_data': List[List[str]], # æœ€å¤š 5 è¡Œçš„æ¨£æœ¬è³‡æ–™
                'total_rows': int,         # è³‡æ–™è¡Œçš„ç¸½æ•¸ (ä¸å«æ¨™é ­)
                'filepath': str,           # æª”æ¡ˆè·¯å¾‘/åç¨±
                'raw_content': str         # æœªç¶“ä¿®æ”¹çš„åŸå§‹æª”æ¡ˆå…§å®¹å­—ä¸²
            }
        """
        filename = file_info.get('filename', file_info.get('name', 'unknown.csv'))

        try:
            # å¾å¤šå€‹å¯èƒ½çš„ key ä¸­ç²å–æª”æ¡ˆå…§å®¹å­—ä¸²
            content_str = ''
            if 'content' in file_info and isinstance(file_info['content'], str):
                content_str = file_info['content']
            elif 'data' in file_info and isinstance(file_info['data'], str):
                content_str = file_info['data']

            if not content_str or not content_str.strip():
                self.logger.warning(f"CSV æª”æ¡ˆ '{filename}' å…§å®¹ç‚ºç©ºã€‚")
                return None

            # ä½¿ç”¨ io.StringIO å°‡å­—ä¸²å…§å®¹æ¨¡æ“¬æˆä¸€å€‹æª”æ¡ˆï¼Œä»¥ä¾¿ csv æ¨¡çµ„å¯ä»¥è®€å–
            file_stream = io.StringIO(content_str)

            # ä½¿ç”¨ csv.reader é€²è¡Œè§£æï¼Œé€™æ˜¯è™•ç† CSV çš„æ¨™æº–åšæ³•
            csv_reader = csv.reader(file_stream)

            # è®€å–ç¬¬ä¸€è¡Œä½œç‚ºæ¨™é ­
            try:
                headers = next(csv_reader)
                # æ¸…ç†æ¨™é ­ï¼Œå»é™¤å‰å¾Œç©ºæ ¼å’Œç©ºå­—ä¸²
                cleaned_headers = [h.strip() for h in headers if h and h.strip()]
            except StopIteration:
                # æª”æ¡ˆç‚ºç©ºï¼Œæ²’æœ‰ä»»ä½•è¡Œ
                self.logger.warning(f"CSV æª”æ¡ˆ '{filename}' ç‚ºç©ºï¼Œç„¡æ³•è®€å–æ¨™é ­ã€‚")
                return {
                    'headers': [], 'sample_data': [], 'total_rows': 0,
                    'filepath': filename, 'raw_content': content_str
                }

            # è®€å–å‰©é¤˜çš„æ‰€æœ‰è³‡æ–™è¡Œ
            data_rows = list(csv_reader)
            total_data_rows = len(data_rows)

            # æå–æœ€å¤š 5 è¡Œä½œç‚ºæ¨£æœ¬è³‡æ–™
            sample_data = data_rows[:5]

            self.logger.info(
                f"âœ… CSV è§£ææˆåŠŸ: '{filename}' -> æ¨™é ­: {cleaned_headers}, è³‡æ–™è¡Œæ•¸: {total_data_rows}"
            )

            return {
                'headers': cleaned_headers,
                'sample_data': sample_data,
                'total_rows': total_data_rows,
                'filepath': filename,
                'raw_content': content_str  # åŒ…å«åŸå§‹å…§å®¹ï¼Œç”¨æ–¼å¾ŒçºŒé‚è¼¯åˆ¤æ–·
            }

        except csv.Error as e:
            self.logger.error(f"è§£æ CSV æª”æ¡ˆ '{filename}' æ™‚ç™¼ç”Ÿæ ¼å¼éŒ¯èª¤: {e}")
            return None
        except Exception as e:
            self.logger.error(f"è™•ç†å–®ä¸€ CSV æª”æ¡ˆ '{filename}' æ™‚ç™¼ç”Ÿæœªé æœŸéŒ¯èª¤: {e}", exc_info=True)
            return None

    def _clean_csv_header(self, header: str) -> str:
        """æ¸…ç† CSV æ¨™é ­"""
        if not header or str(header).lower() in ['nan', 'null', 'none', '']:
            return ''
        return str(header).strip().strip('"').strip("'")

    def _clean_csv_value(self, value: str) -> str:
        """æ¸…ç† CSV å€¼"""
        if not value or str(value).lower() in ['nan', 'null', 'none', '']:
            return ''

        try:
            float_val = float(value)
            if math.isnan(float_val) or math.isinf(float_val):
                return ''
        except (ValueError, TypeError):
            pass

        return str(value).strip().strip('"').strip("'")

    def _process_json_files(self, files_data: List[Dict]) -> Dict:
        """è™•ç† JSON æª”æ¡ˆ"""
        json_contents = {}

        if not files_data:
            return json_contents

        for file_info in files_data:
            try:
                filename = file_info.get('filename', file_info.get('name', ''))
                if not filename or not filename.lower().endswith('.json'):
                    continue

                content = self._safe_process_single_json(file_info)
                if content:
                    json_contents[filename] = content

            except Exception as e:
                self.logger.error(f"è™•ç† JSON æª”æ¡ˆ {filename} å¤±æ•—: {e}")
                json_contents[filename] = {'error': str(e), 'raw_content': '', 'variables': []}

        return json_contents

    def _safe_process_single_json(self, file_info: Dict) -> Optional[Dict]:
        """å®‰å…¨åœ°è™•ç†å–®ä¸€ JSON æª”æ¡ˆ - å¢å¼·ç‰ˆ"""
        try:
            self.logger.info(f"è™•ç† JSON æª”æ¡ˆ: {file_info.get('filename', file_info.get('name', 'æœªçŸ¥'))}")
            self.logger.info(f"æª”æ¡ˆè³‡è¨Šéµå€¼: {list(file_info.keys())}")

            content = ''

            # ğŸ¯ å¤šé‡ç­–ç•¥ç²å–å…§å®¹
            strategies = [
                ('content', lambda x: x.get('content')),
                ('data', lambda x: self._extract_data_content(x.get('data'))),
                ('body', lambda x: x.get('body')),
                ('text', lambda x: x.get('text')),
                ('raw_content', lambda x: x.get('raw_content')),
            ]

            for strategy_name, extractor in strategies:
                try:
                    extracted = extractor(file_info)
                    if extracted:
                        content = str(extracted) if not isinstance(extracted, str) else extracted
                        self.logger.info(f"âœ… ä½¿ç”¨ç­–ç•¥ '{strategy_name}' æˆåŠŸç²å–å…§å®¹ï¼Œé•·åº¦: {len(content)}")
                        break
                except Exception as e:
                    self.logger.warning(f"ç­–ç•¥ '{strategy_name}' å¤±æ•—: {e}")

            if not content:
                self.logger.error(f"æ‰€æœ‰å…§å®¹æå–ç­–ç•¥éƒ½å¤±æ•—ï¼Œæª”æ¡ˆè³‡è¨Š: {file_info}")
                return None

            # ğŸ¯ ç¢ºä¿æ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼
            self.logger.info(f"åŸå§‹å…§å®¹å‰100å­—ç¬¦: {content[:100]}")

            # å˜—è©¦è§£æ JSON
            parsed_json = None
            try:
                parsed_json = json.loads(content)
                self.logger.info(f"âœ… JSON è§£ææˆåŠŸ")
            except json.JSONDecodeError as e:
                self.logger.warning(f"JSON è§£æå¤±æ•—ï¼Œä¿ç•™åŸå§‹å…§å®¹: {e}")
                # å¦‚æœä¸æ˜¯æœ‰æ•ˆJSONï¼Œä»ç„¶ä¿ç•™åŸå§‹å…§å®¹

            # æ¸…ç†å’Œæå–è®Šæ•¸
            cleaned_json = self._clean_json_values(parsed_json) if parsed_json else None
            variables = self._extract_json_variables(cleaned_json) if cleaned_json else []

            result = {
                'raw_content': content,
                'parsed': cleaned_json,
                'variables': variables
            }

            self.logger.info(f"JSON è™•ç†æˆåŠŸï¼raw_content é•·åº¦: {len(content)}, è®Šæ•¸æ•¸é‡: {len(variables)}")
            return result

        except Exception as e:
            self.logger.error(f"è™•ç† JSON æª”æ¡ˆå¤±æ•—: {e}", exc_info=True)
            return None

    def _extract_data_content(self, data):
        """å¾dataå­—æ®µæå–å…§å®¹"""
        if not data:
            return None

        if isinstance(data, dict):
            return json.dumps(data, ensure_ascii=False, indent=2)
        elif isinstance(data, str):
            return data
        else:
            return str(data)

    def _clean_json_values(self, obj):
        """æ¸…ç† JSON ç‰©ä»¶ä¸­çš„å•é¡Œå€¼"""
        if isinstance(obj, dict):
            return {key: self._clean_json_values(value) for key, value in obj.items()}
        elif isinstance(obj, list):
            return [self._clean_json_values(item) for item in obj]
        elif isinstance(obj, float):
            if math.isnan(obj) or math.isinf(obj):
                return None
            return obj
        else:
            return obj

    def _extract_json_variables(self, json_obj) -> List[str]:
        """å¾ JSON ä¸­æå–è®Šæ•¸åç¨±"""
        if json_obj is None:
            return []

        variables = []

        def extract_vars(obj):
            try:
                if isinstance(obj, dict):
                    for key, value in obj.items():
                        if isinstance(value, str) and value.startswith('${') and value.endswith('}'):
                            var_name = value[2:-1]
                            if var_name and var_name not in variables:
                                variables.append(var_name)
                        elif isinstance(value, (dict, list)):
                            extract_vars(value)
                elif isinstance(obj, list):
                    for item in obj:
                        extract_vars(item)
            except Exception as e:
                self.logger.warning(f"æå–è®Šæ•¸æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

        extract_vars(json_obj)
        return variables

    def validate_xml(self, xml_content: str) -> Tuple[bool, str]:
        """é©—è­‰ XML å…§å®¹çš„æœ‰æ•ˆæ€§

        Args:
            xml_content: è¦é©—è­‰çš„ XML å…§å®¹

        Returns:
            Tuple[bool, str]: (æ˜¯å¦æœ‰æ•ˆ, é©—è­‰è¨Šæ¯)
        """
        try:
            # æª¢æŸ¥å…§å®¹æ˜¯å¦ç‚ºç©º
            if not xml_content or not xml_content.strip():
                return False, "XML å…§å®¹ç‚ºç©º"

            # æª¢æŸ¥åŸºæœ¬æ ¼å¼
            content = xml_content.strip()

            # æª¢æŸ¥ XML è²æ˜æ˜¯å¦å­˜åœ¨
            if not content.startswith('<?xml'):
                return False, "ç¼ºå°‘ XML è²æ˜"

            # æª¢æŸ¥ XML è²æ˜æ•¸é‡ï¼Œç¢ºä¿åªæœ‰ä¸€å€‹
            xml_count = content.count('<?xml')
            if xml_count > 1:
                return False, f"ç™¼ç¾å¤šå€‹ XML è²æ˜ ({xml_count} å€‹)"

            # æª¢æŸ¥åŸºæœ¬çµæ§‹ï¼Œç¢ºä¿æœ‰æ ¹å…ƒç´ 
            if '<jmeterTestPlan' not in content:
                return False, "ç¼ºå°‘ jmeterTestPlan æ ¹å…ƒç´ "

            if '</jmeterTestPlan>' not in content:
                return False, "ç¼ºå°‘ jmeterTestPlan çµæŸæ¨™ç±¤"

            # å˜—è©¦è§£æ XML å…§å®¹
            root = ET.fromstring(content)

            # æª¢æŸ¥æ ¹å…ƒç´ æ˜¯å¦æ­£ç¢º
            if root.tag != 'jmeterTestPlan':
                return False, f"æ ¹å…ƒç´ æ‡‰ç‚º jmeterTestPlanï¼Œå¯¦éš›ç‚º {root.tag}"

            # æª¢æŸ¥å¿…è¦å±¬æ€§æ˜¯å¦å­˜åœ¨
            if 'version' not in root.attrib:
                return False, "jmeterTestPlan ç¼ºå°‘ version å±¬æ€§"

            # æª¢æŸ¥ TestPlan å…ƒç´ æ˜¯å¦å­˜åœ¨
            test_plan = root.find('.//TestPlan')
            if test_plan is None:
                return False, "æ‰¾ä¸åˆ° TestPlan å…ƒç´ "

            # æª¢æŸ¥ TestPlan.user_define_classpath çš„çµæ§‹æ˜¯å¦æ­£ç¢º
            classpath_prop = test_plan.find('./elementProp[@name="TestPlan.user_define_classpath"]')
            if classpath_prop is not None:
                if classpath_prop.get('elementType') != 'Arguments':
                    return False, "TestPlan.user_define_classpath çš„ elementType æ‡‰ç‚º Arguments"
                collection_prop = classpath_prop.find('./collectionProp[@name="Arguments.arguments"]')
                if collection_prop is None:
                    return False, "TestPlan.user_define_classpath ä¸­ç¼ºå°‘æ­£ç¢ºçš„ collectionProp çµæ§‹"

            # æª¢æŸ¥ hashTree çµæ§‹æ˜¯å¦å­˜åœ¨
            hash_trees = root.findall('.//hashTree')
            if not hash_trees:
                return False, "ç¼ºå°‘ hashTree çµæ§‹"

            # æª¢æŸ¥ hashTree æ¨™ç±¤æ˜¯å¦æˆå°å‡ºç¾
            open_tags = content.count('<hashTree>')
            close_tags = content.count('</hashTree>')
            if open_tags != close_tags:
                return False, f"hashTree æ¨™ç±¤ä¸åŒ¹é… (é–‹å§‹: {open_tags}, çµæŸ: {close_tags})"

            # æª¢æŸ¥å¸¸è¦‹çš„ JMeter çµ„ä»¶æ˜¯å¦å­˜åœ¨ï¼Œä½œç‚ºé™„åŠ è³‡è¨Š
            components_found = []
            if root.find('.//ThreadGroup') is not None:
                components_found.append("ThreadGroup")
            if root.find('.//HTTPSamplerProxy') is not None or root.find('.//HTTPSampler') is not None:
                components_found.append("HTTP Sampler")
            if root.find('.//ResponseAssertion') is not None:
                components_found.append("Response Assertion")

            # æ§‹å»ºé©—è­‰è¨Šæ¯
            validation_message = "XML çµæ§‹æœ‰æ•ˆ"
            if components_found:
                validation_message += f"ï¼ŒåŒ…å«çµ„ä»¶: {', '.join(components_found)}"
            else:
                validation_message += "ï¼Œä½†æœªç™¼ç¾æ¸¬è©¦çµ„ä»¶"

            return True, validation_message

        except ET.ParseError as e:
            self.logger.error(f"XML è§£æå¤±æ•—: {e}")
            return False, f"XML è§£æéŒ¯èª¤: {str(e)}"
        except Exception as e:
            self.logger.error(f"XML é©—è­‰æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return False, f"é©—è­‰éç¨‹ç™¼ç”ŸéŒ¯èª¤: {str(e)}"

    def _parameterize_json_body(self, json_body: str, csv_info: CsvInfo) -> str:
        """
        å®‰å…¨åœ°å°‡ JSON Body åƒæ•¸åŒ–ã€‚
        1. å„ªå…ˆç­–ç•¥ï¼šå¦‚æœ JSON çš„ key èˆ‡ CSV çš„è®Šæ•¸ååŒ¹é…ï¼Œç›´æ¥æ›¿æ›ã€‚
        2. å‚™ç”¨ç­–ç•¥ï¼šå¦‚æœ key ä¸åŒ¹é…ï¼Œå‰‡å˜—è©¦åŒ¹é… value (èˆŠæœ‰é‚è¼¯)ï¼Œä»¥è™•ç†ç‰¹æ®Šæƒ…æ³ã€‚
        """
        self.logger.info(f"ğŸš€ é–‹å§‹ä½¿ç”¨ã€æ™ºæ…§å‹é›™é‡ç­–ç•¥ã€‘åƒæ•¸åŒ– JSONï¼Œä¾†æº CSV: '{csv_info.filename}'")

        if not json_body or not csv_info.raw_content or not csv_info.variable_names:
            self.logger.warning("JSON Body æˆ– CSV å…§å®¹/è®Šæ•¸ç‚ºç©ºï¼Œè·³éåƒæ•¸åŒ–ã€‚")
            return json_body or ""

        try:
            # æ­¥é©Ÿ 1: è§£æ JSON å­—ä¸²ç‚º Python ç‰©ä»¶
            data_obj = json.loads(json_body)

            # æ­¥é©Ÿ 2: æº–å‚™å…©ç¨®æ›¿æ›ç­–ç•¥æ‰€éœ€çš„è³‡æ–™
            # ç­–ç•¥ä¸€ï¼šå»ºç«‹ä¸€å€‹é«˜æ•ˆçš„ CSV è®Šæ•¸åé›†åˆ (ç”¨æ–¼éµåŒ¹é…)
            variable_set = set(csv_info.variable_names)

            # ç­–ç•¥äºŒï¼šå¾ CSV è®€å–ç¬¬ä¸€è¡Œè³‡æ–™ï¼Œå»ºç«‹ "å€¼ -> ${è®Šæ•¸}" çš„å°æ‡‰å­—å…¸ (ç”¨æ–¼å€¼åŒ¹é…)
            file_stream = io.StringIO(csv_info.raw_content)
            csv_reader = csv.reader(file_stream)
            next(csv_reader, None)  # è·³éæ¨™é ­
            first_data_row = next(csv_reader, None)

            value_to_placeholder_map = {}
            if first_data_row:
                value_to_placeholder_map = {
                    value.strip(): f"${{{variable}}}"
                    for variable, value in zip(csv_info.variable_names, first_data_row)
                    if value and value.strip()
                }
                self.logger.info(f"å»ºç«‹çš„ã€Œå€¼ã€æ›¿æ›å°æ‡‰è¡¨: {value_to_placeholder_map}")
            else:
                self.logger.warning(f"CSV '{csv_info.filename}' ä¸­æ²’æœ‰è³‡æ–™è¡Œï¼Œç„¡æ³•ä½¿ç”¨ã€Œå€¼åŒ¹é…ã€ç­–ç•¥ã€‚")

            # ä½¿ç”¨ä¸€å€‹ list ä¾†è¿½è¹¤è¢«æ›¿æ›çš„éµå’ŒåŸå› 
            replacements_made = []

            # æ­¥é©Ÿ 3: å®šç¾©ä¸€å€‹éè¿´å‡½å¼ä¾†èµ°è¨ªä¸¦åŸ·è¡Œé›™é‡æ›¿æ›ç­–ç•¥
            def recursive_replace(obj):
                if isinstance(obj, dict):
                    # ä½¿ç”¨ list(obj.keys()) ä¾†é¿å…åœ¨è¿­ä»£æœŸé–“ä¿®æ”¹å­—å…¸çš„å•é¡Œ
                    for key in list(obj.keys()):
                        value = obj[key]

                        # --- ç­–ç•¥ä¸€ï¼šå„ªå…ˆé€²è¡Œã€Œéµã€åŒ¹é… ---
                        if key in variable_set:
                            placeholder = f"${{{key}}}"
                            if obj[key] != placeholder:
                                obj[key] = placeholder
                                replacements_made.append(f"'{key}' (éµåŒ¹é…)")
                            # éµåŒ¹é…æˆåŠŸå¾Œï¼Œè·³éå°è©²éµå€¼çš„å¾ŒçºŒè™•ç†
                            continue

                        # --- ç­–ç•¥äºŒï¼šå¦‚æœéµä¸åŒ¹é…ï¼Œå‰‡å˜—è©¦ã€Œå€¼ã€åŒ¹é… ---
                        str_value = str(value)
                        if str_value in value_to_placeholder_map:
                            placeholder = value_to_placeholder_map[str_value]
                            if obj[key] != placeholder:
                                obj[key] = placeholder
                                replacements_made.append(f"'{key}' (å€¼åŒ¹é…)")
                            # å€¼åŒ¹é…æˆåŠŸå¾Œï¼Œä¹Ÿè·³ééè¿´
                            continue

                        # --- å¦‚æœéƒ½æ²’æœ‰åŒ¹é…ï¼Œå‰‡éè¿´æ·±å…¥ ---
                        if isinstance(value, (dict, list)):
                            recursive_replace(value)

                elif isinstance(obj, list):
                    for item in obj:
                        recursive_replace(item)

            # åŸ·è¡Œéè¿´æ›¿æ›
            recursive_replace(data_obj)

            if replacements_made:
                # ä½¿ç”¨ set å»é™¤é‡è¤‡é …ï¼Œç„¶å¾Œå†è½‰å› list
                unique_replacements = sorted(list(set(replacements_made)))
                self.logger.info(f"âœ… JSON Body åƒæ•¸åŒ–æˆåŠŸï¼å·²æ›¿æ›çš„æ¬„ä½: {unique_replacements}")
            else:
                self.logger.warning(
                    "JSON Body å…§å®¹æœªç™¼ç”Ÿè®ŠåŒ–ã€‚è«‹æª¢æŸ¥ JSON çš„éµåæˆ–å€¼æ˜¯å¦èƒ½å°æ‡‰åˆ° CSV çš„è®Šæ•¸ã€‚")

            # æ­¥é©Ÿ 4: å°‡ä¿®æ”¹å¾Œçš„ Python ç‰©ä»¶åºåˆ—åŒ–å›æ ¼å¼åŒ–çš„ JSON å­—ä¸²
            parameterized_body = json.dumps(data_obj, indent=4, ensure_ascii=False)
            self.logger.debug(f"åƒæ•¸åŒ–å¾Œçš„ Body: \n{parameterized_body}")
            return parameterized_body

        except json.JSONDecodeError:
            self.logger.error(f"JSON è§£æå¤±æ•—ï¼è«‹æª¢æŸ¥ JSON æª”æ¡ˆæ ¼å¼ã€‚Body: \n{json_body[:500]}...")
            return json_body
        except Exception as e:
            self.logger.error(f"åƒæ•¸åŒ–éç¨‹ä¸­ç™¼ç”Ÿæœªé æœŸçš„éŒ¯èª¤: {e}", exc_info=True)
            return json_body