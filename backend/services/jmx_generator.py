import os
import json
import threading
import re, textwrap
import math
from typing import List, Dict, Any, Optional, Tuple
from pathlib import Path
import pandas as pd
from ibm_watsonx_ai.foundation_models import ModelInference
from ibm_watsonx_ai.metanames import GenTextParamsMetaNames as GenParams
from ibm_watsonx_ai.credentials import Credentials
from dotenv import load_dotenv
from lxml import etree
from lxml.builder import E
import xml.etree.ElementTree as ET
import xml.sax.saxutils as saxutils
from xml.sax.saxutils import escape as saxutils_escape
from dataclasses import asdict
from .logger import get_logger
from .llm_service import LLMService
import io
import csv
import asyncio
from dataclasses import dataclass, field

load_dotenv()

@dataclass
class CsvInfo:
    """å„²å­˜ CSV Data Set Config çš„æ‰€æœ‰è©³ç´°åƒæ•¸"""
    name : str
    filename: str
    variable_names: List[str] = field(default_factory=list)
    delimiter: str = ","
    ignoreFirstLine: bool = False
    quotedData: bool = False
    recycle: bool = True
    stopThread: bool = False
    shareMode: str = "shareMode.all"
    encoding: str = "UTF-8"
    raw_content: Optional[str] = None
    total_rows: int = 0

@dataclass
class GlobalHttpDefaultsInfo:
    """å„²å­˜å…¨åŸŸ HTTP Request Defaults çš„è¨­å®šã€‚"""
    protocol: str = "https"
    domain: str = ""
    port: str = ""
    path: str = ""
    encoding: str = "UTF-8"
    connect_timeout: str = ""
    response_timeout: str = ""

@dataclass
class GlobalHeaderInfo:
    """å„²å­˜å–®ä¸€å…¨åŸŸ HTTP æ¨™é ­çš„éµå€¼å°ã€‚"""
    name: str
    value: str

@dataclass
class GlobalRandomVariableInfo:
    """å„²å­˜ Random Variable Config å…ƒä»¶çš„åƒæ•¸ã€‚"""
    name: str
    variable_name: str
    output_format: str
    min_value: str
    max_value: str
    per_thread: bool = False

@dataclass
class AssertionInfo:
    """å„²å­˜ Response Assertion çš„æ‰€æœ‰åƒæ•¸ã€‚"""
    name: str
    test_field: str = "Assertion.response_data"
    test_type: int = 2
    patterns: List[str] = field(default_factory=list)
    is_or: bool = False
    is_not: bool = False
    main_sample_only: bool = True
    enabled: bool = True
    assume_success: bool = True

@dataclass
class ListenerInfo:
    """
    å„²å­˜ View Results Tree ç›£è½å™¨çš„æ‰€æœ‰è©³ç´°åƒæ•¸ã€‚
    """
    name: str
    filename: str
    log_errors_only: bool = False
    log_successes_only: bool = False

@dataclass
class JsonExtractorInfo:
    """å„²å­˜ JSON Extractor (JSON å¾Œç½®è™•ç†å™¨) çš„åƒæ•¸ã€‚"""
    name: str
    reference_name: str
    json_path_expression: str
    match_number: str = "1"
    default_value: str = "NOT_FOUND"
    enabled: bool = True

@dataclass
class HttpRequestInfo:
    """å„²å­˜å–®ä¸€ HTTP Request Sampler çš„æ‰€æœ‰ç›¸é—œè³‡è¨Šã€‚"""
    name: str
    method: str = "POST"
    protocol: str = ""
    domain: str = ""
    port: str = ""
    path: str = ""
    encoding: str = "UTF-8"
    connect_timeout: str = ""
    response_timeout: str = ""
    json_body: Optional[str] = None
    source_json_filename: Optional[str] = None
    is_parameterized: bool = False
    assertions: List[AssertionInfo] = field(default_factory=list)

@dataclass
class ThreadGroupContext:
    """å„²å­˜å–®ä¸€åŸ·è¡Œç·’ç¾¤çµ„ (Thread Group) çš„å®Œæ•´ä¸Šä¸‹æ–‡ï¼ŒåŒ…å«å…¶æ‰€æœ‰å­å…ƒä»¶ã€‚"""
    name: str
    num_threads_str: str = "${__P(threads,1)}"
    ramp_time_str: str = "${__P(rampUp,1)}"
    loops_str: str = "${__P(loop,-1)}"
    duration_str: str = "${__P(duration,60)}"
    on_sample_error: str = "continue"
    scheduler: bool = True
    http_requests: List[HttpRequestInfo] = field(default_factory=list)
    headers: List[GlobalHeaderInfo] = field(default_factory=list)
    random_variables: List[GlobalRandomVariableInfo] = field(default_factory=list)
    listeners: List[ListenerInfo] = field(default_factory=list)
    csv_data_sets: List[CsvInfo] = field(default_factory=list)

@dataclass
class GlobalSettings:
    """å„²å­˜æ¸¬è©¦è¨ˆç•«å±¤ç´šçš„å…¨åŸŸè¨­å®šã€‚"""
    http_defaults: Optional[GlobalHttpDefaultsInfo] = None
    headers: List[GlobalHeaderInfo] = field(default_factory=list)
    random_variables: List[GlobalRandomVariableInfo] = field(default_factory=list)

@dataclass
class GenerationContext:
    """å„²å­˜ç”Ÿæˆ JMX æ‰€éœ€çš„å®Œæ•´ä¸Šä¸‹æ–‡ï¼Œæ˜¯å‚³éçµ¦çµ„è£å‡½å¼çš„é ‚å±¤ç‰©ä»¶ã€‚"""
    test_plan_name: str
    thread_groups: List[ThreadGroupContext]
    requirements: str
    test_plan_teardown: bool = True
    global_settings: Optional[GlobalSettings] = None
    listeners: List[ListenerInfo] = field(default_factory=list)

class JMXGeneratorService:
    def __init__(self, llm_service: Optional[LLMService] = None, model_name: str = "meta-llama/llama-4-maverick-17b-128e-instruct-fp8"):
        """
        åˆå§‹åŒ– JMXGeneratorService
        :param llm_service: å¯é¸çš„ LLMService å¯¦ä¾‹ï¼Œå¦‚æœç‚º None å‰‡æœƒè‡ªå‹•å‰µå»º
        :param model_name: è¦ä½¿ç”¨çš„æ¨¡å‹åç¨±ï¼Œé è¨­ç‚º "default"
        """
        self._llm_service = llm_service
        self._model_name = model_name
        self.logger = get_logger(__name__)

    @property
    def llm_service(self) -> LLMService:
        """
        ä¸€å€‹å»¶é²è¼‰å…¥ (lazy-loading) çš„å±¬æ€§ï¼Œç¢ºä¿ LLMService åªåœ¨éœ€è¦æ™‚æ‰è¢«åˆå§‹åŒ–ã€‚
        :return: LLMService çš„å¯¦ä¾‹ã€‚
        """
        if self._llm_service is None:
            self.logger.info(f"åˆå§‹åŒ– LLMService (Model: {self._model_name})")
            try:
                from main import get_llm_service
                self._llm_service = get_llm_service(self._model_name)
            except ImportError:
                self.logger.warning("ç„¡æ³•å¾ main æ¨¡çµ„å°å…¥ get_llm_serviceï¼Œä½¿ç”¨é»˜èª LLMService åˆå§‹åŒ–")
                self._llm_service = LLMService()
        return self._llm_service

    async def generate_jmx_with_retry(self, requirements: str, files_data: List[Dict] = None, max_retries: int = 3) -> str:
        """
        JMX ç”Ÿæˆæµç¨‹çš„ç¸½æŒ‡æ®ã€‚

        æ­¤å‡½å¼å”èª¿æ•´å€‹æµç¨‹ï¼Œå¾ç†è§£ä½¿ç”¨è€…éœ€æ±‚åˆ°æœ€çµ‚ç”Ÿæˆä¸¦é©—è­‰ JMX æª”æ¡ˆã€‚
        å®ƒåŒ…å«äº†è½‰æ›ã€æº–å‚™ã€é©—è­‰ã€çµ„è£å’Œæœ€çµ‚é©—è­‰ç­‰æ ¸å¿ƒæ­¥é©Ÿã€‚
        :param requirements: ä½¿ç”¨è€…è¼¸å…¥çš„è‡ªç„¶èªè¨€éœ€æ±‚ã€‚
        :param files_data: ä¸€å€‹åŒ…å«å·²ä¸Šå‚³æª”æ¡ˆè³‡è¨Šçš„å­—å…¸åˆ—è¡¨ã€‚
        :param max_retries: (ç›®å‰æœªä½¿ç”¨) æœ€å¤§é‡è©¦æ¬¡æ•¸ã€‚
        :return: ä¸€å€‹åŒ…å«æœ€çµ‚ JMX å…§å®¹çš„å­—ä¸²ã€‚
        :raises RuntimeError: å¦‚æœ LLM è½‰æ›æ­¥é©Ÿå¤±æ•—ã€‚
        :raises ValueError: å¦‚æœè¼¸å…¥è³‡æ–™è§£æå¤±æ•—ã€è³‡æ–™é©—è­‰å¤±æ•—æˆ–æœ€çµ‚ JMX çµæ§‹ç„¡æ•ˆã€‚
        """
        self.logger.info("=== é–‹å§‹åŸ·è¡Œ JMX ç”Ÿæˆæµç¨‹ ===")

        # æ­¥é©Ÿ 1: å¼·åˆ¶åŸ·è¡Œ LLM è½‰æ›
        self.logger.info("å•Ÿå‹• LLM è½‰æ›ï¼Œå°‡ä½¿ç”¨è€…è¼¸å…¥çµ±ä¸€ç‚ºæ¨™æº–åŒ–æ¨¡æ¿...")
        final_requirements_template: str
        try:
            final_requirements_template = await self.convert_requirements_to_template(requirements, files_data)
            self.logger.info("LLM æˆåŠŸå°‡è¼¸å…¥è½‰æ›ç‚ºçµæ§‹åŒ–æ¨¡æ¿ã€‚")
        except Exception as e:
            self.logger.error(f"LLM è½‰æ›æ­¥é©Ÿå¤±æ•—: {e}", exc_info=True)
            raise RuntimeError(f"ç„¡æ³•å°‡æ‚¨çš„éœ€æ±‚è½‰æ›ç‚ºå¯è™•ç†çš„æ ¼å¼: {e}")

        # æ­¥é©Ÿ 2: æº–å‚™ç”Ÿæˆä¸Šä¸‹æ–‡
        try:
            context = self._prepare_generation_context(final_requirements_template, files_data)
            self.logger.info(f"ç”Ÿæˆä¸Šä¸‹æ–‡æº–å‚™å®Œæˆï¼Œæ¸¬è©¦è¨ˆç•«: '{context.test_plan_name}'")
        except ValueError as e:
            self.logger.error(f"è¼¸å…¥è³‡æ–™æº–å‚™æˆ–è§£æå¤±æ•—: {e}", exc_info=True)
            raise e

        # æ­¥é©Ÿ 3: åœ¨çµ„è£å‰ï¼Œé©—è­‰è³‡æ–™å®Œæ•´æ€§
        self.logger.info("é–‹å§‹åŸ·è¡Œ JMX çµ„è£å‰çš„è³‡æ–™å®Œæ•´æ€§é©—è­‰...")
        for tg_context in context.thread_groups:
            for req_info in tg_context.http_requests:
                # æª¢æŸ¥æ¢ä»¶ï¼šå¦‚æœè«‹æ±‚æœ¬èº«æ²’æœ‰ domainï¼Œä¸”å…¨åŸŸä¹Ÿæ²’æœ‰è¨­å®š domain
                has_global_domain = (
                    context.global_settings and
                    context.global_settings.http_defaults and
                    context.global_settings.http_defaults.domain
                )
                if not req_info.domain and not has_global_domain:
                    error_msg = f"è«‹æ±‚ '{req_info.name}' ç¼ºå°‘å¿…è¦çš„ä¼ºæœå™¨ä½å€(domain)ï¼Œä¸”æœªè¨­å®šå…¨åŸŸé è¨­å€¼ã€‚"
                    self.logger.error(f"è³‡æ–™é©—è­‰å¤±æ•—: {error_msg}")
                    raise ValueError(error_msg)
        self.logger.info("è³‡æ–™å®Œæ•´æ€§é©—è­‰é€šéã€‚")

        # æ­¥é©Ÿ 4: ä½¿ç”¨é©—è­‰é€šéçš„ context é€²è¡Œçµ„è£
        try:
            self.logger.info("é–‹å§‹çµ„è£ JMX...")
            jmx_content = self._assemble_jmx_from_structured_data(context)

            # æ­¥é©Ÿ 5: é©—è­‰çµ„è£å¾Œçš„ JMX
            is_valid, message = self.validate_xml(jmx_content)
            if not is_valid:
                self.logger.error(f"JMX çµ„è£å¾Œé©—è­‰å¤±æ•—: {message}")
                raise ValueError(f"çµ„è£å¾Œçš„ JMX çµæ§‹ç„¡æ•ˆ: {message}")

            self.logger.info("JMX çµ„è£èˆ‡é©—è­‰æˆåŠŸï¼")
            return jmx_content

        except Exception as e:
            self.logger.error(f"JMX çµ„è£éç¨‹ä¸­ç™¼ç”Ÿåš´é‡éŒ¯èª¤: {e}", exc_info=True)
            raise Exception(f"ç„¡æ³•ç”Ÿæˆæœ‰æ•ˆçš„ JMX æª”æ¡ˆ: {e}")

    def _prepare_generation_context(self, requirements: str, files_data: List[Dict]) -> GenerationContext:
        """
        æº–å‚™ç”Ÿæˆ JMX æ‰€éœ€çš„å®Œæ•´ä¸Šä¸‹æ–‡ (Context) ç‰©ä»¶ã€‚

        æ­¤å‡½å¼æ˜¯è³‡æ–™æº–å‚™éšæ®µçš„æ ¸å¿ƒï¼Œå®ƒè² è²¬å°‡ã€Œå­—ä¸²ã€å’Œã€ŒåŸå§‹æª”æ¡ˆã€è½‰æ›ç‚ºçµæ§‹åŒ–çš„ Python ç‰©ä»¶ã€‚
        1. å‘¼å« `_analyze_requirements_dynamically` å°‡ LLM ç”Ÿæˆçš„æ¨¡æ¿å­—ä¸²è§£ææˆä¸€å€‹åŒ…å«å±¤ç´šé—œä¿‚çš„å­—å…¸ã€‚
        2. å‘¼å« `_safe_process_files` è™•ç†æ‰€æœ‰ä¸Šå‚³çš„æª”æ¡ˆï¼ˆå¦‚ CSVã€JSONï¼‰ã€‚
        3. å°‡è§£æå¾Œçš„å­—å…¸å’Œæª”æ¡ˆå…§å®¹ï¼Œå¡«å……åˆ°é å…ˆå®šç¾©å¥½çš„ä¸€ç³»åˆ— `dataclass` ç‰©ä»¶ä¸­ã€‚
        4. è™•ç†é—œéµé‚è¼¯ï¼Œä¾‹å¦‚æ±ºå®š CSV è®Šæ•¸åç¨±çš„å„ªå…ˆç´šï¼ˆå„ªå…ˆä½¿ç”¨æ¨¡æ¿å®šç¾©ï¼Œè‹¥ç„¡æ‰ç”¨æª”æ¡ˆæ¨™é ­ï¼‰ã€‚
        :param requirements: çµæ§‹åŒ–çš„éœ€æ±‚æ¨¡æ¿å­—ä¸²ã€‚
        :param files_data: ä¸€å€‹åŒ…å«å·²ä¸Šå‚³æª”æ¡ˆè³‡è¨Šçš„å­—å…¸åˆ—è¡¨ã€‚
        :return: ä¸€å€‹åŒ…å«æ‰€æœ‰ç”Ÿæˆæ‰€éœ€è³‡è¨Šçš„ GenerationContext ç‰©ä»¶ã€‚
        """
        self.logger.info("=== æ­¥é©Ÿ 1: é–‹å§‹æº–å‚™ç”Ÿæˆä¸Šä¸‹æ–‡ ===")
        processed_files = self._safe_process_files(files_data)
        req_analysis = self._analyze_requirements_dynamically(requirements)

        global_settings = GlobalSettings(
            http_defaults=GlobalHttpDefaultsInfo(**req_analysis.get('global_http_defaults', {})),
            headers=[GlobalHeaderInfo(**h) for h in req_analysis.get('global_headers', [])]
        )

        thread_group_contexts = []
        for tg_data in req_analysis.get('thread_groups', []):
            tg_params = tg_data.get('params', {})
            tg_context = ThreadGroupContext(
                name=tg_data.get('name'),
                num_threads_str=tg_params.get('threads', '${__P(threads,1)}'),
                ramp_time_str=tg_params.get('rampup', '${__P(rampUp,1)}'),
                loops_str=tg_params.get('loops', '${__P(loop,-1)}'),
                duration_str=tg_params.get('duration', '${__P(duration,60)}'),
                on_sample_error=tg_params.get('on_sample_error', 'continue'),
                scheduler=tg_params.get('use_scheduler', 'false').lower() == 'true',
                headers=[GlobalHeaderInfo(**h) for h in tg_data.get('headers', [])],
                random_variables=[GlobalRandomVariableInfo(**rv) for rv in tg_data.get('random_variables', [])],
                listeners=[ListenerInfo(**l) for l in tg_data.get('listeners', [])]
            )

            # è™•ç† CsvDataSet
            for csv_data in tg_data.get('csv_data_sets', []):
                csv_params = csv_data.get('params', {})
                csv_filename = csv_params.get('filename')
                if not csv_filename:
                    continue

                csv_info_dict = next(
                    (csv for csv in processed_files.get('csv_configs', []) if csv.get('filename') == csv_filename),
                    None)
                if not csv_info_dict:
                    self.logger.warning(f"æ¨¡æ¿ä¸­å®šç¾©çš„ CSV æª”æ¡ˆ '{csv_filename}' æœªä¸Šå‚³æˆ–è™•ç†å¤±æ•—ï¼Œå·²è·³éã€‚")
                    continue

                final_variable_names = []
                # 1. å„ªå…ˆå˜—è©¦å¾æ¨¡æ¿ä¸­ç²å– variable_names
                template_vars_str = csv_params.get('variable_names', '').strip()
                if template_vars_str:
                    # å¦‚æœä½¿ç”¨è€…åœ¨æ¨¡æ¿ä¸­æ˜ç¢ºæŒ‡å®šäº†ï¼Œå‰‡ä½¿ç”¨å®ƒå€‘
                    final_variable_names = [name.strip() for name in template_vars_str.split(',') if name.strip()]
                    self.logger.info(f"åµæ¸¬åˆ°æ¨¡æ¿æŒ‡ä»¤ï¼šç‚º '{csv_filename}' ä½¿ç”¨æŒ‡å®šçš„è®Šæ•¸: {final_variable_names}")
                else:
                    # 2. å¦‚æœæ¨¡æ¿ä¸­æ²’æœ‰ï¼Œå‰‡å›é€€ä½¿ç”¨å¾ CSV æª”æ¡ˆè®€å–çš„æ¨™é ­
                    final_variable_names = csv_info_dict.get('variable_names', [])
                    self.logger.info(f"æ¨¡æ¿ä¸­æœªæŒ‡å®šè®Šæ•¸ï¼Œç‚º '{csv_filename}' å›é€€ä½¿ç”¨æª”æ¡ˆæ¨™é ­: {final_variable_names}")

                sharing_mode_from_template = csv_params.get('sharing_mode', 'All threads').lower()
                sharing_mode_jmeter = 'shareMode.all'
                if 'group' in sharing_mode_from_template:
                    sharing_mode_jmeter = 'shareMode.group'
                elif 'thread' in sharing_mode_from_template and 'all' not in sharing_mode_from_template:
                    sharing_mode_jmeter = 'shareMode.thread'

                csv_info = CsvInfo(
                    name=csv_data.get('name', 'CSV Data Set Config'),
                    filename=csv_filename,
                    variable_names=final_variable_names,
                    ignoreFirstLine=csv_params.get('ignore_first_line', 'false').lower() == 'true',
                    recycle=csv_params.get('recycle_on_eof', 'true').lower() == 'true',
                    stopThread=csv_params.get('stop_thread_on_eof', 'false').lower() == 'true',
                    quotedData=csv_params.get('quoted_data', 'false').lower() == 'true',
                    delimiter=csv_params.get('delimiter', ','),
                    shareMode=sharing_mode_jmeter,
                    raw_content=csv_info_dict.get('raw_content', '')
                )
                tg_context.csv_data_sets.append(csv_info)

            # è™•ç† HTTP Requests (æ­¤éƒ¨åˆ†é‚è¼¯ä¸è®Š)
            for req_data in tg_data.get('http_requests', []):
                req_params = req_data.get('params', {})
                http_req_info = HttpRequestInfo(
                    name=req_data.get('name'),
                    method=req_params.get('method', 'POST'),
                    protocol=req_params.get('protocol', ''),
                    domain=req_params.get('domain', ''),
                    port=req_params.get('port', ''),
                    path=req_params.get('path', ''),
                    connect_timeout=req_params.get('connect_timeout', ''),
                    response_timeout=req_params.get('response_timeout', ''),
                    assertions=[AssertionInfo(**a) for a in req_data.get('assertions', [])]
                )

                body_filename = req_params.get('body_file')
                if body_filename:
                    json_content_info = processed_files.get('json_contents', {}).get(body_filename)
                    if json_content_info:
                        http_req_info.source_json_filename = body_filename
                        if tg_context.csv_data_sets:
                            http_req_info.is_parameterized = True

                tg_context.http_requests.append(http_req_info)

            thread_group_contexts.append(tg_context)

        return GenerationContext(
            test_plan_name=req_analysis.get('test_plan', {}).get('name', 'Generated Test Plan'),
            test_plan_teardown=req_analysis.get('test_plan', {}).get('teardown', True),
            thread_groups=thread_group_contexts,
            global_settings=global_settings,
            listeners=[ListenerInfo(**l) for l in req_analysis.get('listeners', [])],
            requirements=requirements
        )

    def _safe_process_files(self, files_data: List[Dict] = None) -> Dict:
        """
        å®‰å…¨åœ°è™•ç†æ‰€æœ‰ä¸Šå‚³çš„æª”æ¡ˆè³‡æ–™ã€‚

        ä½œç‚ºä¸€å€‹ç¸½èª¿åº¦å‡½å¼ï¼Œå®ƒæœƒåˆ†é¡è™•ç†å‚³å…¥çš„æª”æ¡ˆåˆ—è¡¨ï¼Œåˆ†åˆ¥èª¿ç”¨
        `_process_csv_files` å’Œ `_process_json_files`ï¼Œä¸¦å°‡çµæœåŒ¯ç¸½æˆä¸€å€‹å­—å…¸ã€‚
        :param files_data: ä¸€å€‹åŒ…å«å·²ä¸Šå‚³æª”æ¡ˆè³‡è¨Šçš„å­—å…¸åˆ—è¡¨ã€‚
        :return: ä¸€å€‹åŒ…å« 'csv_configs' å’Œ 'json_contents' çš„å­—å…¸ã€‚
        """
        try:
            if not files_data:
                self.logger.warning("æ²’æœ‰å‚³å…¥ä»»ä½•æª”æ¡ˆè³‡æ–™")
                return {"csv_configs": [], "json_contents": {}}

            self.logger.info(f"é–‹å§‹è™•ç† {len(files_data)} å€‹æª”æ¡ˆ")

            # å¾ _process_csv_files ç²å–çš„æ˜¯å­—å…¸ï¼Œkey æ˜¯æª”å
            csv_configs_dict = self._process_csv_files(files_data)
            json_contents = self._process_json_files(files_data)

            self.logger.info(f"JSON è™•ç†çµæœ: {list(json_contents.keys())}")

            # å°‡ CSV configs å­—å…¸è½‰æ›ç‚ºåˆ—è¡¨æ ¼å¼ï¼Œä¸¦ç¢ºä¿åŒ…å« raw_content
            csv_configs_list = []
            for filename, config in csv_configs_dict.items():
                if config and 'error' not in config:
                    # ç¢ºä¿æˆ‘å€‘å¾ _safe_process_single_csv è¿”å›çš„æ‰€æœ‰é‡è¦è³‡è¨Šéƒ½è¢«åŒ…å«
                    csv_configs_list.append({
                        'filename': filename,
                        'variable_names': config.get('headers', []),
                        'total_rows': config.get('total_rows', 0),
                        'filepath': config.get('filepath', filename),
                        'raw_content': config.get('raw_content', '')  # ç¢ºä¿ raw_content è¢«å‚³é
                    })
                    self.logger.info(
                        f"ç‚ºåˆ—è¡¨æ·»åŠ  CSV è¨­å®š: '{filename}', è®Šæ•¸: {config.get('headers', [])}, raw_content é•·åº¦: {len(config.get('raw_content', ''))}")
                else:
                    self.logger.warning(f"è·³éæœ‰å•é¡Œçš„ CSV è¨­å®š: {filename}")

            result = {"csv_configs": csv_configs_list, "json_contents": json_contents}
            self.logger.info(f"æª”æ¡ˆè™•ç†å®Œæˆ - CSV: {len(csv_configs_list)}, JSON: {len(json_contents)}")
            return result

        except Exception as e:
            self.logger.error(f"æª”æ¡ˆè™•ç†å¤±æ•—: {e}", exc_info=True)
            return {"csv_configs": [], "json_contents": {}}

    def _analyze_requirements_dynamically(self, requirements: str) -> dict:
        """
        å‹•æ…‹è§£æçµæ§‹åŒ–çš„éœ€æ±‚æ¨¡æ¿å­—ä¸²ï¼Œä¸¦å»ºç«‹å…ƒä»¶ä¹‹é–“çš„å±¤ç´šé—œä¿‚ã€‚

        é€™æ˜¯è‡ªè¨‚æ¨¡æ¿æ ¼å¼çš„å°ˆç”¨è§£æå™¨ã€‚å®ƒä½¿ç”¨æ­£è¦è¡¨ç¤ºå¼è®€å– `[å…ƒä»¶é¡å‹:å…ƒä»¶åç¨±]` æ ¼å¼çš„æ¨¡æ¿ï¼Œ
        ä¸¦æ ¹æ“š `parent` å±¬æ€§å°‡å­å…ƒä»¶æ­£ç¢ºåœ°æ”¾å…¥çˆ¶å…ƒä»¶çš„åˆ—è¡¨ä¸­ï¼Œå¾è€Œå»ºç«‹èµ·æ•´å€‹æ¸¬è©¦è¨ˆç•«çš„æ¨¹ç‹€çµæ§‹ã€‚
        å®ƒé‚„åŒ…å«è™•ç†ç‰¹æ®Šæƒ…æ³çš„é‚è¼¯ï¼Œä¾‹å¦‚å°‡ã€Œä½œç”¨æ–¼æ•´å€‹åŸ·è¡Œç·’ç¾¤çµ„çš„æ–·è¨€ã€æš«å­˜èµ·ä¾†ï¼Œä¸¦åœ¨æœ€å¾Œåˆ†ç™¼çµ¦è©²ç¾¤çµ„ä¸‹çš„æ‰€æœ‰è«‹æ±‚ã€‚
        :param requirements: çµæ§‹åŒ–çš„éœ€æ±‚æ¨¡æ¿å­—ä¸²ã€‚
        :return: ä¸€å€‹ä»£è¡¨æ•´å€‹æ¸¬è©¦è¨ˆç•«çµæ§‹çš„å·¢ç‹€å­—å…¸ã€‚
        """
        self.logger.info("================== é–‹å§‹åŸ·è¡Œè§£æå™¨ ==================")
        is_structured_format = re.search(r"^\s*\[[a-zA-Z]+:.+?\]", requirements, re.MULTILINE)

        if not is_structured_format:
            self.logger.warning("æœªåµæ¸¬åˆ°çµæ§‹åŒ–æ¨¡æ¿æ ¼å¼ï¼Œé€€å›ã€‚")
            return {'test_plan': {}, 'global_http_defaults': {}, 'global_headers': [], 'thread_groups': [],
                    'listeners': []}

        self.logger.info("åµæ¸¬åˆ°çµæ§‹åŒ–æ¨¡æ¿æ ¼å¼ï¼Œå•Ÿç”¨è§£æå™¨ã€‚")
        analysis = {'test_plan': {}, 'global_http_defaults': {}, 'global_headers': [], 'thread_groups': [],
                    'listeners': []}

        # --- ç¬¬ä¸€éšæ®µï¼šå°‡æ¨¡æ¿å­—ä¸²è§£æç‚ºä¸€å€‹æ‰å¹³çš„å…ƒä»¶åˆ—è¡¨ ---
        all_components = []
        # ä½¿ç”¨æ­£è¦è¡¨ç¤ºå¼å°‹æ‰¾æ‰€æœ‰ [Component: Name] å€å¡Š
        for match in re.finditer(r"\[([a-zA-Z]+):\s*(.+?)\]\n([\s\S]+?)(?=\n\[|\Z)", requirements, re.MULTILINE):
            comp_type, comp_name, comp_body = match.groups()
            component = {'type': comp_type.strip(), 'name': comp_name.strip(), 'params': {}}

            # è§£ææ¯å€‹å€å¡Šå…§çš„ key = value åƒæ•¸
            for param_match in re.finditer(r"^\s*([^#\s=]+?)\s*=\s*(.+?)\s*$", comp_body, re.MULTILINE):
                key, value = param_match.groups()
                component['params'][key.strip()] = value.strip().strip('\'"')

            # ç‚ºå®¹å™¨é¡å‹çš„å…ƒä»¶é å…ˆåˆå§‹åŒ–å­åˆ—è¡¨ï¼Œæ–¹ä¾¿å¾ŒçºŒé™„åŠ 
            if component['type'] == 'ThreadGroup':
                component.setdefault('http_requests', [])
                component.setdefault('headers', [])
                component.setdefault('random_variables', [])
                component.setdefault('listeners', [])
                component.setdefault('csv_data_sets', [])
                component.setdefault('tg_level_assertions', [])  # ç”¨æ–¼æš«å­˜åŸ·è¡Œç·’ç¾¤çµ„å±¤ç´šçš„æ–·è¨€
            elif component['type'] == 'HttpRequest':
                component.setdefault('assertions', [])
            all_components.append(component)

        # å»ºç«‹ä¸€å€‹ä»¥å…ƒä»¶åç¨±ç‚ºéµçš„å­—å…¸ï¼Œæ–¹ä¾¿å¿«é€ŸæŸ¥æ‰¾çˆ¶å…ƒä»¶
        component_map = {}
        for comp in all_components:
            name = comp['name']
            if name not in component_map:
                component_map[name] = []
            component_map[name].append(comp)

        # --- ç¬¬äºŒéšæ®µï¼šéæ­·æ‰å¹³åˆ—è¡¨ï¼Œå»ºç«‹å…ƒä»¶ä¹‹é–“çš„å±¤ç´šé—œä¿‚ ---
        test_plan_comp = next((c for c in all_components if c['type'] == 'TestPlan'), None)
        if not test_plan_comp:
            raise ValueError("æ¨¡æ¿ä¸­æœªæ‰¾åˆ° [TestPlan: ...] å…ƒä»¶ã€‚")

        analysis['test_plan'] = {
            'name': test_plan_comp['name'],
            'teardown': test_plan_comp['params'].get('tearDown_on_shutdown', 'true').lower() == 'true'
        }

        # å°‡æ‰€æœ‰å…ƒä»¶åˆ†é¡ä¸¦é™„åŠ åˆ°å…¶çˆ¶å±¤
        for comp in all_components:
            if comp['type'] == 'TestPlan':
                continue  # TestPlan æ˜¯æ ¹ç¯€é»ï¼Œè·³é

            # æ ¹æ“š 'parent' å±¬æ€§å°‹æ‰¾çˆ¶å…ƒä»¶
            parent_name = comp.get('params', {}).get('parent')
            if not parent_name:
                self.logger.warning(f"å…ƒä»¶ '{comp['name']}' ç¼ºå°‘ 'parent' å±¬æ€§ï¼Œå·²è·³éã€‚")
                continue

            parent_candidates = component_map.get(parent_name)
            if not parent_candidates:
                self.logger.warning(f"å…ƒä»¶ '{comp['name']}' æ‰¾ä¸åˆ°çˆ¶å±¤ '{parent_name}'ï¼Œå·²è·³éã€‚")
                continue

            # ç¢ºå®šå”¯ä¸€çš„çˆ¶å…ƒä»¶å¯¦é«”
            parent_comp = next((p for p in parent_candidates if p['type'] in ['TestPlan', 'ThreadGroup']), None)
            if not parent_comp:
                parent_comp = next((p for p in parent_candidates if p['type'] == 'HttpRequest'), None)

            if not parent_comp:
                self.logger.warning(
                    f"å…ƒä»¶ '{comp['name']}' é›–ç„¶æ‰¾åˆ°äº†åç‚º '{parent_name}' çš„å€™é¸çˆ¶å…ƒä»¶ï¼Œä½†å®ƒå€‘çš„é¡å‹ä¸é©åˆåšç‚ºçˆ¶å±¤ï¼Œå·²è·³éã€‚")
                continue

            comp_type, parent_type = comp['type'], parent_comp['type']

            # æ ¹æ“šçˆ¶å…ƒä»¶çš„é¡å‹ï¼Œå°‡ç•¶å‰å…ƒä»¶æ”¾å…¥å°æ‡‰çš„å­åˆ—è¡¨ä¸­
            if parent_type == 'TestPlan':
                if comp_type == 'ThreadGroup':
                    analysis['thread_groups'].append(comp)
                elif comp_type == 'GlobalHttpRequestDefaults':
                    http_defaults_params = comp['params'].copy()
                    http_defaults_params.pop('parent', None)  # ç§»é™¤ parent å±¬æ€§ï¼Œé¿å…å¾ŒçºŒ dataclass åˆå§‹åŒ–éŒ¯èª¤
                    analysis['global_http_defaults'] = http_defaults_params
                elif comp_type in ['HttpHeaderManager', 'GlobalHttpHeaderManager']:
                    headers = [{'name': k.split('.', 1)[1], 'value': v} for k, v in comp['params'].items() if
                               k.startswith('header.')]
                    analysis['global_headers'].extend(headers)
                elif comp_type == 'Listener':
                    listener_params = {
                        'name': comp['name'],
                        'filename': comp['params'].get('filename', ''),
                        'log_errors_only': comp['params'].get('log_errors_only', 'false').lower() == 'true',
                        'log_successes_only': comp['params'].get('log_successes_only', 'false').lower() == 'true'
                    }
                    analysis['listeners'].append(listener_params)

            elif parent_type == 'ThreadGroup':
                if comp_type == 'HttpRequest':
                    parent_comp['http_requests'].append(comp)
                elif comp_type == 'CsvDataSet':
                    parent_comp['csv_data_sets'].append(comp)
                elif comp_type == 'HttpHeaderManager':
                    headers = [{'name': k.split('.', 1)[1], 'value': v} for k, v in comp['params'].items() if
                               k.startswith('header.')]
                    parent_comp['headers'].extend(headers)
                elif comp_type == 'RandomVariableConfig':
                    parent_comp['random_variables'].append(comp['params'])
                elif comp_type == 'Listener':
                    listener_params = {
                        'name': comp['name'],
                        'filename': comp['params'].get('filename', ''),
                        'log_errors_only': comp['params'].get('log_errors_only', 'false').lower() == 'true',
                        'log_successes_only': comp['params'].get('log_successes_only', 'false').lower() == 'true'
                    }
                    parent_comp['listeners'].append(listener_params)
                elif comp_type == 'ResponseAssertion':
                    # è™•ç†åŸ·è¡Œç·’ç¾¤çµ„å±¤ç´šçš„æ–·è¨€ï¼šå…ˆæš«å­˜
                    self.logger.info(f"ç™¼ç¾ä¸€å€‹åŸ·è¡Œç·’ç¾¤çµ„å±¤ç´šçš„æ–·è¨€ '{comp['name']}'ï¼Œå°‡å…¶æš«å­˜ã€‚")
                    rule = comp['params'].get('pattern_matching_rule', 'Contains')
                    patterns = [v for k, v in comp['params'].items() if k.startswith('pattern_')]
                    possible_rules = {'contains', 'matches', 'equals', 'substring', 'not', 'or'}
                    filtered_patterns = [p for p in patterns if p.lower() not in possible_rules]
                    rule_lower = rule.lower()
                    test_type = 2
                    if 'matches' in rule_lower:
                        test_type = 1
                    elif 'equals' in rule_lower:
                        test_type = 8
                    parent_comp['tg_level_assertions'].append({
                        'name': comp['name'], 'test_type': test_type, 'patterns': filtered_patterns,
                        'is_or': comp['params'].get('use_or_logic', 'false').lower() == 'true',
                        'is_not': 'not' in rule_lower,
                        'assume_success': comp['params'].get('assume_success', 'false').lower() == 'true'
                    })

            elif parent_type == 'HttpRequest':
                # è™•ç†è«‹æ±‚å±¤ç´šçš„æ–·è¨€
                if comp_type == 'ResponseAssertion':
                    rule = comp['params'].get('pattern_matching_rule', 'Contains')
                    patterns = [v for k, v in comp['params'].items() if k.startswith('pattern_')]
                    possible_rules = {'contains', 'matches', 'equals', 'substring', 'not', 'or'}
                    filtered_patterns = [p for p in patterns if p.lower() not in possible_rules]
                    rule_lower = rule.lower()
                    test_type = 2
                    if 'matches' in rule_lower:
                        test_type = 1
                    elif 'equals' in rule_lower:
                        test_type = 8
                    parent_comp['assertions'].append({
                        'name': comp['name'], 'test_type': test_type, 'patterns': filtered_patterns,
                        'is_or': comp['params'].get('use_or_logic', 'false').lower() == 'true',
                        'is_not': 'not' in rule_lower,
                        'assume_success': comp['params'].get('assume_success', 'false').lower() == 'true'
                    })

        # --- ç¬¬ä¸‰éšæ®µï¼šå¾Œè™•ç†ï¼Œåˆ†ç™¼æš«å­˜çš„åŸ·è¡Œç·’ç¾¤çµ„å±¤ç´šæ–·è¨€ ---
        self.logger.info("æ­£åœ¨åˆ†ç™¼åŸ·è¡Œç·’ç¾¤çµ„å±¤ç´šçš„æ–·è¨€...")
        for tg_comp in analysis['thread_groups']:
            if tg_comp.get('tg_level_assertions'):
                assertions_to_add = tg_comp['tg_level_assertions']
                if assertions_to_add and tg_comp['http_requests']:
                    self.logger.info(
                        f"åœ¨ ThreadGroup '{tg_comp['name']}' ä¸­æ‰¾åˆ° {len(assertions_to_add)} å€‹å…¨åŸŸæ–·è¨€ï¼Œæº–å‚™é™„åŠ åˆ° {len(tg_comp['http_requests'])} å€‹è«‹æ±‚ä¸­ã€‚")
                    for http_request in tg_comp['http_requests']:
                        for assertion in assertions_to_add:
                            # ä½¿ç”¨ .copy() ç¢ºä¿æ¯å€‹è«‹æ±‚ç²å¾—çš„æ˜¯ç¨ç«‹çš„æ–·è¨€å­—å…¸å‰¯æœ¬
                            http_request['assertions'].append(assertion.copy())
                elif assertions_to_add:
                    self.logger.warning(
                        f"ThreadGroup '{tg_comp['name']}' æœ‰ {len(assertions_to_add)} å€‹å…¨åŸŸæ–·è¨€ï¼Œä½†å…¶ä¸‹æ²’æœ‰ä»»ä½• HTTP è«‹æ±‚å¯é™„åŠ ã€‚")

        self.logger.info("================== éœ€æ±‚è§£æå™¨åŸ·è¡Œå®Œç•¢ ==================")
        self.logger.debug(f"æœ€çµ‚è§£æçµæœ: {json.dumps(analysis, indent=2, ensure_ascii=False)}")
        return analysis

    def _process_csv_files(self, files_data: List[Dict]) -> Dict[str, Dict]:
        """
        è™•ç†æ‰€æœ‰ä¸Šå‚³çš„ CSV æª”æ¡ˆã€‚

        æ­¤å‡½å¼è¿­ä»£æ‰€æœ‰å‚³å…¥çš„æª”æ¡ˆè³‡æ–™ï¼Œç¯©é¸å‡º CSV æª”æ¡ˆï¼Œ
        ä¸¦å‘¼å« `_safe_process_single_csv` é€²è¡Œå–®ä¸€æª”æ¡ˆçš„è§£æã€‚
        :param files_data: ä¸€å€‹æª”æ¡ˆå­—å…¸çš„åˆ—è¡¨ã€‚
        :return: ä¸€å€‹ä»¥æª”åç‚ºéµï¼Œæª”æ¡ˆè©³ç´°è³‡è¨Šç‚ºå€¼çš„å­—å…¸ã€‚
        """
        csv_configs = {}
        if not files_data:
            self.logger.warning("æ²’æœ‰å‚³å…¥ä»»ä½•æª”æ¡ˆè³‡æ–™ï¼Œç„¡æ³•è™•ç† CSV æª”æ¡ˆã€‚")
            return csv_configs

        self.logger.info(f"é–‹å§‹è™•ç† {len(files_data)} å€‹æª”æ¡ˆä¸­çš„ CSV æª”æ¡ˆ...")
        for file_info in files_data:
            try:
                # å…¼å®¹ä¸åŒå‰ç«¯å‚³å…¥çš„æª”å key
                filename = file_info.get('filename', file_info.get('name', ''))
                if not filename or not filename.lower().endswith('.csv'):
                    continue

                self.logger.info(f"ç™¼ç¾ CSV æª”æ¡ˆ: '{filename}'ï¼Œé€²è¡Œè§£æ...")
                config = self._safe_process_single_csv(file_info)
                if config:
                    # ä½¿ç”¨æª”åä½œç‚º keyï¼Œæ–¹ä¾¿å¾ŒçºŒå¿«é€ŸæŸ¥æ‰¾
                    csv_configs[filename] = config
                else:
                    self.logger.warning(f"æª”æ¡ˆ '{filename}' è§£æå¤±æ•—æˆ–ç‚ºç©ºï¼Œå·²è·³éã€‚")

            except Exception as e:
                # æ•ç²è¿´åœˆä¸­çš„æ„å¤–éŒ¯èª¤ï¼Œç¢ºä¿ä¸€å€‹æª”æ¡ˆçš„å¤±æ•—ä¸æœƒå½±éŸ¿å…¶ä»–æª”æ¡ˆ
                filename_for_log = file_info.get('filename', 'æœªçŸ¥æª”æ¡ˆ')
                self.logger.error(f"è™•ç†æª”æ¡ˆ '{filename_for_log}' æ™‚ç™¼ç”Ÿæœªé æœŸéŒ¯èª¤: {e}", exc_info=True)

        self.logger.info(f"CSV æª”æ¡ˆè™•ç†å®Œæˆï¼Œå…±æˆåŠŸè§£æ {len(csv_configs)} å€‹æª”æ¡ˆã€‚")
        return csv_configs

    def _safe_process_single_csv(self, file_info: Dict) -> Optional[Dict]:
        """
        å®‰å…¨ä¸”å¥å£¯åœ°è™•ç†å–®ä¸€ CSV æª”æ¡ˆçš„å…§å®¹ã€‚

        æ­¤å‡½å¼ä½¿ç”¨æ¨™æº–çš„ `io` å’Œ `csv` æ¨¡çµ„ï¼Œå°‡æª”æ¡ˆå…§å®¹å­—ä¸²è½‰æ›ç‚º
        çµæ§‹åŒ–çš„è³‡è¨Šï¼ŒåŒ…æ‹¬æ¨™é ­ã€è³‡æ–™è¡Œæ•¸å’ŒåŸå§‹å…§å®¹ã€‚
        :param file_info: ä»£è¡¨å–®ä¸€æª”æ¡ˆçš„å­—å…¸ï¼Œæ‡‰åŒ…å«æª”åå’Œå…§å®¹ã€‚
        :return: ä¸€å€‹åŒ…å« CSV è©³ç´°è³‡è¨Šçš„å­—å…¸ï¼Œå¦‚æœè™•ç†å¤±æ•—å‰‡è¿”å› Noneã€‚
        """
        filename = file_info.get('filename', file_info.get('name', 'unknown.csv'))

        try:
            # å¾å¤šå€‹å¯èƒ½çš„ key ä¸­ç²å–æª”æ¡ˆå…§å®¹å­—ä¸²
            content_str = ''
            if 'content' in file_info and isinstance(file_info['content'], str):
                content_str = file_info['content']
            elif 'data' in file_info and isinstance(file_info['data'], str):
                content_str = file_info['data']

            if not content_str or not content_str.strip():
                self.logger.warning(f"CSV æª”æ¡ˆ '{filename}' å…§å®¹ç‚ºç©ºã€‚")
                return None

            # ä½¿ç”¨ io.StringIO å°‡å­—ä¸²å…§å®¹æ¨¡æ“¬æˆä¸€å€‹æª”æ¡ˆï¼Œä»¥ä¾¿ csv æ¨¡çµ„å¯ä»¥è®€å–
            file_stream = io.StringIO(content_str)

            # ä½¿ç”¨ csv.reader é€²è¡Œè§£æï¼Œé€™æ˜¯è™•ç† CSV çš„æ¨™æº–åšæ³•
            csv_reader = csv.reader(file_stream)

            # è®€å–ç¬¬ä¸€è¡Œä½œç‚ºæ¨™é ­
            try:
                headers = next(csv_reader)
                # æ¸…ç†æ¨™é ­ï¼Œå»é™¤å‰å¾Œç©ºæ ¼å’Œç©ºå­—ä¸²
                cleaned_headers = [h.strip() for h in headers if h and h.strip()]
            except StopIteration:
                # æª”æ¡ˆç‚ºç©ºï¼Œæ²’æœ‰ä»»ä½•è¡Œ
                self.logger.warning(f"CSV æª”æ¡ˆ '{filename}' ç‚ºç©ºï¼Œç„¡æ³•è®€å–æ¨™é ­ã€‚")
                return {
                    'headers': [], 'sample_data': [], 'total_rows': 0,
                    'filepath': filename, 'raw_content': content_str
                }

            # è®€å–å‰©é¤˜çš„æ‰€æœ‰è³‡æ–™è¡Œ
            data_rows = list(csv_reader)
            total_data_rows = len(data_rows)

            # æå–æœ€å¤š 5 è¡Œä½œç‚ºæ¨£æœ¬è³‡æ–™
            sample_data = data_rows[:5]

            self.logger.info(
                f"CSV è§£ææˆåŠŸ: '{filename}' -> æ¨™é ­: {cleaned_headers}, è³‡æ–™è¡Œæ•¸: {total_data_rows}"
            )

            return {
                'headers': cleaned_headers,
                'sample_data': sample_data,
                'total_rows': total_data_rows,
                'filepath': filename,
                'raw_content': content_str  # åŒ…å«åŸå§‹å…§å®¹ï¼Œç”¨æ–¼å¾ŒçºŒé‚è¼¯åˆ¤æ–·
            }

        except csv.Error as e:
            self.logger.error(f"è§£æ CSV æª”æ¡ˆ '{filename}' æ™‚ç™¼ç”Ÿæ ¼å¼éŒ¯èª¤: {e}")
            return None
        except Exception as e:
            self.logger.error(f"è™•ç†å–®ä¸€ CSV æª”æ¡ˆ '{filename}' æ™‚ç™¼ç”Ÿæœªé æœŸéŒ¯èª¤: {e}", exc_info=True)
            return None

    def _process_json_files(self, files_data: List[Dict]) -> Dict:
        """
        è™•ç†æ‰€æœ‰ä¸Šå‚³çš„ JSON æª”æ¡ˆã€‚

        æ­¤å‡½å¼è¿­ä»£æ‰€æœ‰å‚³å…¥çš„æª”æ¡ˆè³‡æ–™ï¼Œç¯©é¸å‡º JSON æª”æ¡ˆï¼Œ
        ä¸¦å‘¼å« `_safe_process_single_json` é€²è¡Œå–®ä¸€æª”æ¡ˆçš„è§£æã€‚
        :param files_data: ä¸€å€‹æª”æ¡ˆå­—å…¸çš„åˆ—è¡¨ã€‚
        :return: ä¸€å€‹ä»¥æª”åç‚ºéµï¼Œæª”æ¡ˆè©³ç´°è³‡è¨Šç‚ºå€¼çš„å­—å…¸ã€‚
        """
        json_contents = {}

        if not files_data:
            return json_contents

        for file_info in files_data:
            try:
                filename = file_info.get('filename', file_info.get('name', ''))
                if not filename or not filename.lower().endswith('.json'):
                    continue

                content = self._safe_process_single_json(file_info)
                if content:
                    json_contents[filename] = content

            except Exception as e:
                self.logger.error(f"è™•ç† JSON æª”æ¡ˆ {filename} å¤±æ•—: {e}")
                json_contents[filename] = {'error': str(e), 'raw_content': '', 'variables': []}

        return json_contents

    def _safe_process_single_json(self, file_info: Dict) -> Optional[Dict]:
        """
        å®‰å…¨åœ°è™•ç†å–®ä¸€ JSON æª”æ¡ˆã€‚

        :param file_info: ä»£è¡¨å–®ä¸€æª”æ¡ˆçš„å­—å…¸ï¼Œæ‡‰åŒ…å«æª”åå’Œå…§å®¹ã€‚
        :return: ä¸€å€‹åŒ…å« JSON è©³ç´°è³‡è¨Šçš„å­—å…¸ï¼Œå¦‚æœè™•ç†å¤±æ•—å‰‡è¿”å› Noneã€‚
        """
        try:
            self.logger.info(f"è™•ç† JSON æª”æ¡ˆ: {file_info.get('filename', file_info.get('name', 'æœªçŸ¥'))}")
            self.logger.info(f"æª”æ¡ˆè³‡è¨Šéµå€¼: {list(file_info.keys())}")

            content = ''

            # ğŸ¯ å¤šé‡ç­–ç•¥ç²å–å…§å®¹
            strategies = [
                ('content', lambda x: x.get('content')),
                ('data', lambda x: self._extract_data_content(x.get('data'))),
                ('body', lambda x: x.get('body')),
                ('text', lambda x: x.get('text')),
                ('raw_content', lambda x: x.get('raw_content')),
            ]

            for strategy_name, extractor in strategies:
                try:
                    extracted = extractor(file_info)
                    if extracted:
                        content = str(extracted) if not isinstance(extracted, str) else extracted
                        self.logger.info(f"ä½¿ç”¨ç­–ç•¥ '{strategy_name}' æˆåŠŸç²å–å…§å®¹ï¼Œé•·åº¦: {len(content)}")
                        break
                except Exception as e:
                    self.logger.warning(f"ç­–ç•¥ '{strategy_name}' å¤±æ•—: {e}")

            if not content:
                self.logger.error(f"æ‰€æœ‰å…§å®¹æå–ç­–ç•¥éƒ½å¤±æ•—ï¼Œæª”æ¡ˆè³‡è¨Š: {file_info}")
                return None

            # æ¨™æº–åŒ–æ›è¡Œç¬¦ï¼Œå°‡æ‰€æœ‰ \r\n å’Œ \r æ›¿æ›ç‚º \n
            content = content.replace('\r\n', '\n').replace('\r', '\n')

            # ğŸ¯ ç¢ºä¿æ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼
            self.logger.info(f"åŸå§‹å…§å®¹å‰100å­—ç¬¦: {content[:100]}")

            # å˜—è©¦è§£æ JSON
            parsed_json = None
            try:
                parsed_json = json.loads(content)
                self.logger.info(f"JSON è§£ææˆåŠŸ")
            except json.JSONDecodeError as e:
                self.logger.warning(f"JSON è§£æå¤±æ•—ï¼Œä¿ç•™åŸå§‹å…§å®¹: {e}")
                # å¦‚æœä¸æ˜¯æœ‰æ•ˆJSONï¼Œä»ç„¶ä¿ç•™åŸå§‹å…§å®¹

            # æ¸…ç†å’Œæå–è®Šæ•¸
            cleaned_json = self._clean_json_values(parsed_json) if parsed_json else None
            variables = self._extract_json_variables(cleaned_json) if cleaned_json else []

            result = {
                'raw_content': content,
                'parsed': cleaned_json,
                'variables': variables
            }

            self.logger.info(f"JSON è™•ç†æˆåŠŸï¼raw_content é•·åº¦: {len(content)}, è®Šæ•¸æ•¸é‡: {len(variables)}")
            return result

        except Exception as e:
            self.logger.error(f"è™•ç† JSON æª”æ¡ˆå¤±æ•—: {e}", exc_info=True)
            return None

    def _extract_data_content(self, data):
        """
        ä¸€å€‹è¼”åŠ©å‡½å¼ï¼Œç”¨æ–¼å¾ file_info å­—å…¸ä¸­çš„ 'data' éµæå–å…§å®¹ã€‚

        å®ƒèƒ½è™•ç† 'data' éµçš„å€¼æ˜¯å­—å…¸ã€å­—ä¸²æˆ–å…¶ä»–é¡å‹çš„æƒ…æ³ï¼Œä¸¦çµ±ä¸€è¿”å›å­—ä¸²ã€‚
        :param data: 'data' éµå°æ‡‰çš„å€¼ã€‚
        :return: å…§å®¹å­—ä¸²æˆ– Noneã€‚
        """
        if not data:
            return None

        if isinstance(data, dict):
            return json.dumps(data, ensure_ascii=False, indent=2)
        elif isinstance(data, str):
            return data
        else:
            return str(data)

    def _clean_json_values(self, obj):
        """
        éè¿´åœ°æ¸…ç†ä¸€å€‹ Python ç‰©ä»¶ï¼ˆé€šå¸¸ä¾†è‡ªè§£æå¾Œçš„ JSONï¼‰ä¸­çš„ç„¡æ•ˆå€¼ã€‚

        ä¸»è¦ç”¨æ–¼å°‡ `float` é¡å‹çš„ `NaN` æˆ– `Infinity` å€¼è½‰æ›ç‚º `None`ï¼Œä»¥é¿å…å¾ŒçºŒ JSON åºåˆ—åŒ–å¤±æ•—ã€‚
        :param obj: è¦æ¸…ç†çš„ Python ç‰©ä»¶ (å­—å…¸ã€åˆ—è¡¨ç­‰)ã€‚
        :return: æ¸…ç†å¾Œçš„ç‰©ä»¶ã€‚
        """
        if isinstance(obj, dict):
            return {key: self._clean_json_values(value) for key, value in obj.items()}
        elif isinstance(obj, list):
            return [self._clean_json_values(item) for item in obj]
        elif isinstance(obj, float):
            if math.isnan(obj) or math.isinf(obj):
                return None
            return obj
        else:
            return obj

    def _extract_json_variables(self, json_obj) -> List[str]:
        """
        éè¿´åœ°å¾ä¸€å€‹ Python ç‰©ä»¶ä¸­æå–æ‰€æœ‰ JMeter é¢¨æ ¼çš„è®Šæ•¸åç¨±ã€‚

        å®ƒæœƒå°‹æ‰¾æ‰€æœ‰å½¢å¦‚ `${...}` çš„å­—ä¸²å€¼ï¼Œä¸¦å°‡æ‹¬è™Ÿå…§çš„è®Šæ•¸åæ”¶é›†åˆ°ä¸€å€‹åˆ—è¡¨ä¸­ã€‚
        :param json_obj: è§£æå¾Œçš„ JSON ç‰©ä»¶ (å­—å…¸æˆ–åˆ—è¡¨)ã€‚
        :return: ä¸€å€‹åŒ…å«æ‰€æœ‰è®Šæ•¸åçš„åˆ—è¡¨ã€‚
        """
        if json_obj is None:
            return []

        variables = []

        def extract_vars(obj):
            try:
                if isinstance(obj, dict):
                    for key, value in obj.items():
                        if isinstance(value, str) and value.startswith('${') and value.endswith('}'):
                            var_name = value[2:-1]
                            if var_name and var_name not in variables:
                                variables.append(var_name)
                        elif isinstance(value, (dict, list)):
                            extract_vars(value)
                elif isinstance(obj, list):
                    for item in obj:
                        extract_vars(item)
            except Exception as e:
                self.logger.warning(f"æå–è®Šæ•¸æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

        extract_vars(json_obj)
        return variables

    def validate_xml(self, xml_content: str) -> Tuple[bool, str]:
        """
        ä¸€å€‹å“è³ªä¿è­‰å‡½å¼ï¼Œç”¨æ–¼é©—è­‰æœ€çµ‚ç”Ÿæˆçš„ JMX å­—ä¸²æ˜¯å¦ç‚ºæœ‰æ•ˆçš„ XMLã€‚

        åœ¨å°‡æœ€çµ‚çš„ JMX å…§å®¹è¿”å›çµ¦ä½¿ç”¨è€…ä¹‹å‰ï¼Œå®ƒæœƒä½¿ç”¨ Python çš„ XML è§£æå™¨å˜—è©¦è§£æä¸€æ¬¡ã€‚
        å¦‚æœè§£ææˆåŠŸï¼Œä»£è¡¨ XML æ ¼å¼æ­£ç¢ºï¼›å¦‚æœå¤±æ•—ï¼Œå‰‡èƒ½æå‰æ•ç²éŒ¯èª¤ã€‚
        :param xml_content: è¦é©—è­‰çš„ XML å­—ä¸²ã€‚
        :return: ä¸€å€‹å…ƒçµ„ (å¸ƒæ—å€¼, è¨Šæ¯)ï¼Œå¸ƒæ—å€¼è¡¨ç¤ºæ˜¯å¦æœ‰æ•ˆï¼Œè¨Šæ¯ç‚ºé©—è­‰çµæœã€‚
        """
        try:
            if not xml_content or not xml_content.strip():
                return False, "XML content is empty or whitespace."

            content = xml_content.strip()
            if not content.startswith('<?xml'):
                return False, "Validation failed: Missing XML declaration '<?xml ...?>'."
            if not content.endswith('</jmeterTestPlan>'):
                return False, "Validation failed: Content does not end with '</jmeterTestPlan>'."

            open_tags = content.count('<hashTree>')
            close_tags = content.count('</hashTree>')
            if open_tags != close_tags:
                return False, f"Validation failed: Mismatched <hashTree> tags (open: {open_tags}, close: {close_tags})."

            ET.fromstring(content)
            self.logger.info("XML çµæ§‹é©—è­‰é€šéã€‚")
            return True, "XML validation successful."

        except ET.ParseError as e:
            error_line = str(e).split(',')[1].strip() if ',' in str(e) else str(e)
            self.logger.error(f"XML é©—è­‰å¤±æ•—: èªæ³•è§£æéŒ¯èª¤ -> {error_line}", exc_info=True)
            return False, f"XML ParseError: The generated XML is not well-formed. Details: {error_line}"
        except Exception as e:
            self.logger.error(f"XML é©—è­‰éç¨‹ä¸­ç™¼ç”Ÿæœªé æœŸçš„éŒ¯èª¤: {e}", exc_info=True)
            return False, f"An unexpected error occurred during XML validation: {str(e)}"

    def _parameterize_json_body(self, json_body: str, csv_info: CsvInfo) -> str:
        """
        æ™ºæ…§åœ°å°‡ JSON Body å…§å®¹åƒæ•¸åŒ–ã€‚

        ç•¶ä¸€å€‹ HTTP è«‹æ±‚éœ€è¦ä½¿ç”¨ CSV æª”æ¡ˆé€²è¡Œåƒæ•¸åŒ–æ™‚ï¼Œæ­¤å‡½å¼æœƒè¢«å‘¼å«ã€‚
        å®ƒæ¡ç”¨é›™é‡ç­–ç•¥ï¼š
        1. **éµåŒ¹é…**ï¼šå¦‚æœ JSON çš„éµåèˆ‡ CSV çš„è®Šæ•¸ååŒ¹é…ï¼Œç›´æ¥å°‡å…¶å€¼æ›¿æ›ç‚º `${è®Šæ•¸å}`ã€‚
        2. **å€¼åŒ¹é…**ï¼šå¦‚æœéµä¸åŒ¹é…ï¼Œå‰‡å˜—è©¦å°‡ JSON çš„å€¼èˆ‡ CSV ç¬¬ä¸€è¡Œè³‡æ–™çš„å€¼é€²è¡ŒåŒ¹é…ï¼Œå¦‚æœåŒ¹é…æˆåŠŸï¼Œå‰‡æ›¿æ›ç‚ºå°æ‡‰çš„ `${è®Šæ•¸å}`ã€‚
        :param json_body: åŸå§‹çš„ JSON Body å­—ä¸²ã€‚
        :param csv_info: åŒ…å« CSV è®Šæ•¸å’Œå…§å®¹çš„ CsvInfo ç‰©ä»¶ã€‚
        :return: åƒæ•¸åŒ–å¾Œçš„ JSON Body å­—ä¸²ã€‚
        """
        self.logger.info(f"é–‹å§‹ä½¿ç”¨ã€æ™ºæ…§å‹é›™é‡ç­–ç•¥ã€‘åƒæ•¸åŒ– JSONï¼Œä¾†æº CSV: '{csv_info.filename}'")

        if not json_body or not csv_info.raw_content or not csv_info.variable_names:
            self.logger.warning("JSON Body æˆ– CSV å…§å®¹/è®Šæ•¸ç‚ºç©ºï¼Œè·³éåƒæ•¸åŒ–ã€‚")
            return json_body or ""

        try:
            # æ­¥é©Ÿ 1: è§£æ JSON å­—ä¸²ç‚º Python ç‰©ä»¶
            data_obj = json.loads(json_body)

            # æ­¥é©Ÿ 2: æº–å‚™å…©ç¨®æ›¿æ›ç­–ç•¥æ‰€éœ€çš„è³‡æ–™
            # ç­–ç•¥ä¸€ï¼šå»ºç«‹ä¸€å€‹é«˜æ•ˆçš„ CSV è®Šæ•¸åé›†åˆ (ç”¨æ–¼éµåŒ¹é…)
            variable_set = set(csv_info.variable_names)

            # ç­–ç•¥äºŒï¼šå¾ CSV è®€å–ç¬¬ä¸€è¡Œè³‡æ–™ï¼Œå»ºç«‹ "å€¼ -> ${è®Šæ•¸}" çš„å°æ‡‰å­—å…¸ (ç”¨æ–¼å€¼åŒ¹é…)
            file_stream = io.StringIO(csv_info.raw_content)
            csv_reader = csv.reader(file_stream)
            next(csv_reader, None)  # è·³éæ¨™é ­
            first_data_row = next(csv_reader, None)

            value_to_placeholder_map = {}
            if first_data_row:
                value_to_placeholder_map = {
                    value.strip(): f"${{{variable}}}"
                    for variable, value in zip(csv_info.variable_names, first_data_row)
                    if value and value.strip()
                }
                self.logger.info(f"å»ºç«‹çš„ã€Œå€¼ã€æ›¿æ›å°æ‡‰è¡¨: {value_to_placeholder_map}")
            else:
                self.logger.warning(f"CSV '{csv_info.filename}' ä¸­æ²’æœ‰è³‡æ–™è¡Œï¼Œç„¡æ³•ä½¿ç”¨ã€Œå€¼åŒ¹é…ã€ç­–ç•¥ã€‚")

            # ä½¿ç”¨ä¸€å€‹ list ä¾†è¿½è¹¤è¢«æ›¿æ›çš„éµå’ŒåŸå› 
            replacements_made = []

            # æ­¥é©Ÿ 3: å®šç¾©ä¸€å€‹éè¿´å‡½å¼ä¾†èµ°è¨ªä¸¦åŸ·è¡Œé›™é‡æ›¿æ›ç­–ç•¥
            def recursive_replace(obj):
                if isinstance(obj, dict):
                    # ä½¿ç”¨ list(obj.keys()) ä¾†é¿å…åœ¨è¿­ä»£æœŸé–“ä¿®æ”¹å­—å…¸çš„å•é¡Œ
                    for key in list(obj.keys()):
                        value = obj[key]

                        # --- ç­–ç•¥ä¸€ï¼šå„ªå…ˆé€²è¡Œã€Œéµã€åŒ¹é… ---
                        if key in variable_set:
                            placeholder = f"${{{key}}}"
                            if obj[key] != placeholder:
                                obj[key] = placeholder
                                replacements_made.append(f"'{key}' (éµåŒ¹é…)")
                            # éµåŒ¹é…æˆåŠŸå¾Œï¼Œè·³éå°è©²éµå€¼çš„å¾ŒçºŒè™•ç†
                            continue

                        # --- ç­–ç•¥äºŒï¼šå¦‚æœéµä¸åŒ¹é…ï¼Œå‰‡å˜—è©¦ã€Œå€¼ã€åŒ¹é… ---
                        str_value = str(value)
                        if str_value in value_to_placeholder_map:
                            placeholder = value_to_placeholder_map[str_value]
                            if obj[key] != placeholder:
                                obj[key] = placeholder
                                replacements_made.append(f"'{key}' (å€¼åŒ¹é…)")
                            # å€¼åŒ¹é…æˆåŠŸå¾Œï¼Œä¹Ÿè·³ééè¿´
                            continue

                        # --- å¦‚æœéƒ½æ²’æœ‰åŒ¹é…ï¼Œå‰‡éè¿´æ·±å…¥ ---
                        if isinstance(value, (dict, list)):
                            recursive_replace(value)

                elif isinstance(obj, list):
                    for item in obj:
                        recursive_replace(item)

            # åŸ·è¡Œéè¿´æ›¿æ›
            recursive_replace(data_obj)

            if replacements_made:
                # ä½¿ç”¨ set å»é™¤é‡è¤‡é …ï¼Œç„¶å¾Œå†è½‰å› list
                unique_replacements = sorted(list(set(replacements_made)))
                self.logger.info(f"JSON Body åƒæ•¸åŒ–æˆåŠŸï¼å·²æ›¿æ›çš„æ¬„ä½: {unique_replacements}")
            else:
                self.logger.warning(
                    "JSON Body å…§å®¹æœªç™¼ç”Ÿè®ŠåŒ–ã€‚è«‹æª¢æŸ¥ JSON çš„éµåæˆ–å€¼æ˜¯å¦èƒ½å°æ‡‰åˆ° CSV çš„è®Šæ•¸ã€‚")

            # æ­¥é©Ÿ 4: å°‡ä¿®æ”¹å¾Œçš„ Python ç‰©ä»¶åºåˆ—åŒ–å›æ ¼å¼åŒ–çš„ JSON å­—ä¸²
            parameterized_body = json.dumps(data_obj, indent=4, ensure_ascii=False)
            self.logger.debug(f"åƒæ•¸åŒ–å¾Œçš„ Body: \n{parameterized_body}")
            return parameterized_body

        except json.JSONDecodeError:
            self.logger.error(f"JSON è§£æå¤±æ•—ï¼è«‹æª¢æŸ¥ JSON æª”æ¡ˆæ ¼å¼ã€‚Body: \n{json_body[:500]}...")
            return json_body
        except Exception as e:
            self.logger.error(f"åƒæ•¸åŒ–éç¨‹ä¸­ç™¼ç”Ÿæœªé æœŸçš„éŒ¯èª¤: {e}", exc_info=True)
            return json_body

    def _create_test_plan(self, context: GenerationContext):
        """
        å»ºç«‹ JMX æª”æ¡ˆçš„æ ¹ç¯€é» `<TestPlan>` åŠå…¶å°æ‡‰çš„ `<hashTree>`ã€‚
        :param context: åŒ…å«æ¸¬è©¦è¨ˆç•«åç¨±ç­‰è³‡è¨Šçš„ GenerationContext ç‰©ä»¶ã€‚
        :return: ä¸€å€‹åŒ…å« TestPlan XML å…ƒç´ å’Œå…¶ hashTree çš„å…ƒçµ„ã€‚
        """
        test_plan_element = E.TestPlan(
            guiclass="TestPlanGui",
            testclass="TestPlan",
            testname=context.test_plan_name,
            enabled="true"
        )
        test_plan_element.append(E.stringProp({"name": "TestPlan.comments"}, ""))
        test_plan_element.append(E.boolProp({"name": "TestPlan.functional_mode"}, "false"))
        test_plan_element.append(E.boolProp({"name": "TestPlan.tearDown_on_shutdown"}, "true"))
        test_plan_element.append(E.boolProp({"name": "TestPlan.serialize_threadgroups"}, "false"))

        # å»ºç«‹ç©ºçš„ç”¨æˆ¶è‡ªè¨‚è®Šæ•¸å€å¡Š
        user_defined_variables = E.elementProp(
            {"name": "TestPlan.user_defined_variables", "elementType": "Arguments"},
            E.collectionProp({"name": "Arguments.arguments"})
        )
        user_defined_variables.set("guiclass", "ArgumentsPanel")
        user_defined_variables.set("testclass", "Arguments")
        user_defined_variables.set("testname", "User Defined Variables")
        user_defined_variables.set("enabled", "true")
        test_plan_element.append(user_defined_variables)

        # 2. å»ºç«‹ä¸€å€‹ç©ºçš„ hashTree
        test_plan_hash_tree = E.hashTree()

        # 3. å°‡å…©è€…ä½œç‚ºå…ƒçµ„è¿”å›
        return test_plan_element, test_plan_hash_tree

    def _create_http_request_defaults(self, defaults: GlobalHttpDefaultsInfo) -> tuple:
        """
        å»ºç«‹ `<ConfigTestElement>` å…ƒä»¶ï¼Œå³ "HTTP Request Defaults"ã€‚
        :param defaults: åŒ…å«å”å®šã€ç¶²åŸŸç­‰å…¨åŸŸé è¨­å€¼çš„ GlobalHttpDefaultsInfo ç‰©ä»¶ã€‚
        :return: ä¸€å€‹åŒ…å« ConfigTestElement XML å…ƒç´ å’Œå…¶ hashTree çš„å…ƒçµ„ã€‚
        """
        element = E.ConfigTestElement(
            E.elementProp(E.collectionProp(name="Arguments.arguments"), name="HTTPsampler.Arguments",
                             elementType="Arguments", guiclass="HTTPArgumentsPanel", testclass="Arguments",
                             enabled="true"),
            E.stringProp(defaults.path, name="HTTPSampler.path"),
            E.stringProp(defaults.domain, name="HTTPSampler.domain"),
            E.stringProp(defaults.protocol, name="HTTPSampler.protocol"),
            E.stringProp(defaults.port, name="HTTPSampler.port"),
            E.stringProp(defaults.connect_timeout, name="HTTPSampler.connect_timeout"),
            E.stringProp(defaults.response_timeout, name="HTTPSampler.response_timeout"),
            guiclass="HttpDefaultsGui",
            testclass="ConfigTestElement",
            testname="HTTP Request Defaults",
            enabled="true"
        )
        return element, E.hashTree()

    def _create_http_header_manager(self, headers: List[GlobalHeaderInfo], name: str = "HTTP Header Manager") -> tuple:
        """
        æ ¹æ“šæä¾›çš„æ¨™é ­åˆ—è¡¨ï¼Œå»ºç«‹ä¸€å€‹ `<HeaderManager>` å…ƒä»¶ã€‚
        :param headers: ä¸€å€‹åŒ…å«å¤šå€‹ GlobalHeaderInfo ç‰©ä»¶çš„åˆ—è¡¨ã€‚
        :param name: æ­¤æ¨™é ­ç®¡ç†å™¨çš„åç¨±ã€‚
        :return: ä¸€å€‹åŒ…å« HeaderManager XML å…ƒç´ å’Œå…¶ hashTree çš„å…ƒçµ„ã€‚
        """
        header_elements = []
        for header in headers:
            header_elements.append(
                E.elementProp(
                    E.stringProp(header.name, name="Header.name"),
                    E.stringProp(header.value, name="Header.value"),
                    name="", elementType="Header"
                )
            )

        element = E.HeaderManager(
            E.collectionProp(*header_elements, name="HeaderManager.headers"),
            guiclass="HeaderPanel",
            testclass="HeaderManager",
            testname= name,
            enabled="true"
        )
        return element, E.hashTree()

    def _create_random_variable_config(self, var_config: GlobalRandomVariableInfo) -> tuple:
        """
        å»ºç«‹ `<RandomVariableConfig>` å…ƒä»¶ã€‚
        :param var_config: åŒ…å«éš¨æ©Ÿè®Šæ•¸è©³ç´°è¨­å®šçš„ GlobalRandomVariableInfo ç‰©ä»¶ã€‚
        :return: ä¸€å€‹åŒ…å« RandomVariableConfig XML å…ƒç´ å’Œå…¶ hashTree çš„å…ƒçµ„ã€‚
        """
        element = E.RandomVariableConfig(
            E.stringProp(var_config.variable_name, name="variableName"),
            E.stringProp(var_config.output_format, name="outputFormat"),
            E.stringProp(var_config.min_value, name="minimumValue"),
            E.stringProp(var_config.max_value, name="maximumValue"),
            E.stringProp("", name="randomSeed"),
            E.boolProp(str(var_config.per_thread).lower(), name="perThread"),
            guiclass="TestBeanGUI",
            testclass="RandomVariableConfig",
            testname=var_config.name,
            enabled="true"
        )
        return element, E.hashTree()

    def _create_thread_group(self, tg_context: ThreadGroupContext) -> tuple:
        """
        æ ¹æ“š `ThreadGroupContext` ç‰©ä»¶å»ºç«‹ `<ThreadGroup>` å…ƒä»¶ã€‚

        å®ƒæœƒå°‡ context ä¸­çš„æ‰€æœ‰åƒæ•¸ï¼ˆå¦‚åŸ·è¡Œç·’æ•¸ã€Ramp-Up æ™‚é–“ç­‰ï¼‰å°æ‡‰åˆ°
        æ­£ç¢ºçš„ XML å±¬æ€§ä¸Šã€‚
        :param tg_context: åŒ…å«åŸ·è¡Œç·’ç¾¤çµ„æ‰€æœ‰è¨­å®šçš„ ThreadGroupContext ç‰©ä»¶ã€‚
        :return: ä¸€å€‹åŒ…å« ThreadGroup XML å…ƒç´ å’Œå…¶ hashTree çš„å…ƒçµ„ã€‚
        """
        # 1. å»ºç«‹ ThreadGroup å…ƒä»¶æœ¬èº«
        thread_group_element = E.ThreadGroup(
            guiclass="ThreadGroupGui",
            testclass="ThreadGroup",
            testname=tg_context.name,
            enabled="true"
        )
        # ä½¿ç”¨ context ä¸­çš„ on_sample_error
        thread_group_element.append(E.stringProp(tg_context.on_sample_error, name="ThreadGroup.on_sample_error"))

        loop_controller = E.elementProp(
            E.stringProp(tg_context.loops_str, name="LoopController.loops"),
            E.boolProp("false", name="LoopController.continue_forever"),
            name="ThreadGroup.main_controller", elementType="LoopController",
            guiclass="LoopControlPanel", testclass="LoopController",
            testname="Loop Controller", enabled="true"
        )
        thread_group_element.append(loop_controller)

        # ä½¿ç”¨æ­£ç¢ºçš„å±¬æ€§åç¨±
        thread_group_element.append(E.stringProp(tg_context.num_threads_str, name="ThreadGroup.num_threads"))
        thread_group_element.append(E.stringProp(tg_context.ramp_time_str, name="ThreadGroup.ramp_time"))
        thread_group_element.append(E.boolProp(str(tg_context.scheduler).lower(), name="ThreadGroup.scheduler"))
        thread_group_element.append(E.stringProp(tg_context.duration_str, name="ThreadGroup.duration"))
        thread_group_element.append(E.stringProp("", name="ThreadGroup.delay"))
        thread_group_element.append(E.boolProp("true", name="ThreadGroup.same_user_on_next_iteration"))

        # 2. å»ºç«‹ä¸€å€‹ç©ºçš„ hashTree
        thread_group_hash_tree = E.hashTree()

        # 3. å°‡å…©è€…ä½œç‚ºå…ƒçµ„è¿”å›
        return thread_group_element, thread_group_hash_tree

    def _create_csv_data_set_config(self, csv_info: CsvInfo, name: str = "CSV Data Set Config") -> tuple:
        """
        æ ¹æ“š `CsvInfo` ç‰©ä»¶å»ºç«‹ `<CSVDataSet>` å…ƒä»¶ã€‚

        å®ƒæœƒå°‡ CsvInfo ä¸­çš„æ‰€æœ‰è©³ç´°åƒæ•¸ï¼ˆå¦‚æª”åã€åˆ†éš”ç¬¦ã€åˆ†äº«æ¨¡å¼ç­‰ï¼‰æ‡‰ç”¨åˆ° XML å…ƒä»¶ä¸­ã€‚
        :param csv_info: åŒ…å« CSV æª”æ¡ˆæ‰€æœ‰è¨­å®šçš„ CsvInfo ç‰©ä»¶ã€‚
        :param name: æ­¤ CSV Data Set Config çš„åç¨±ã€‚
        :return: ä¸€å€‹åŒ…å« CSVDataSet XML å…ƒç´ å’Œå…¶ hashTree çš„å…ƒçµ„ã€‚
        """
        element = E.CSVDataSet(
            E.stringProp(csv_info.delimiter, name="delimiter"),
            E.stringProp(csv_info.encoding, name="fileEncoding"),
            E.stringProp(csv_info.filename, name="filename"),
            E.boolProp(str(csv_info.ignoreFirstLine).lower(), name="ignoreFirstLine"),
            E.boolProp(str(csv_info.quotedData).lower(), name="quotedData"),
            E.boolProp(str(csv_info.recycle).lower(), name="recycle"),
            E.stringProp(csv_info.shareMode, name="shareMode"),
            E.boolProp(str(csv_info.stopThread).lower(), name="stopThread"),
            E.stringProp(','.join(csv_info.variable_names), name="variableNames"),
            guiclass="TestBeanGUI",
            testclass="CSVDataSet",
            testname= name,
            enabled="true"
        )
        return element, E.hashTree()

    def _create_http_sampler_proxy(self, req_info: HttpRequestInfo, json_body: str) -> tuple:
        """
        å»ºç«‹ `<HTTPSamplerProxy>` å…ƒä»¶ï¼Œå³ "HTTP Request Sampler"ã€‚

        å®ƒæœƒå°‡è«‹æ±‚çš„æ‰€æœ‰è³‡è¨Šï¼ˆæ–¹æ³•ã€è·¯å¾‘ã€Body ç­‰ï¼‰çµ„è£æˆä¸€å€‹å®Œæ•´çš„ HTTP å–æ¨£å™¨ï¼Œ
        ä¸¦æ”¯æ´é€£ç·šå’Œå›æ‡‰è¶…æ™‚çš„è¨­å®šã€‚
        :param req_info: åŒ…å« HTTP è«‹æ±‚æ‰€æœ‰è¨­å®šçš„ HttpRequestInfo ç‰©ä»¶ã€‚
        :param json_body: ç¶“éè™•ç†ï¼ˆå¯èƒ½å·²åƒæ•¸åŒ–ï¼‰çš„è«‹æ±‚ Body å­—ä¸²ã€‚
        :return: ä¸€å€‹åŒ…å« HTTPSamplerProxy XML å…ƒç´ å’Œå…¶ hashTree çš„å…ƒçµ„ã€‚
        """
        escaped_body = saxutils.escape(json_body) if json_body else ""
        children = [
            E.boolProp("true", name="HTTPSampler.postBodyRaw"),
            E.elementProp(
                E.collectionProp(
                    E.elementProp(
                        E.boolProp("false", name="HTTPArgument.always_encode"),
                        E.stringProp(escaped_body, name="Argument.value"),
                        E.stringProp("=", name="Argument.metadata"),
                        name="", elementType="HTTPArgument"
                    ), name="Arguments.arguments"
                ), name="HTTPsampler.Arguments", elementType="Arguments"
            ),
            E.stringProp(req_info.method, name="HTTPSampler.method"),
            E.boolProp("true", name="HTTPSampler.follow_redirects"),
            E.boolProp("false", name="HTTPSampler.auto_redirects"),
            E.boolProp("true", name="HTTPSampler.use_keepalive"),
            E.boolProp("false", name="HTTPSampler.DO_MULTIPART_POST"),
            E.stringProp("6", name="HTTPSampler.concurrentPool"),
            E.stringProp(req_info.encoding, name="HTTPSampler.contentEncoding")
        ]

        # æ¢ä»¶å¼åœ°åŠ å…¥ç¶²è·¯è¨­å®š
        if req_info.domain: children.append(E.stringProp(req_info.domain, name="HTTPSampler.domain"))
        if req_info.protocol: children.append(E.stringProp(req_info.protocol, name="HTTPSampler.protocol"))
        if req_info.port: children.append(E.stringProp(req_info.port, name="HTTPSampler.port"))
        if req_info.path: children.append(E.stringProp(req_info.path, name="HTTPSampler.path"))

        # ã€å¾®èª¿ã€‘æ–°å¢ timeout åƒæ•¸
        if req_info.connect_timeout:
            children.append(E.stringProp(req_info.connect_timeout, name="HTTPSampler.connect_timeout"))
        if req_info.response_timeout:
            children.append(E.stringProp(req_info.response_timeout, name="HTTPSampler.response_timeout"))

        element = E.HTTPSamplerProxy(
            *children, guiclass="HttpTestSampleGui", testclass="HTTPSamplerProxy",
            testname=req_info.name, enabled="true"
        )
        return element, E.hashTree()

    def _create_response_assertion(self, assertion: AssertionInfo) -> tuple:
        """
        æ ¹æ“š `AssertionInfo` ç‰©ä»¶å»ºç«‹ `<ResponseAssertion>` å…ƒä»¶ã€‚

        æ­¤å‡½å¼æœƒå°‡æ–·è¨€çš„æ‰€æœ‰ç´°ç¯€ï¼ˆå¦‚æ¸¬è©¦é¡å‹ã€æ¯”å°æ¨£å¼ã€é‚è¼¯é‹ç®—ï¼‰è½‰æ›ç‚º
        JMeter æ‰€éœ€çš„ XML æ ¼å¼ï¼Œä¸¦å®Œæ•´æ”¯æ´ is_or, is_not ç­‰é¸é …ã€‚
        :param assertion: åŒ…å«æ–·è¨€æ‰€æœ‰è¨­å®šçš„ AssertionInfo ç‰©ä»¶ã€‚
        :return: ä¸€å€‹åŒ…å« ResponseAssertion XML å…ƒç´ å’Œå…¶ hashTree çš„å…ƒçµ„ã€‚
        """
        # 1. è™•ç† is_not æ¢ä»¶ï¼Œå®ƒæœƒä¿®æ”¹ test_type
        # JMeter ä½¿ç”¨ä½å…ƒé‹ç®—ä¾†çµ„åˆæ¢ä»¶ï¼Œ4 ä»£è¡¨ 'Not'
        final_test_type = assertion.test_type
        if assertion.is_not:
            final_test_type |= 4  # æŒ‰ä½æˆ–é‹ç®—ï¼Œæ·»åŠ  NOT æ¢ä»¶ (e.g., Substring 2 -> Not Substring 6)

        # 2. æº–å‚™ test_strings é›†åˆ
        #    æ­¤è™•ç›´æ¥ä½¿ç”¨ assertion.patterns åˆ—è¡¨ï¼Œç¢ºä¿ä¸æœƒæ··å…¥ä»»ä½•å¤šé¤˜çš„å­—ä¸²ã€‚
        test_strings_props = [E.stringProp(str(p)) for p in assertion.patterns]
        collection_prop = E.collectionProp(*test_strings_props, name="Assertion.test_strings")

        # 3. è™•ç† main_sample_only (å°æ‡‰ Assertion.scope)
        scope = "main" if assertion.main_sample_only else "all"

        # 4. å»ºç«‹æ‰€æœ‰å±¬æ€§ï¼ˆé™¤äº† is_orï¼‰
        props = [
            collection_prop,
            E.stringProp("", name="Assertion.custom_message"),
            E.stringProp(assertion.test_field, name="Assertion.test_field"),
            E.boolProp(str(assertion.assume_success).lower(), name="Assertion.assume_success"),
            E.intProp(str(final_test_type), name="Assertion.test_type"),
            E.stringProp(scope, name="Assertion.scope")
        ]

        # 5. ã€é—œéµã€‘æ ¹æ“š is_or æ¢ä»¶ï¼Œæ·»åŠ é¡å¤–çš„ boolProp
        #    é€™å€‹å±¬æ€§åªåœ¨éœ€è¦ OR é‚è¼¯æ™‚æ‰å­˜åœ¨ã€‚
        if assertion.is_or:
            props.append(E.boolProp("true", name="Assertion.or"))

        # 6. çµ„åˆæœ€çµ‚çš„ XML å…ƒä»¶
        element = E.ResponseAssertion(
            *props,
            guiclass="AssertionGui",
            testclass="ResponseAssertion",
            testname=assertion.name,
            enabled=str(assertion.enabled).lower()
        )

        return element, E.hashTree()

    def _create_view_results_tree_listener(self, listener_info: ListenerInfo) -> tuple:
        """
        æ ¹æ“š `ListenerInfo` ç‰©ä»¶å»ºç«‹ä¸€å€‹å¯è¨­å®šçš„ `<ResultCollector>` (View Results Tree) å…ƒä»¶ã€‚

        :param listener_info: åŒ…å«ç›£è½å™¨è¨­å®šçš„ ListenerInfo ç‰©ä»¶ã€‚
        :return: ä¸€å€‹åŒ…å« ResultCollector XML å…ƒç´ å’Œå…¶ hashTree çš„å…ƒçµ„ã€‚
        """
        # 1. å»ºç«‹ ResultCollector å…ƒä»¶
        collector_element = E.ResultCollector(
            guiclass="ViewResultsFullVisualizer",
            testclass="ResultCollector",
            testname=listener_info.name,
            enabled="true"
        )

        # 2. è™•ç†æ—¥èªŒè¨˜éŒ„é¸é …
        collector_element.append(E.boolProp(str(listener_info.log_errors_only).lower(), name="ResultCollector.error_logging"))
        if listener_info.log_successes_only:
            # JMeter ä¸­ï¼Œåªè¨˜éŒ„æˆåŠŸæ˜¯é€éä¸€å€‹ç¨ç«‹çš„ flagï¼Œè€Œä¸æ˜¯ error_logging çš„åå‘
            collector_element.append(E.boolProp("true", name="ResultCollector.success_only_logging"))

        # 3. å»ºç«‹æ¨™æº–çš„ saveConfig ç‰©ä»¶å±¬æ€§ï¼Œé€™å®šç¾©äº†ç›£è½å™¨è¦å„²å­˜å“ªäº›æ¬„ä½
        save_config = E.objProp(
            E.name("saveConfig"),
            E.value(
                E.time("true"), E.latency("true"), E.timestamp("true"),
                E.success("true"), E.label("true"), E.code("true"),
                E.message("true"), E.threadName("true"), E.dataType("true"),
                E.encoding("false"), E.assertions("true"), E.subresults("true"),
                E.responseData("false"), E.samplerData("false"), E.xml("false"),
                E.fieldNames("true"), E.responseHeaders("false"), E.requestHeaders("false"),
                E.responseDataOnError("false"), E.saveAssertionResultsFailureMessage("true"),
                E.assertionsResultsToSave("0"), E.bytes("true"), E.sentBytes("true"),
                E.url("true"), E.threadCounts("true"), E.idleTime("true"),
                E.connectTime("true"),
                **{'class': "SampleSaveConfiguration"}
            )
        )
        collector_element.append(save_config)

        # 4. è¨­å®šè¼¸å‡ºæª”æ¡ˆåç¨±
        collector_element.append(E.stringProp(listener_info.filename, name="filename"))

        # 5. å»ºç«‹ä¸€å€‹ç©ºçš„ hashTree
        collector_hash_tree = E.hashTree()

        return collector_element, collector_hash_tree

    def _assemble_jmx_from_structured_data(self, context: GenerationContext) -> str:
        """
        æ ¹æ“šçµæ§‹åŒ–çš„ Context ç‰©ä»¶ï¼Œçµ„è£å‡ºæœ€çµ‚çš„ JMX (XML) å­—ä¸²ã€‚

        é€™æ˜¯ JMX çš„ã€Œçµ„è£å·¥å» ã€ã€‚å®ƒæ¥æ”¶ `_prepare_generation_context` ç”¢å‡ºçš„ `GenerationContext` ç‰©ä»¶ï¼Œ
        ç„¶å¾Œéæ­·å…¶ä¸­çš„æ‰€æœ‰å…ƒä»¶ï¼Œå‘¼å«å°æ‡‰çš„ `_create_*` è¼”åŠ©å‡½å¼ä¾†ç”Ÿæˆ XML ç‰‡æ®µï¼Œ
        ä¸¦å°‡å®ƒå€‘æŒ‰ç…§æ­£ç¢ºçš„å±¤ç´šé—œä¿‚çµ„è£èµ·ä¾†ã€‚
        :param context: åŒ…å«æ‰€æœ‰å·²è§£æå’Œè™•ç†éçš„æ¸¬è©¦è¨ˆç•«è³‡è¨Šçš„ GenerationContext ç‰©ä»¶ã€‚
        :return: ä¸€å€‹åŒ…å«å®Œæ•´ JMX å…§å®¹çš„å­—ä¸²ã€‚
        """
        self.logger.info("=== é–‹å§‹åŸ·è¡Œ JMX çµ„è£æµç¨‹ ===")

        root = E.jmeterTestPlan(version="1.2", properties="5.0", jmeter="5.6.3")
        root_hash_tree = E.hashTree()
        root.append(root_hash_tree)

        test_plan_element, test_plan_hash_tree = self._create_test_plan(context)
        root_hash_tree.append(test_plan_element)
        root_hash_tree.append(test_plan_hash_tree)

        if context.global_settings:
            gs = context.global_settings
            if gs.http_defaults and gs.http_defaults.domain:
                defaults_element, defaults_ht = self._create_http_request_defaults(gs.http_defaults)
                test_plan_hash_tree.append(defaults_element)
                test_plan_hash_tree.append(defaults_ht)
            if gs.headers:
                header_manager_element, header_manager_ht = self._create_http_header_manager(gs.headers,
                                                                                             name="Global HTTP Headers")
                test_plan_hash_tree.append(header_manager_element)
                test_plan_hash_tree.append(header_manager_ht)
            if gs.random_variables:
                for var_config in gs.random_variables:
                    rvc_element, rvc_ht = self._create_random_variable_config(var_config)
                    test_plan_hash_tree.append(rvc_element)
                    test_plan_hash_tree.append(rvc_ht)

        for tg_context in context.thread_groups:
            self.logger.info(f"æ­£åœ¨è™•ç† ThreadGroup: {tg_context.name}")
            self.logger.info(f"æ­¤ ThreadGroup çš„ HTTP Requests æ•¸é‡: {len(tg_context.http_requests)}")

            tg_element, tg_hash_tree = self._create_thread_group(tg_context)
            test_plan_hash_tree.append(tg_element)
            test_plan_hash_tree.append(tg_hash_tree)

            if tg_context.headers:
                header_manager_element, header_manager_ht = self._create_http_header_manager(tg_context.headers)
                tg_hash_tree.append(header_manager_element)
                tg_hash_tree.append(header_manager_ht)

            if tg_context.random_variables:
                for var_config in tg_context.random_variables:
                    rvc_element, rvc_ht = self._create_random_variable_config(var_config)
                    tg_hash_tree.append(rvc_element)
                    tg_hash_tree.append(rvc_ht)

            if tg_context.csv_data_sets:
                for csv_info in tg_context.csv_data_sets:
                    csv_element, csv_ht = self._create_csv_data_set_config(csv_info, name=csv_info.name)
                    tg_hash_tree.append(csv_element)
                    tg_hash_tree.append(csv_ht)

            if tg_context.http_requests:
                for req_info in tg_context.http_requests:
                    self.logger.info(f"  -> æ­£åœ¨çµ„è£ HTTP Sampler: {req_info.name}")

                    final_body_content = ""  # åˆå§‹åŒ–æœ€çµ‚çš„ Body å…§å®¹

                    if req_info.source_json_filename:
                        # å¦‚æœæ˜¯æª”æ¡ˆå¼•ç”¨ï¼Œç”Ÿæˆ __FileToString å‡½æ•¸å­—ä¸²
                        # ä½¿ç”¨ JMeter å±¬æ€§ ${__P(testDataPath,.)} ä¾†æŒ‡å®šæª”æ¡ˆçš„æ ¹ç›®éŒ„ï¼Œå¢åŠ éˆæ´»æ€§
                        final_body_content = f"${{__FileToString(${{__P(testDataPath,.)}}/{req_info.source_json_filename},UTF-8)}}"
                        self.logger.info(f"    -> Body ä¾†æº: æª”æ¡ˆå¼•ç”¨ -> {final_body_content}")
                    elif req_info.json_body:
                        # å¦å‰‡ï¼Œä½¿ç”¨èˆŠçš„é‚è¼¯ï¼Œè™•ç†åµŒå…¥çš„ Body
                        final_body_content = req_info.json_body
                        self.logger.info(f"    -> Body ä¾†æº: åµŒå…¥å¼å…§å®¹")
                        # åƒæ•¸åŒ–é‚è¼¯åªå°åµŒå…¥å¼ Body ç”Ÿæ•ˆ
                        if req_info.is_parameterized and tg_context.csv_data_sets:
                            for csv_info in tg_context.csv_data_sets:
                                final_body_content = self._parameterize_json_body(final_body_content, csv_info)

                    # å°‡è™•ç†å¥½çš„ final_body_content å‚³çµ¦å»ºç«‹å‡½å¼
                    sampler_element, sampler_hash_tree = self._create_http_sampler_proxy(
                        req_info=req_info,
                        json_body=final_body_content
                    )

                    tg_hash_tree.append(sampler_element)
                    tg_hash_tree.append(sampler_hash_tree)

                    if req_info.assertions:
                        for assertion_info in req_info.assertions:
                            assertion_element, assertion_ht = self._create_response_assertion(assertion_info)
                            sampler_hash_tree.append(assertion_element)
                            sampler_hash_tree.append(assertion_ht)

            if tg_context.listeners:
                for listener_info in tg_context.listeners:
                    listener_element, listener_ht = self._create_view_results_tree_listener(listener_info)
                    tg_hash_tree.append(listener_element)
                    tg_hash_tree.append(listener_ht)

        for listener_info in context.listeners:
            listener_element, listener_ht = self._create_view_results_tree_listener(listener_info)
            test_plan_hash_tree.append(listener_element)
            test_plan_hash_tree.append(listener_ht)

        self.logger.info("JMX å…ƒä»¶çµ„è£å®Œæˆã€‚")
        return etree.tostring(root, pretty_print=True, xml_declaration=True, encoding='UTF-8').decode('utf-8')

    async def convert_requirements_to_template(self, requirements: str, files_data: List[Dict] = None) -> str:
        """
        ä½¿ç”¨ LLM å°‡è‡ªç„¶èªè¨€éœ€æ±‚è½‰æ›ç‚ºçµæ§‹åŒ–çš„ JMX éœ€æ±‚æ¨¡æ¿ã€‚

        æ­¤å‡½å¼æ˜¯èˆ‡ LLM äº’å‹•çš„å…¥å£ï¼Œè² è²¬å°‡è‡ªç”±æ ¼å¼çš„æ–‡å­—è½‰æ›æˆå¾ŒçºŒç¨‹å¼å¯ä»¥è§£æçš„å›ºå®šæ ¼å¼ã€‚
        :param requirements: ä½¿ç”¨è€…è¼¸å…¥çš„è‡ªç„¶èªè¨€éœ€æ±‚ã€‚
        :param files_data: ä¸€å€‹åŒ…å«å·²ä¸Šå‚³æª”æ¡ˆè³‡è¨Šçš„å­—å…¸åˆ—è¡¨ã€‚
        :return: ä¸€å€‹åŒ…å«çµæ§‹åŒ–æ¨¡æ¿å…§å®¹çš„å­—ä¸²ã€‚
        :raises RuntimeError: å¦‚æœ LLM å‘¼å«æˆ–å¾ŒçºŒæ¸…ç†å¤±æ•—ã€‚
        """
        self.logger.info("é–‹å§‹åŸ·è¡Œ LLM éœ€æ±‚è½‰æ›ä»»å‹™ï¼šè‡ªç„¶èªè¨€ -> çµæ§‹åŒ–æ¨¡æ¿")

        # æ­¥é©Ÿ 1: å»ºç«‹ä¸€å€‹å°ˆç‚ºæ­¤è½‰æ›ä»»å‹™è¨­è¨ˆçš„æç¤ºè©
        prompt = self._build_conversion_prompt(requirements, files_data)
        self.logger.debug(f"å»ºç«‹çš„è½‰æ›æç¤ºè©:\n---\n{prompt}\n---")

        try:
            # æ­¥é©Ÿ 2: å‘¼å« LLM æœå‹™ä¾†åŸ·è¡Œè½‰æ›
            self.logger.info("æ­£åœ¨å‘¼å« LLM é€²è¡Œè½‰æ›...")
            response = self.llm_service.generate_text(prompt)
            self.logger.info("LLM å›æ‡‰æ¥æ”¶æˆåŠŸã€‚")
            self.logger.debug(f"LLM åŸå§‹å›æ‡‰:\n---\n{response}\n---")

            # æ­¥é©Ÿ 3: æ¸…ç† LLM çš„å›æ‡‰ï¼Œç§»é™¤å¯èƒ½çš„å¤šé¤˜éƒ¨åˆ† (å¦‚ markdown)
            template_str = self._clean_llm_template_response(response)
            self.logger.info("å·²æ¸…ç† LLM å›æ‡‰ï¼Œæº–å‚™è¿”å›çµæ§‹åŒ–æ¨¡æ¿ã€‚")

            return template_str

        except Exception as e:
            self.logger.error(f"åœ¨ä½¿ç”¨ LLM è½‰æ›éœ€æ±‚æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}", exc_info=True)
            raise RuntimeError(f"ç„¡æ³•å°‡éœ€æ±‚è½‰æ›ç‚ºæ¨¡æ¿: {e}")

    def _build_conversion_prompt(self, requirements: str, files_data: List[Dict] = None) -> str:
        """
        å»ºç«‹ç”¨æ–¼æŒ‡å° LLM é€²è¡Œéœ€æ±‚è½‰æ›çš„æç¤ºè© (Prompt)ã€‚

        é€™æ˜¯ã€Œæç¤ºè©å·¥ç¨‹ã€çš„æ ¸å¿ƒï¼Œè² è²¬å‹•æ…‹ç”¢ç”Ÿä¸€æ®µè©³ç´°çš„æ–‡å­—ï¼ŒæŒ‡å° LLM å¦‚ä½•å·¥ä½œã€‚
        å®ƒåŒ…å«äº†è§’è‰²è¨­å®šã€æ ¸å¿ƒè¦å‰‡ã€ä»»å‹™æè¿°å’Œè¼¸å‡ºç¯„ä¾‹ã€‚
        :param requirements: ä½¿ç”¨è€…è¼¸å…¥çš„è‡ªç„¶èªè¨€éœ€æ±‚ã€‚
        :param files_data: ä¸€å€‹åŒ…å«å·²ä¸Šå‚³æª”æ¡ˆè³‡è¨Šçš„å­—å…¸åˆ—è¡¨ã€‚
        :return: å®Œæ•´çš„æç¤ºè©å­—ä¸²ã€‚
        """
        attached_files = [f.get('filename', f.get('name', '')) for f in files_data if f] if files_data else []
        files_context = "\n".join([f"- `{name}`" for name in attached_files]) if attached_files else "ç„¡"

        prompt = textwrap.dedent(f"""
        [INST]
        <<SYS>>
        æ‚¨æ˜¯ä¸€ä½ç²¾é€š JMeter çš„å°ˆå®¶åŠ©ç†ã€‚æ‚¨çš„å”¯ä¸€ä»»å‹™æ˜¯å°‡ç”¨æˆ¶æä¾›çš„è‡ªç„¶èªè¨€éœ€æ±‚ï¼Œç²¾ç¢ºåœ°è½‰æ›ç‚ºæŒ‡å®šçš„çµæ§‹åŒ–æ–‡å­—æ¨¡æ¿æ ¼å¼ã€‚

        **æ ¸å¿ƒè¦å‰‡:**
        1.  **åš´æ ¼éµå¾ªæ ¼å¼**: æ‚¨çš„è¼¸å‡º**å¿…é ˆ**åƒ…åŒ…å«çµæ§‹åŒ–æ¨¡æ¿å…§å®¹ï¼Œä¸å¾—åŒ…å«ä»»ä½•å°è©±ã€è§£é‡‹æˆ– Markdown æ¨™è¨˜ (ä¾‹å¦‚ ```)ã€‚
        2.  **ã€é—œéµã€‘åç¨±å¿…é ˆç²¾ç¢º**: æ‰€æœ‰å…ƒä»¶çš„åç¨± (ä¾‹å¦‚ `[TestPlan: msp-svc-checkid]`) **å¿…é ˆ**åš´æ ¼ä½¿ç”¨ç¯„ä¾‹ä¸­æä¾›çš„åç¨±ï¼Œä¸å¾—ä½¿ç”¨ JMeter çš„é è¨­åç¨±ã€‚
        3.  **ã€é—œéµã€‘æª”æ¡ˆå¼•ç”¨è¦å‰‡**: å¦‚æœ `HttpRequest` éœ€è¦ä½¿ç”¨æª”æ¡ˆä½œç‚ºè«‹æ±‚ Bodyï¼Œæ‚¨**å¿…é ˆ**ä½¿ç”¨ `body_file = "æª”æ¡ˆåç¨±"` çš„æ ¼å¼ã€‚**çµ•å°ç¦æ­¢**å°‡æª”æ¡ˆçš„å¯¦éš›å…§å®¹ç›´æ¥å¡«å…¥ `body` åƒæ•¸ä¸­ã€‚
        4.  **æ­£ç¢ºçš„å±¤ç´šé—œä¿‚**: å…ƒä»¶çš„ `parent` å±¬æ€§å¿…é ˆæ­£ç¢ºè¨­å®šã€‚
        5.  **ã€é—œéµã€‘æ–·è¨€å±¤ç´šè¦å‰‡**: å¦‚æœç”¨æˆ¶éœ€æ±‚ä¸­çš„æ–·è¨€æ²’æœ‰æ˜ç¢ºæŒ‡å®šè¦é™„åŠ åˆ°å“ªä¸€å€‹ `HttpRequest`ï¼Œå‰‡å…¶ `parent` å±¬æ€§**å¿…é ˆ**è¨­å®šç‚ºå…¶æ‰€å±¬çš„ `ThreadGroup` åç¨±ã€‚
        6.  **ã€é—œéµã€‘åš´æ ¼çš„å…§å®¹è¦å‰‡**: **çµ•å°ç¦æ­¢**åœ¨æ²’æœ‰ç”¨æˆ¶æ˜ç¢ºæŒ‡ç¤ºï¼ˆä¾‹å¦‚ï¼Œæä¾› CSV æª”æ¡ˆé€²è¡Œåƒæ•¸åŒ–ï¼‰çš„æƒ…æ³ä¸‹ï¼Œä¸»å‹•å°‡è«‹æ±‚ Body ä¸­çš„ä»»ä½•å€¼ä¿®æ”¹ç‚º JMeter è®Šæ•¸ (ä¾‹å¦‚ `${{variable}}`)ã€‚Body å…§å®¹å¿…é ˆä¿æŒåŸå§‹ç‹€æ…‹ï¼Œé™¤éæœ‰æ˜ç¢ºçš„è¦†å¯«æŒ‡ä»¤ã€‚
        7.  **ã€æ–°å¢ã€‘ä¼ºæœå™¨è³‡è¨ŠåŒç¾©è©è¦å‰‡**: ç”¨æˆ¶å¯èƒ½æœƒä½¿ç”¨ã€ŒServer Name or IPã€ã€ã€Œä¼ºæœå™¨ä½å€ã€ã€ã€Œä¸»æ©Ÿã€ç­‰è©èªä¾†æè¿°ä¼ºæœå™¨ã€‚é€™äº›éƒ½æ‡‰è¢«å°æ‡‰åˆ° `domain` åƒæ•¸ã€‚
        <</SYS>>

        **### ä»»å‹™: å°‡ä»¥ä¸‹ç”¨æˆ¶éœ€æ±‚è½‰æ›ç‚ºçµæ§‹åŒ–æ¨¡æ¿ ###**

        **ç”¨æˆ¶éœ€æ±‚æè¿°:**
        ---
        {requirements}
        ---

        **å¯ç”¨çš„é™„ä»¶æª”æ¡ˆåˆ—è¡¨:**
        ---
        {files_context}
        ---

        **### ç›®æ¨™è¼¸å‡ºæ ¼å¼ (æ‚¨å¿…é ˆå®Œå…¨ä»¿ç…§æ­¤æ ¼å¼è¼¸å‡º) ###**

        ```text
        # ======================================================================
        # JMeter æ¸¬è©¦è¨ˆç•«ç”Ÿæˆéœ€æ±‚æ¨¡æ¿ 
        # ======================================================================

        [TestPlan: msp-svc-checkid]
        tearDown_on_shutdown = true

        # --- ã€æ³¨æ„åç¨±ã€‘ ---
        [HttpHeaderManager: GlobalHeaders]
        parent = msp-svc-checkid
        header.Content-type = application/json
        header.x-cub-it-key = zgnf1hJIZVxtIxfjLl2a0T9vl5f98o9b

        # --- ã€å…¨åŸŸä¼ºæœå™¨è¨­å®šã€‘ ---
        [GlobalHttpRequestDefaults: DefaultHttpSettings]
        parent = msp-svc-checkid
        # æ³¨æ„ï¼šç”¨æˆ¶éœ€æ±‚ä¸­çš„ "Server Name or IP" æˆ– "ä¼ºæœå™¨ä½å€" éƒ½æ‡‰å°æ‡‰åˆ°æ­¤ domain åƒæ•¸
        domain = your-global-server.com
        protocol = https

        [ThreadGroup: MSP-B-CHECKIDC001]
        parent = msp-svc-checkid
        threads = ${{__P(threads,3)}}
        rampup = ${{__P(rampUp,1)}}
        use_scheduler = true
        duration = ${{__P(duration,10)}}

        # --- ã€æ³¨æ„ body_file çš„ä½¿ç”¨èˆ‡å…§å®¹çš„åŸå§‹æ€§ã€‘ ---
        [HttpRequest: REQ_MSP-B-CHECKIDC001]
        parent = MSP-B-CHECKIDC001
        method = POST
        path = /rest # <-- ç•¶ GlobalHttpRequestDefaults å·²è¨­å®š domainï¼Œé€™è£¡åªéœ€æä¾› path
        # Body å…§å®¹ä¸æ‡‰è¢«ä¸»å‹•åƒæ•¸åŒ–
        body_file = MOCK-B-CHECKIDC001.json # <-- æ­£ç¢ºç”¨æ³•

        # --- ã€æ³¨æ„åç¨±ã€‘ ---
        [CsvDataSet: CSV_For_CHECKIDC001]
        parent = MSP-B-CHECKIDC001
        filename = MOCK-B-CHECKIDC001.csv
        variable_names = type,ID

        [ResponseAssertion: é©—è­‰å›è¦†-TXNSEQ]
        parent = REQ_MSP-B-CHECKIDC001 # <-- è‹¥æ–·è¨€ç›®æ¨™ä¸æ˜ç¢ºï¼Œparent æ‡‰è¨­ç‚º ThreadGroup åç¨±
        pattern_matching_rule = Contains
        pattern_1 = ZXZTEST-123456

        [ResponseAssertion: é©—è­‰å›è¦†-RETURNCODE]
        parent = REQ_MSP-B-CHECKIDC001
        pattern_matching_rule = Contains
        use_or_logic = true
        pattern_1 = "RETURNCODE":"0000"

        # --- ã€æ³¨æ„ç›£è½å™¨åç¨±å’Œå±¬æ€§ã€‘ ---
        [Listener: Successes]
        parent = msp-svc-checkid
        filename = Successes_Content.xml
        log_successes_only = true

        [Listener: Errors]
        parent = msp-svc-checkid
        filename = Error_Content.xml
        log_errors_only = true
        ```
        [/INST]
        """)
        return prompt

    def _clean_llm_template_response(self, response: str) -> str:
        """
        æ¸…ç† LLM è¿”å›çš„æ¨¡æ¿å­—ä¸²ï¼Œç§»é™¤å¸¸è¦‹çš„å¤šé¤˜éƒ¨åˆ†ã€‚
        :param response: ä¾†è‡ª LLM çš„åŸå§‹å›æ‡‰å­—ä¸²ã€‚
        :return: æ¸…ç†å¾Œçš„æ¨¡æ¿å­—ä¸²ã€‚
        """
        # å°‹æ‰¾æ¨¡æ¿çš„èµ·å§‹æ¨™èªŒ
        start_marker = "# ======================================================================"
        start_index = response.find(start_marker)

        if start_index == -1:
            # å¦‚æœæ‰¾ä¸åˆ°èµ·å§‹æ¨™èªŒï¼Œå˜—è©¦å°‹æ‰¾ç¬¬ä¸€å€‹ [Component: Name]
            match = re.search(r"^\s*\[[a-zA-Z]+:.+?\]", response, re.MULTILINE)
            if match:
                start_index = match.start()
            else:
                self.logger.warning("åœ¨ LLM å›æ‡‰ä¸­æ‰¾ä¸åˆ°æ¨¡æ¿èµ·å§‹æ¨™èªŒï¼Œè¿”å›åŸå§‹å›æ‡‰ã€‚")
                return response.strip()

        # å¾æ‰¾åˆ°çš„èµ·å§‹ä½ç½®æˆªå–
        cleaned_response = response[start_index:]

        # ç§»é™¤çµå°¾å¯èƒ½å‡ºç¾çš„ markdown
        if cleaned_response.endswith("```"):
            cleaned_response = cleaned_response[:-3].strip()

        return cleaned_response